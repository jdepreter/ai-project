{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Restricted Boltzmann Machine Defintion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Import PyTorch library\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "device = torch.device('cpu')\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# https://github.com/khanhnamle1994/MetaRec/blob/b5e36cb579a88b32cdfb728f35f645d76b24ad95/Boltzmann-Machines-Experiments/RBM-CF-PyTorch/rbm.py#L23\n",
    "# Create the Restricted Boltzmann Machine architecture\n",
    "class RBM(nn.Module):\n",
    "    def __init__(self, n_vis, n_hid):\n",
    "        \"\"\"\n",
    "        Initialize the parameters (weights and biases) we optimize during the training process\n",
    "        :param n_vis: number of visible units\n",
    "        :param n_hid: number of hidden units\n",
    "        \"\"\"\n",
    "        self.i = 0\n",
    "\n",
    "        # Weights used for the probability of the visible units given the hidden units\n",
    "        super().__init__()\n",
    "        self.W = torch.zeros(n_hid, n_vis, device=device)  # torch.rand: random normal distribution mean = 0, variance = 1\n",
    "\n",
    "        # Bias probability of the visible units is activated, given the value of the hidden units (p_v_given_h)\n",
    "        self.v_bias = torch.zeros(1, n_vis, device=device)  # fake dimension for the batch = 1\n",
    "\n",
    "        # Bias probability of the hidden units is activated, given the value of the visible units (p_h_given_v)\n",
    "        self.h_bias = torch.zeros(1, n_hid, device=device)  # fake dimension for the batch = 1\n",
    "    \n",
    "    def lr(self):\n",
    "        return 0.02\n",
    "\n",
    "    def sample_h(self, x):\n",
    "        \"\"\"\n",
    "        Sample the hidden units\n",
    "        :param x: the dataset\n",
    "        \"\"\"\n",
    "\n",
    "        # Probability h is activated given that the value v is sigmoid(Wx + a)\n",
    "        # torch.mm make the product of 2 tensors\n",
    "        # W.t() take the transpose because W is used for the p_v_given_h\n",
    "        wx = torch.mm(x, self.W.t())\n",
    "        # print(wx.shape)\n",
    "\n",
    "        # Expand the mini-batch\n",
    "        activation = wx + self.h_bias.expand_as(wx)\n",
    "        # print(activation.shape)\n",
    "\n",
    "        # Calculate the probability p_h_given_v\n",
    "        p_h_given_v = torch.sigmoid(activation)\n",
    "\n",
    "        # print(\"h sparse\", p_h_given_v.is_sparse, torch.bernoulli(p_h_given_v).is_sparse)\n",
    "\n",
    "        # Construct a Bernoulli RBM to predict whether an user loves the movie or not (0 or 1)\n",
    "        # This corresponds to whether the n_hid is activated or not activated\n",
    "        return p_h_given_v, torch.bernoulli(p_h_given_v)\n",
    "\n",
    "    def sample_v(self, y):\n",
    "        \"\"\"\n",
    "        Sample the visible units\n",
    "        :param y: the dataset\n",
    "        \"\"\"\n",
    "\n",
    "        # Probability v is activated given that the value h is sigmoid(Wx + a)\n",
    "        wy = torch.mm(y, self.W)\n",
    "\n",
    "        # Expand the mini-batch\n",
    "        activation = wy + self.v_bias.expand_as(wy)\n",
    "\n",
    "        # Calculate the probability p_v_given_h\n",
    "        p_v_given_h = torch.sigmoid(activation)\n",
    "\n",
    "        # print(\"v sparse\", p_v_given_h.is_sparse, torch.bernoulli(p_v_given_h).is_sparse)\n",
    "\n",
    "        # Construct a Bernoulli RBM to predict whether an user loves the movie or not (0 or 1)\n",
    "        # This corresponds to whether the n_vis is activated or not activated\n",
    "        return p_v_given_h, torch.bernoulli(p_v_given_h)\n",
    "\n",
    "    def train_model(self, v0, vk, ph0, phk):\n",
    "        \"\"\"\n",
    "        Perform contrastive divergence algorithm to optimize the weights that minimize the energy\n",
    "        This maximizes the log-likelihood of the model\n",
    "        \"\"\"\n",
    "\n",
    "        w_extra = (torch.mm(v0.t(), ph0) - torch.mm(vk.t(), phk)).t()\n",
    "        v_extra = torch.sum((v0 - vk), 0)\n",
    "        h_extra = torch.sum((ph0 - phk), 0)\n",
    "\n",
    "        # if self.i % 45 == 0:\n",
    "            # print(torch.max(w_extra), torch.max(v_extra), torch.max(h_extra), flush=True)\n",
    "\n",
    "        # Approximate the gradients with the CD algorithm\n",
    "        # TODO learning rate toevoegen\n",
    "        self.W += self.lr() * w_extra\n",
    "\n",
    "        # Add (difference, 0) for the tensor of 2 dimensions\n",
    "        self.v_bias += self.lr() * v_extra\n",
    "        self.h_bias += self.lr() * h_extra\n",
    "        self.i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "cuda = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "import gzip\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "import math\n",
    "tqdm.pandas() #for progres_apply etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "#read file line-by-line and parse json, returns dataframe\n",
    "def parse_json(filename_gzipped_python_json, read_max=-1):\n",
    "  #read gzipped content\n",
    "  f=gzip.open(filename_gzipped_python_json,'r')\n",
    "  \n",
    "  #parse json\n",
    "  parse_data = []\n",
    "  for line in tqdm(f): #tqdm is for showing progress bar, always good when processing large amounts of data\n",
    "    line = line.decode('utf-8')\n",
    "    line = line.replace('true','True') #difference json/python\n",
    "    line = line.replace('false','False')\n",
    "    parsed_result = eval(line) #load python nested datastructure\n",
    "    # print(filename_gzipped_python_json == steam_path + steam_reviews and 'user_id' not in parsed_result)\n",
    "    # break\n",
    "    if filename_gzipped_python_json == steam_path + steam_reviews and 'user_id' not in parsed_result:\n",
    "      continue\n",
    "      \n",
    "    parse_data.append(parsed_result)\n",
    "    if read_max !=-1 and len(parse_data) > read_max:\n",
    "      print(f'Break reading after {read_max} records')\n",
    "      break\n",
    "  print(f\"Reading {len(parse_data)} rows.\")\n",
    "\n",
    "  #create dataframe\n",
    "  df= pd.DataFrame.from_dict(parse_data)\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "steam_path = './data/'\n",
    "metadata_games = 'steam_games.json.gz' \n",
    "user_items = 'australian_users_items.json.gz'\n",
    "user_reviews = 'australian_user_reviews.json.gz'\n",
    "game_bundles = 'bundle_data.json.gz'\n",
    "steam_reviews= 'steam_reviews.json.gz'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def score_model(rbm, batch_size, train_matrix, test_matrix):\n",
    "    test_recon_error = 0  # RMSE reconstruction error initialized to 0 at the beginning of training\n",
    "    s = 0  # a counter (float type) \n",
    "    # for loop - go through every single user\n",
    "    for id_user in range(0, train_matrix.shape[0] - batch_size, batch_size):\n",
    "        v = train_matrix[id_user:id_user + batch_size]  # training set inputs are used to activate neurons of my RBM\n",
    "        vt = test_matrix[id_user:id_user + batch_size]  # target\n",
    "        # v = convert_sparse_matrix_to_sparse_tensor(training_sample)\n",
    "        # vt = convert_sparse_matrix_to_sparse_tensor(training_sample2)\n",
    "        v = v.todense()\n",
    "        vt = vt.todense()\n",
    "\n",
    "        # v = v.to_dense()\n",
    "        # vt = vt.to_dense()\n",
    "        v = v - 1\n",
    "        vt = vt - 1\n",
    "        v = torch.Tensor(v)\n",
    "        vt = torch.Tensor(vt)\n",
    "        if torch.cuda.is_available():\n",
    "            v = v.cuda()\n",
    "            vt = vt.cuda()\n",
    "        if len(vt[vt > -1]) > 0:\n",
    "            _, h = rbm.sample_h(v)\n",
    "            v, _ = rbm.sample_v(h)\n",
    "\n",
    "            # Update test RMSE reconstruction error\n",
    "            test_recon_error += torch.sqrt(torch.mean((vt[vt > -1] - v[vt > -1])**2)) * len(vt > -1)\n",
    "            s += len(vt > -1) \n",
    "\n",
    "    return test_recon_error / s\n",
    "\n",
    "\n",
    "# https://stackoverflow.com/questions/40896157/scipy-sparse-csr-matrix-to-tensorflow-sparsetensor-mini-batch-gradient-descent\n",
    "def convert_sparse_matrix_to_sparse_tensor(X):\n",
    "    coo = X.tocoo()\n",
    "\n",
    "    values = coo.data\n",
    "    indices = np.vstack((coo.row, coo.col))\n",
    "\n",
    "    i = torch.LongTensor(indices)\n",
    "    v = torch.FloatTensor(values)\n",
    "    # print(values)\n",
    "    # print(\"values\", v)\n",
    "    shape = coo.shape\n",
    "    tensor = torch.sparse.FloatTensor(i, v, torch.Size(shape)) \n",
    "    if torch.cuda.is_available():\n",
    "        tensor = tensor.cuda()\n",
    "\n",
    "    return tensor \n",
    "\n",
    "def create_rbm(train_matrix, test_matrix, n_hidden, batch_size, epochs, rbm=None) -> RBM:\n",
    "    n_vis = train_matrix.shape[1]\n",
    "    train_errors = []\n",
    "    test_errors = []\n",
    "    if rbm is None:\n",
    "        rbm = RBM(n_vis, n_hidden)\n",
    "\n",
    "    print(\"start training\")\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        rbm.train()\n",
    "        train_recon_error = 0  # RMSE reconstruction error initialized to 0 at the beginning of training\n",
    "        s = 0\n",
    "        \n",
    "        for user_id in range(0, train_matrix.shape[0] - batch_size, batch_size):\n",
    "            training_sample = train_matrix[user_id : user_id + batch_size]\n",
    "            training_sample2 = train_matrix[user_id : user_id + batch_size]\n",
    "            # print(training_sample)\n",
    "            v0 = convert_sparse_matrix_to_sparse_tensor(training_sample)\n",
    "            # print(v0.coalesce().indices())\n",
    "            vk = convert_sparse_matrix_to_sparse_tensor(training_sample2)\n",
    "\n",
    "            v0 = v0.to_dense()\n",
    "            vk = vk.to_dense()\n",
    "            v0 = v0.sub(1)\n",
    "            vk = vk.sub(1)\n",
    "            \n",
    "            ph0, _ = rbm.sample_h(v0)\n",
    "\n",
    "            # Third for loop - perform contrastive divergence\n",
    "            # TODO misschien is iets lager proberen?\n",
    "            for k in range(1):\n",
    "                _, hk = rbm.sample_h(vk)\n",
    "                _, vk = rbm.sample_v(hk)\n",
    "\n",
    "                # We don't want to learn when there is no rating by the user, and there is no update when rating = -1\n",
    "                # Remove indices from vk vector that are not in the v0 vector => get sparse tensor again\n",
    "                vk[v0 < 0] = v0[v0 < 0]\n",
    "                \n",
    "\n",
    "            phk, _ = rbm.sample_h(vk)\n",
    "\n",
    "            rbm.train_model(v0, vk, ph0, phk)\n",
    "            vk, _ = rbm.sample_v(hk)\n",
    "            \n",
    "            train_recon_error += torch.sqrt(torch.mean((v0[v0 > -1] - vk[v0 > -1])**2)) * len(v0 > -1)\n",
    "            s += len(v0 > -1)\n",
    "            \n",
    "            # print((torch.mm(v0.t(), ph0) - torch.mm(vk.t(), phk)).t().shape)\n",
    "            # print(torch.sum((-vk + v0), 0).shape)\n",
    "            # print(torch.sum((ph0 - phk), 0).shape)\n",
    "            \n",
    "        train_errors.append(train_recon_error / s)\n",
    "\n",
    "        # print('calculating test scores')\n",
    "        rbm.eval()\n",
    "        test_errors.append(score_model(rbm, batch_size, train_matrix, test_matrix))\n",
    "\n",
    "        # print('finished epoch', epoch)    \n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "    # Plot the RMSE reconstruction error with respect to increasing number of epochs\n",
    "    plt.plot(torch.Tensor(train_errors, device='cpu'), label=\"train\")\n",
    "    plt.plot(torch.Tensor(test_errors, device='cpu'), label=\"test\")\n",
    "    plt.ylabel('Error')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend()\n",
    "    plt.savefig(f'large-{n_hidden}-{batch_size}-{epochs}.jpg')\n",
    "\n",
    "    return rbm\n",
    "\n",
    "# Evaluate the RBM on test set\n",
    "# test_recon_error = score_model(rbm)\n",
    "# print(\"Final error\", test_recon_error)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hitrate / Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_hr(train_matrix, test_matrix, rbm, k=10, batch_size=100):\n",
    "    s = 0  # a counter (float type) \n",
    "    hitrates = []\n",
    "    recall = []\n",
    "    nDCG = []\n",
    "    # for loop - go through every single user\n",
    "    for id_user in range(0, train_matrix.shape[0]): # - batch_size, batch_size):\n",
    "        v = train_matrix[id_user]  # training set inputs are used to activate neurons of my RBM\n",
    "        vt = test_matrix[id_user]  # target\n",
    "\n",
    "        target_data = vt.data\n",
    "        target_index = vt.indices\n",
    "        target_recommendations = target_index[target_data == 2]\n",
    "        # print(target_test)\n",
    "\n",
    "        v = v.todense()\n",
    "\n",
    "        v = v - 1\n",
    "        v = torch.Tensor(v)\n",
    "        if torch.cuda.is_available():\n",
    "            v = v.cuda()\n",
    "        \n",
    "        if len(target_recommendations) > 0: # check that target contains recommendations (only needed for aussies)\n",
    "            _, h = rbm.sample_h(v)\n",
    "            recommended, _ = rbm.sample_v(h)\n",
    "\n",
    "            # all recommendations\n",
    "            _, indices =  torch.topk(recommended[v < 0], k)\n",
    "            recommendations = torch.tensor(indices, device='cpu').tolist()\n",
    "\n",
    "            counter = 0\n",
    "            total = len(target_recommendations)\n",
    "            for target in target_recommendations:\n",
    "                if target in recommendations:\n",
    "                    counter += 1\n",
    "            # counter = len(recommendations)\n",
    "\n",
    "            recall.append(counter / total)\n",
    "            hitrates.append(min(1, counter))\n",
    "\n",
    "            # nDCG\n",
    "            idcg = np.sum([1 / np.log2(i+2) for i in range(min(k, len(target_recommendations)))])\n",
    "            dcg = 0\n",
    "            for i, r in enumerate(recommendations):\n",
    "                if r in target_recommendations:\n",
    "                    dcg += 1 / np.log2(i+2)\n",
    "\n",
    "            nDCG.append(dcg / idcg) \n",
    "\n",
    "    return hitrates, recall, nDCG\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCHS 10\n",
      "20 tensor(0.9137, device='cuda:0')\n",
      "21 tensor(0.8984, device='cuda:0')\n",
      "average value tensor(0.5602, device='cuda:0')\n",
      "values tensor([0.9817, 0.9805, 0.9754, 0.9713, 0.9701, 0.9658, 0.9637, 0.9616, 0.9616,\n",
      "        0.9585], device='cuda:0')\n",
      "recommended [59, 33, 0, 61, 27, 197, 20, 24, 40, 25]\n",
      "real [18]\n",
      "------------------------------\n",
      "EPOCHS 20\n",
      "20 tensor(0.9089, device='cuda:0')\n",
      "21 tensor(0.9168, device='cuda:0')\n",
      "average value tensor(0.5865, device='cuda:0')\n",
      "values tensor([0.9849, 0.9834, 0.9820, 0.9817, 0.9777, 0.9754, 0.9739, 0.9729, 0.9723,\n",
      "        0.9718], device='cuda:0')\n",
      "recommended [59, 0, 33, 61, 35, 92, 330, 27, 197, 109]\n",
      "real [18]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jolan\\AppData\\Local\\Temp/ipykernel_22208/4121192494.py:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  recommendations = torch.tensor(indices, device='cpu').tolist()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[59, 0, 33, 61, 35, 92, 330, 27, 197, 109]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def recommend(rbm, v, vt, k, p=True):\n",
    "    target_data = vt.data\n",
    "    target_index = vt.indices\n",
    "    target_recommendations = target_index[target_data == 2]\n",
    "    v = v.todense()\n",
    "    v = v - 1\n",
    "    v = torch.Tensor(v)\n",
    "    if torch.cuda.is_available():\n",
    "        v = v.cuda()\n",
    "    \n",
    "    _, h = rbm.sample_h(v)\n",
    "    recommended, _ = rbm.sample_v(h)\n",
    "\n",
    "    # all recommendations\n",
    "    values, indices =  torch.topk(recommended[v < 0], k)\n",
    "    recommendations = torch.tensor(indices, device='cpu').tolist()\n",
    "\n",
    "    if p:\n",
    "        print('20', recommended[0][20])\n",
    "        print('21', recommended[0][21])\n",
    "        print(\"average value\", torch.mean(recommended[0]))\n",
    "\n",
    "    found = True\n",
    "    for r in recommendations:\n",
    "        if r in target_recommendations:\n",
    "            if p:\n",
    "                print(\"HIT\")\n",
    "            found = True\n",
    "            break\n",
    "\n",
    "    if found and p:\n",
    "        print(\"values\", values)\n",
    "        print(\"recommended\", recommendations)\n",
    "        print(\"real\", target_recommendations)\n",
    "\n",
    "    \n",
    "    \n",
    "    return recommendations\n",
    "\n",
    "# user = 4\n",
    "# # print(\"train\", train_matrix[user])\n",
    "# # print(\"test\", test_matrix[user])\n",
    "\n",
    "# print(\"EPOCHS 10\")\n",
    "# recommend(rbm10, train_matrix[user], test_matrix[user], 10)\n",
    "# print('---' * 10)\n",
    "# print(\"EPOCHS 20\")\n",
    "# recommend(rbm20, train_matrix[user], test_matrix[user], 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Full Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7793069it [03:48, 34113.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 3176223 rows.\n"
     ]
    }
   ],
   "source": [
    "steam_reviews_df = parse_json(steam_path + steam_reviews)\n",
    "steam_reviews_df_small = steam_reviews_df[['user_id', 'product_id', 'recommended', 'date']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "steam_reviews_df_cleaned = steam_reviews_df_small.dropna(axis=0, subset=['user_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76561198011965365    1254\n",
       "76561198094803808     900\n",
       "76561197969749884     750\n",
       "76561198094321628     669\n",
       "76561198073092169     549\n",
       "                     ... \n",
       "76561198345086561       1\n",
       "76561198054491833       1\n",
       "76561198095690287       1\n",
       "76561198301658414       1\n",
       "76561198089897928       1\n",
       "Name: user_id, Length: 1485611, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steam_reviews_df_cleaned.head(5)\n",
    "steam_reviews_df[\"user_id\"].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3176223/3176223 [00:01<00:00, 1660198.64it/s]\n"
     ]
    }
   ],
   "source": [
    "dct = {}\n",
    "def map_to_consecutive_id(uuid):\n",
    "  if uuid in dct:\n",
    "    return dct[uuid]\n",
    "  else:\n",
    "    id = len(dct)\n",
    "    dct[uuid] = id\n",
    "    return id\n",
    "steam_reviews_df_cleaned['product_id_int'] = steam_reviews_df_cleaned['product_id'].progress_apply(map_to_consecutive_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# train_df, test_df = train_test_split(steam_reviews_df_cleaned, test_size=0.2)\n",
    "\n",
    "\n",
    "# test_df_grouped = test_df.groupby('user_id_int').agg(list)\n",
    "# test_df_grouped = test_df_grouped.reset_index()\n",
    "\n",
    "# train_df_grouped = train_df.groupby('user_id_int').agg(list)\n",
    "# train_df_grouped = train_df_grouped.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Date Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id                   object\n",
       "product_id                object\n",
       "recommended                 bool\n",
       "date              datetime64[ns]\n",
       "product_id_int             int64\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>recommended</th>\n",
       "      <th>date</th>\n",
       "      <th>product_id_int</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>76561198007483075</td>\n",
       "      <td>35140</td>\n",
       "      <td>True</td>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>76561197970402776</td>\n",
       "      <td>707610</td>\n",
       "      <td>True</td>\n",
       "      <td>2017-10-16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>76561198060686749</td>\n",
       "      <td>328100</td>\n",
       "      <td>True</td>\n",
       "      <td>2017-06-23</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>76561198023491401</td>\n",
       "      <td>35140</td>\n",
       "      <td>True</td>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>76561198115331805</td>\n",
       "      <td>35140</td>\n",
       "      <td>True</td>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             user_id product_id  recommended       date  product_id_int\n",
       "0  76561198007483075      35140         True 2018-01-04               0\n",
       "1  76561197970402776     707610         True 2017-10-16               1\n",
       "2  76561198060686749     328100         True 2017-06-23               2\n",
       "3  76561198023491401      35140         True 2018-01-03               0\n",
       "4  76561198115331805      35140         True 2018-01-03               0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "steam_reviews_df_cleaned[\"date\"] = pd.to_datetime(steam_reviews_df_cleaned[\"date\"])\n",
    "display(steam_reviews_df_cleaned.dtypes)\n",
    "display(steam_reviews_df_cleaned.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id_int</th>\n",
       "      <th>recommended</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>76561197960265806</th>\n",
       "      <td>[14313]</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[2017-12-20 00:00:00]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76561197960266010</th>\n",
       "      <td>[9722]</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[2017-11-27 00:00:00]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76561197960266146</th>\n",
       "      <td>[597]</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[2017-11-04 00:00:00]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76561197960266225</th>\n",
       "      <td>[1622]</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[2017-06-07 00:00:00]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76561197960266375</th>\n",
       "      <td>[3716]</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[2017-09-13 00:00:00]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  product_id_int recommended                   date\n",
       "user_id                                                            \n",
       "76561197960265806        [14313]      [True]  [2017-12-20 00:00:00]\n",
       "76561197960266010         [9722]      [True]  [2017-11-27 00:00:00]\n",
       "76561197960266146          [597]      [True]  [2017-11-04 00:00:00]\n",
       "76561197960266225         [1622]      [True]  [2017-06-07 00:00:00]\n",
       "76561197960266375         [3716]      [True]  [2017-09-13 00:00:00]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id_int</th>\n",
       "      <th>recommended</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>76561197960266546</th>\n",
       "      <td>[2678, 2678]</td>\n",
       "      <td>[True, True]</td>\n",
       "      <td>[2016-11-25 00:00:00, 2016-11-25 00:00:00]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76561197960266564</th>\n",
       "      <td>[7259, 7259]</td>\n",
       "      <td>[True, True]</td>\n",
       "      <td>[2016-08-14 00:00:00, 2016-08-14 00:00:00]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76561197960267022</th>\n",
       "      <td>[7779, 13382]</td>\n",
       "      <td>[True, True]</td>\n",
       "      <td>[2015-09-29 00:00:00, 2015-04-16 00:00:00]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76561197960267615</th>\n",
       "      <td>[1428, 2098, 2545, 2643, 2633, 3052, 3150, 3979, 3979, 5255, 5797, 5747, 5884, 6832, 6500, 6956, 7122, 7102, 7352, 7469, 7931, 9757, 9911, 10291, 11006, 11309, 11432, 11736, 12754, 12703, 12755, 13323, 13215, 13544, 14085, 14055]</td>\n",
       "      <td>[True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True]</td>\n",
       "      <td>[2012-11-06 00:00:00, 2011-11-30 00:00:00, 2011-07-16 00:00:00, 2011-11-30 00:00:00, 2012-04-04 00:00:00, 2011-07-06 00:00:00, 2011-11-30 00:00:00, 2010-12-10 00:00:00, 2010-12-10 00:00:00, 2011-11-30 00:00:00, 2010-12-10 00:00:00, 2011-11-30 00:00:00, 2013-01-09 00:00:00, 2011-11-30 00:00:00, 2013-10-30 00:00:00, 2011-11-30 00:00:00, 2011-11-30 00:00:00, 2011-11-30 00:00:00, 2011-11-30 00:00:00, 2011-11-30 00:00:00, 2011-11-30 00:00:00, 2010-12-10 00:00:00, 2011-09-13 00:00:00, 2010-12-10 00:00:00, 2011-11-30 00:00:00, 2012-11-05 00:00:00, 2011-11-30 00:00:00, 2011-07-20 00:00:00, 2012-12-14 00:00:00, 2011-11-30 00:00:00, 2011-11-30 00:00:00, 2010-12-10 00:00:00, 2011-11-30 00:00:00, 2012-07-14 00:00:00, 2011-07-30 00:00:00, 2011-11-30 00:00:00]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76561197960268226</th>\n",
       "      <td>[9485, 13462]</td>\n",
       "      <td>[True, True]</td>\n",
       "      <td>[2015-06-01 00:00:00, 2016-11-28 00:00:00]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                          product_id_int  \\\n",
       "user_id                                                                                                                                                                                                                                                    \n",
       "76561197960266546                                                                                                                                                                                                                           [2678, 2678]   \n",
       "76561197960266564                                                                                                                                                                                                                           [7259, 7259]   \n",
       "76561197960267022                                                                                                                                                                                                                          [7779, 13382]   \n",
       "76561197960267615  [1428, 2098, 2545, 2643, 2633, 3052, 3150, 3979, 3979, 5255, 5797, 5747, 5884, 6832, 6500, 6956, 7122, 7102, 7352, 7469, 7931, 9757, 9911, 10291, 11006, 11309, 11432, 11736, 12754, 12703, 12755, 13323, 13215, 13544, 14085, 14055]   \n",
       "76561197960268226                                                                                                                                                                                                                          [9485, 13462]   \n",
       "\n",
       "                                                                                                                                                                                                                                recommended  \\\n",
       "user_id                                                                                                                                                                                                                                       \n",
       "76561197960266546                                                                                                                                                                                                              [True, True]   \n",
       "76561197960266564                                                                                                                                                                                                              [True, True]   \n",
       "76561197960267022                                                                                                                                                                                                              [True, True]   \n",
       "76561197960267615  [True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True]   \n",
       "76561197960268226                                                                                                                                                                                                              [True, True]   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   date  \n",
       "user_id                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "76561197960266546                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            [2016-11-25 00:00:00, 2016-11-25 00:00:00]  \n",
       "76561197960266564                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            [2016-08-14 00:00:00, 2016-08-14 00:00:00]  \n",
       "76561197960267022                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            [2015-09-29 00:00:00, 2015-04-16 00:00:00]  \n",
       "76561197960267615  [2012-11-06 00:00:00, 2011-11-30 00:00:00, 2011-07-16 00:00:00, 2011-11-30 00:00:00, 2012-04-04 00:00:00, 2011-07-06 00:00:00, 2011-11-30 00:00:00, 2010-12-10 00:00:00, 2010-12-10 00:00:00, 2011-11-30 00:00:00, 2010-12-10 00:00:00, 2011-11-30 00:00:00, 2013-01-09 00:00:00, 2011-11-30 00:00:00, 2013-10-30 00:00:00, 2011-11-30 00:00:00, 2011-11-30 00:00:00, 2011-11-30 00:00:00, 2011-11-30 00:00:00, 2011-11-30 00:00:00, 2011-11-30 00:00:00, 2010-12-10 00:00:00, 2011-09-13 00:00:00, 2010-12-10 00:00:00, 2011-11-30 00:00:00, 2012-11-05 00:00:00, 2011-11-30 00:00:00, 2011-07-20 00:00:00, 2012-12-14 00:00:00, 2011-11-30 00:00:00, 2011-11-30 00:00:00, 2010-12-10 00:00:00, 2011-11-30 00:00:00, 2012-07-14 00:00:00, 2011-07-30 00:00:00, 2011-11-30 00:00:00]  \n",
       "76561197960268226                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            [2015-06-01 00:00:00, 2016-11-28 00:00:00]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "steam_reviews_df_grouped = steam_reviews_df_cleaned.groupby(\"user_id\")[[\"product_id_int\", \"recommended\", \"date\"]].agg(list)\n",
    "display(steam_reviews_df_grouped.head(5))\n",
    "\n",
    "steam_reviews_df_grouped_smaller = steam_reviews_df_grouped[steam_reviews_df_grouped[\"recommended\"].map(len) > 1]\n",
    "display(steam_reviews_df_grouped_smaller.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 581343/581343 [00:00<00:00, 1124139.44it/s]\n"
     ]
    }
   ],
   "source": [
    "dct.clear()\n",
    "steam_reviews_df_grouped_smaller = steam_reviews_df_grouped_smaller.reset_index()\n",
    "steam_reviews_df_grouped_smaller[\"user_id_int\"] = steam_reviews_df_grouped_smaller[\"user_id\"].progress_apply(map_to_consecutive_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(581343, 5)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(1485611, 3)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "904268\n"
     ]
    }
   ],
   "source": [
    "display(steam_reviews_df_grouped_smaller.shape)\n",
    "display(steam_reviews_df_grouped.shape)\n",
    "print(steam_reviews_df_grouped.shape[0] - steam_reviews_df_grouped_smaller.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 581343/581343 [00:00<00:00, 1109179.50it/s]\n",
      "100%|██████████| 581343/581343 [00:00<00:00, 1104963.36it/s]\n",
      "100%|██████████| 581343/581343 [00:01<00:00, 364185.22it/s]\n",
      "100%|██████████| 581343/581343 [00:00<00:00, 1148640.95it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>product_id_int</th>\n",
       "      <th>recommended</th>\n",
       "      <th>date</th>\n",
       "      <th>user_id_int</th>\n",
       "      <th>product_history</th>\n",
       "      <th>product_future</th>\n",
       "      <th>recommended_history</th>\n",
       "      <th>recommended_future</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>76561197960266546</td>\n",
       "      <td>[2678, 2678]</td>\n",
       "      <td>[True, True]</td>\n",
       "      <td>[2016-11-25 00:00:00, 2016-11-25 00:00:00]</td>\n",
       "      <td>0</td>\n",
       "      <td>[2678]</td>\n",
       "      <td>[2678]</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>76561197960266564</td>\n",
       "      <td>[7259, 7259]</td>\n",
       "      <td>[True, True]</td>\n",
       "      <td>[2016-08-14 00:00:00, 2016-08-14 00:00:00]</td>\n",
       "      <td>1</td>\n",
       "      <td>[7259]</td>\n",
       "      <td>[7259]</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>76561197960267022</td>\n",
       "      <td>[7779, 13382]</td>\n",
       "      <td>[True, True]</td>\n",
       "      <td>[2015-09-29 00:00:00, 2015-04-16 00:00:00]</td>\n",
       "      <td>2</td>\n",
       "      <td>[7779]</td>\n",
       "      <td>[13382]</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>76561197960267615</td>\n",
       "      <td>[1428, 2098, 2545, 2643, 2633, 3052, 3150, 3979, 3979, 5255, 5797, 5747, 5884, 6832, 6500, 6956, 7122, 7102, 7352, 7469, 7931, 9757, 9911, 10291, 11006, 11309, 11432, 11736, 12754, 12703, 12755, 13323, 13215, 13544, 14085, 14055]</td>\n",
       "      <td>[True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True]</td>\n",
       "      <td>[2012-11-06 00:00:00, 2011-11-30 00:00:00, 2011-07-16 00:00:00, 2011-11-30 00:00:00, 2012-04-04 00:00:00, 2011-07-06 00:00:00, 2011-11-30 00:00:00, 2010-12-10 00:00:00, 2010-12-10 00:00:00, 2011-11-30 00:00:00, 2010-12-10 00:00:00, 2011-11-30 00:00:00, 2013-01-09 00:00:00, 2011-11-30 00:00:00, 2013-10-30 00:00:00, 2011-11-30 00:00:00, 2011-11-30 00:00:00, 2011-11-30 00:00:00, 2011-11-30 00:00:00, 2011-11-30 00:00:00, 2011-11-30 00:00:00, 2010-12-10 00:00:00, 2011-09-13 00:00:00, 2010-12-10 00:00:00, 2011-11-30 00:00:00, 2012-11-05 00:00:00, 2011-11-30 00:00:00, 2011-07-20 00:00:00, 2012-12-14 00:00:00, 2011-11-30 00:00:00, 2011-11-30 00:00:00, 2010-12-10 00:00:00, 2011-11-30 00:00:00, 2012-07-14 00:00:00, 2011-07-30 00:00:00, 2011-11-30 00:00:00]</td>\n",
       "      <td>3</td>\n",
       "      <td>[1428, 2098, 2545, 2643, 2633, 3052, 3150, 3979, 3979, 5255, 5797, 5747, 5884, 6832, 6500, 6956, 7122, 7102, 7352, 7469, 7931, 9757, 9911, 10291, 11006, 11309, 11432, 11736]</td>\n",
       "      <td>[12754, 12703, 12755, 13323, 13215, 13544, 14085, 14055]</td>\n",
       "      <td>[True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True]</td>\n",
       "      <td>[True, True, True, True, True, True, True, True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>76561197960268226</td>\n",
       "      <td>[9485, 13462]</td>\n",
       "      <td>[True, True]</td>\n",
       "      <td>[2015-06-01 00:00:00, 2016-11-28 00:00:00]</td>\n",
       "      <td>4</td>\n",
       "      <td>[9485]</td>\n",
       "      <td>[13462]</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[True]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             user_id  \\\n",
       "0  76561197960266546   \n",
       "1  76561197960266564   \n",
       "2  76561197960267022   \n",
       "3  76561197960267615   \n",
       "4  76561197960268226   \n",
       "\n",
       "                                                                                                                                                                                                                          product_id_int  \\\n",
       "0                                                                                                                                                                                                                           [2678, 2678]   \n",
       "1                                                                                                                                                                                                                           [7259, 7259]   \n",
       "2                                                                                                                                                                                                                          [7779, 13382]   \n",
       "3  [1428, 2098, 2545, 2643, 2633, 3052, 3150, 3979, 3979, 5255, 5797, 5747, 5884, 6832, 6500, 6956, 7122, 7102, 7352, 7469, 7931, 9757, 9911, 10291, 11006, 11309, 11432, 11736, 12754, 12703, 12755, 13323, 13215, 13544, 14085, 14055]   \n",
       "4                                                                                                                                                                                                                          [9485, 13462]   \n",
       "\n",
       "                                                                                                                                                                                                                recommended  \\\n",
       "0                                                                                                                                                                                                              [True, True]   \n",
       "1                                                                                                                                                                                                              [True, True]   \n",
       "2                                                                                                                                                                                                              [True, True]   \n",
       "3  [True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True]   \n",
       "4                                                                                                                                                                                                              [True, True]   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   date  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            [2016-11-25 00:00:00, 2016-11-25 00:00:00]   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            [2016-08-14 00:00:00, 2016-08-14 00:00:00]   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            [2015-09-29 00:00:00, 2015-04-16 00:00:00]   \n",
       "3  [2012-11-06 00:00:00, 2011-11-30 00:00:00, 2011-07-16 00:00:00, 2011-11-30 00:00:00, 2012-04-04 00:00:00, 2011-07-06 00:00:00, 2011-11-30 00:00:00, 2010-12-10 00:00:00, 2010-12-10 00:00:00, 2011-11-30 00:00:00, 2010-12-10 00:00:00, 2011-11-30 00:00:00, 2013-01-09 00:00:00, 2011-11-30 00:00:00, 2013-10-30 00:00:00, 2011-11-30 00:00:00, 2011-11-30 00:00:00, 2011-11-30 00:00:00, 2011-11-30 00:00:00, 2011-11-30 00:00:00, 2011-11-30 00:00:00, 2010-12-10 00:00:00, 2011-09-13 00:00:00, 2010-12-10 00:00:00, 2011-11-30 00:00:00, 2012-11-05 00:00:00, 2011-11-30 00:00:00, 2011-07-20 00:00:00, 2012-12-14 00:00:00, 2011-11-30 00:00:00, 2011-11-30 00:00:00, 2010-12-10 00:00:00, 2011-11-30 00:00:00, 2012-07-14 00:00:00, 2011-07-30 00:00:00, 2011-11-30 00:00:00]   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            [2015-06-01 00:00:00, 2016-11-28 00:00:00]   \n",
       "\n",
       "   user_id_int  \\\n",
       "0            0   \n",
       "1            1   \n",
       "2            2   \n",
       "3            3   \n",
       "4            4   \n",
       "\n",
       "                                                                                                                                                                 product_history  \\\n",
       "0                                                                                                                                                                         [2678]   \n",
       "1                                                                                                                                                                         [7259]   \n",
       "2                                                                                                                                                                         [7779]   \n",
       "3  [1428, 2098, 2545, 2643, 2633, 3052, 3150, 3979, 3979, 5255, 5797, 5747, 5884, 6832, 6500, 6956, 7122, 7102, 7352, 7469, 7931, 9757, 9911, 10291, 11006, 11309, 11432, 11736]   \n",
       "4                                                                                                                                                                         [9485]   \n",
       "\n",
       "                                             product_future  \\\n",
       "0                                                    [2678]   \n",
       "1                                                    [7259]   \n",
       "2                                                   [13382]   \n",
       "3  [12754, 12703, 12755, 13323, 13215, 13544, 14085, 14055]   \n",
       "4                                                   [13462]   \n",
       "\n",
       "                                                                                                                                                        recommended_history  \\\n",
       "0                                                                                                                                                                    [True]   \n",
       "1                                                                                                                                                                    [True]   \n",
       "2                                                                                                                                                                    [True]   \n",
       "3  [True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True]   \n",
       "4                                                                                                                                                                    [True]   \n",
       "\n",
       "                                 recommended_future  \n",
       "0                                            [True]  \n",
       "1                                            [True]  \n",
       "2                                            [True]  \n",
       "3  [True, True, True, True, True, True, True, True]  \n",
       "4                                            [True]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "def split(items, train_percentage):\n",
    "    train_count = math.floor(len(items) * train_percentage)\n",
    "    return items[0:train_count], items[train_count:]\n",
    "\n",
    "train_percentage = 0.8\n",
    "steam_reviews_df_grouped_smaller[\"product_history\"] = steam_reviews_df_grouped_smaller[\"product_id_int\"].progress_apply(lambda items: split(items, train_percentage)[0])\n",
    "steam_reviews_df_grouped_smaller[\"product_future\"] = steam_reviews_df_grouped_smaller[\"product_id_int\"].progress_apply(lambda items: split(items, train_percentage)[1])\n",
    "steam_reviews_df_grouped_smaller[\"recommended_history\"] = steam_reviews_df_grouped_smaller[\"recommended\"].progress_apply(lambda items: split(items, train_percentage)[0])\n",
    "steam_reviews_df_grouped_smaller[\"recommended_future\"] = steam_reviews_df_grouped_smaller[\"recommended\"].progress_apply(lambda items: split(items, train_percentage)[1])\n",
    "display(steam_reviews_df_grouped_smaller.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2271955"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steam_reviews_df_grouped_smaller[\"recommended\"].map(len).describe()\n",
    "steam_reviews_df_grouped_smaller[\"recommended\"].map(len).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#Create scipy csr matrix\n",
    "def get_sparse_matrix(df, shape, recommended_col=\"recommended_history\", product_col=\"product_history\"):\n",
    "    user_ids = []\n",
    "    product_ids = []\n",
    "    values = []\n",
    "    for _, row in df.iterrows():\n",
    "        products = row[product_col]\n",
    "        user = row['user_id_int']\n",
    "    \n",
    "        recommended = row[recommended_col]\n",
    "        user_ids.extend([user] * len(products))\n",
    "        product_ids.extend(products)\n",
    "        values.extend([2 if recommended[i] else 1 for i in range(len(products))])\n",
    "    #create csr matrix\n",
    "    # values = np.ones(len(user_ids))\n",
    "    matrix = scipy.sparse.csr_matrix((values, (user_ids, product_ids)), shape=shape, dtype=np.int32)\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "steam_reviews_set = steam_reviews_df_grouped_smaller#.head(100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<581343x14513 sparse matrix of type '<class 'numpy.intc'>'\n",
       "\twith 1404885 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape = (steam_reviews_set.shape[0], steam_reviews_df_cleaned['product_id_int'].max() + 1)\n",
    "\n",
    "steam_reviews_set = steam_reviews_set.reset_index()\n",
    "train_matrix_big = get_sparse_matrix(steam_reviews_set, shape)\n",
    "test_matrix_big = get_sparse_matrix(steam_reviews_set, shape, recommended_col=\"recommended_future\", product_col=\"product_future\")\n",
    "train_matrix_big"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<581343x14513 sparse matrix of type '<class 'numpy.intc'>'\n",
       "\twith 708285 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_matrix_big"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train RBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [18:34<00:00, 111.40s/it]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rbm_big_10 = create_rbm(train_matrix_big, test_matrix_big, 1024, 10240, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jolan\\AppData\\Local\\Temp/ipykernel_3944/2706428938.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  recommendations = torch.tensor(indices, device='cpu').tolist()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hr 0.0003738370246083048\n",
      "recall 0.0003738370246083048\n",
      "ndcg 0.00020253310525841176\n"
     ]
    }
   ],
   "source": [
    "print(\"10 epochs\")\n",
    "hr, r, ndcg = compute_hr(train_matrix_big, test_matrix_big, rbm_big_10)\n",
    "print(\"hr\", np.average(hr))\n",
    "print(\"recall\", np.average(r))\n",
    "print(\"ndcg\", np.average(ndcg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Garbage Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [17:45<00:00, 106.58s/it]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rbm_big_10_10000 = create_rbm(train_matrix_big, test_matrix_big, 10000, 10240, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jolan\\AppData\\Local\\Temp/ipykernel_3944/2706428938.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  recommendations = torch.tensor(indices, device='cpu').tolist()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hr 0.0003738370246083048\n",
      "recall 0.0003738370246083048\n",
      "ndcg 0.00020253310525841176\n"
     ]
    }
   ],
   "source": [
    "print(\"10 epochs\")\n",
    "hr, r, ndcg = compute_hr(train_matrix_big, test_matrix_big, rbm_big_10_10000)\n",
    "print(\"hr\", np.average(hr))\n",
    "print(\"recall\", np.average(r))\n",
    "print(\"ndcg\", np.average(ndcg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [6:02:07<00:00, 217.27s/it]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rbm_big_big = create_rbm(train_matrix_big, test_matrix_big, 4096, 4096, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------\n",
      "start training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [24:20<00:00, 146.01s/it]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def score_model(rbm, batch_size):\n",
    "    test_recon_error = 0  # RMSE reconstruction error initialized to 0 at the beginning of training\n",
    "    s = 0  # a counter (float type) \n",
    "    # for loop - go through every single user\n",
    "    for id_user in range(0, user_reviews_df_exploded['user_id_int'].max() + 1 - batch_size, batch_size):\n",
    "        v = train_matrix[id_user:id_user + batch_size]  # training set inputs are used to activate neurons of my RBM\n",
    "        vt = test_matrix[id_user:id_user + batch_size]  # target\n",
    "        # v = convert_sparse_matrix_to_sparse_tensor(training_sample)\n",
    "        # vt = convert_sparse_matrix_to_sparse_tensor(training_sample2)\n",
    "        v = v.todense()\n",
    "        vt = vt.todense()\n",
    "\n",
    "        # v = v.to_dense()\n",
    "        # vt = vt.to_dense()\n",
    "        v = v - 1\n",
    "        vt = vt - 1\n",
    "        v = torch.Tensor(v)\n",
    "        vt = torch.Tensor(vt)\n",
    "        if torch.cuda.is_available():\n",
    "            v = v.cuda()\n",
    "            vt = vt.cuda()\n",
    "        if len(vt[vt > -1]) > 0:\n",
    "            _, h = rbm.sample_h(v)\n",
    "            v, _ = rbm.sample_v(h)\n",
    "\n",
    "            # Update test RMSE reconstruction error\n",
    "            test_recon_error += torch.sqrt(torch.mean((vt[vt > -1] - v[vt > -1])**2)) * len(vt > -1)\n",
    "            s += len(vt > -1) \n",
    "\n",
    "    return test_recon_error / s\n",
    "\n",
    "print('-------')\n",
    "n_vis = shape[1]\n",
    "n_hidden = 2000\n",
    "batch_size = 2048 \n",
    "epochs = 10\n",
    "train_errors = []\n",
    "test_errors = []\n",
    "rbm = RBM(n_vis, n_hidden)\n",
    "\n",
    "# https://stackoverflow.com/questions/40896157/scipy-sparse-csr-matrix-to-tensorflow-sparsetensor-mini-batch-gradient-descent\n",
    "def convert_sparse_matrix_to_sparse_tensor(X):\n",
    "    coo = X.tocoo()\n",
    "\n",
    "    values = coo.data\n",
    "    indices = np.vstack((coo.row, coo.col))\n",
    "\n",
    "    i = torch.LongTensor(indices)\n",
    "    v = torch.FloatTensor(values)\n",
    "    if torch.cuda.is_available():\n",
    "        i = i.cuda()\n",
    "        v = v.cuda()\n",
    "    # print(values)\n",
    "    # print(\"values\", v)\n",
    "    shape = coo.shape\n",
    "    tensor = torch.sparse.FloatTensor(i, v, torch.Size(shape)) \n",
    "    if torch.cuda.is_available():\n",
    "        tensor = tensor.cuda()\n",
    "\n",
    "    return tensor \n",
    "\n",
    "print(\"start training\")\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    rbm.train()\n",
    "    train_recon_error = 0  # RMSE reconstruction error initialized to 0 at the beginning of training\n",
    "    s = 0\n",
    "    \n",
    "    for user_id in range(0, shape[0] - batch_size, batch_size):\n",
    "        training_sample = train_matrix[user_id : user_id + batch_size]\n",
    "        training_sample2 = train_matrix[user_id : user_id + batch_size]\n",
    "        # print(training_sample)\n",
    "        v0 = convert_sparse_matrix_to_sparse_tensor(training_sample)\n",
    "        # print(v0.coalesce().indices())\n",
    "        vk = convert_sparse_matrix_to_sparse_tensor(training_sample2)\n",
    "\n",
    "        v0 = v0.to_dense()\n",
    "        vk = vk.to_dense()\n",
    "        v0 = v0.sub(1)\n",
    "        vk = vk.sub(1)\n",
    "        \n",
    "        ph0, _ = rbm.sample_h(v0)   \n",
    "\n",
    "        # Third for loop - perform contrastive divergence\n",
    "        for k in range(5):\n",
    "            _, hk = rbm.sample_h(vk)\n",
    "            _, vk = rbm.sample_v(hk)\n",
    "\n",
    "            # We don't want to learn when there is no rating by the user, and there is no update when rating = -1\n",
    "            # Remove indices from vk vector that are not in the v0 vector => get sparse tensor again\n",
    "            vk[v0 < 0] = v0[v0 < 0]\n",
    "\n",
    "        phk, _ = rbm.sample_h(vk)\n",
    "        rbm.train_model(v0, vk, ph0, phk)\n",
    "\n",
    "        vk_train, _ = rbm.sample_v(hk)\n",
    "        train_recon_error += torch.sqrt(torch.mean((v0[v0 > -1] - vk_train[v0 > -1])**2)) * len(v0 > -1)\n",
    "        s += len(v0 > -1) \n",
    "        \n",
    "    train_errors.append(train_recon_error / s)\n",
    "\n",
    "    # print('calculating test scores')\n",
    "    # rbm.eval()\n",
    "    # test_errors.append(score_model(rbm)) \n",
    "    rbm.eval()\n",
    "    test_errors.append(score_model(rbm, batch_size))\n",
    "\n",
    "    # print('finished epoch', epoch)    \n",
    "    \n",
    "import matplotlib.pyplot as plt\n",
    "# Plot the RMSE reconstruction error with respect to increasing number of epochs\n",
    "plt.plot(torch.Tensor(train_errors, device='cpu'), label=\"train\")\n",
    "plt.plot(torch.Tensor(test_errors, device='cpu'), label=\"test\")\n",
    "plt.ylabel('Error')\n",
    "plt.xlabel('Epoch')\n",
    "plt.savefig(f'datasubset-{n_hidden}-{batch_size}-{epochs}-test.jpg')\n",
    "\n",
    "# Evaluate the RBM on test set\n",
    "# test_recon_error = score_model(rbm)\n",
    "# print(\"Final error\", test_recon_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hitrate / Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jolan\\AppData\\Local\\Temp/ipykernel_6996/1445240602.py:28: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  recommendations = torch.tensor(indices, device='cpu').tolist()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hr 0.0006022403340426386\n",
      "recall 0.0006022403340426386\n"
     ]
    }
   ],
   "source": [
    "hr, r = compute_hr(rbm)\n",
    "print('hr', np.average(hr))\n",
    "print(\"recall\", np.average(r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(0.7204, device='cuda:0'),\n",
       " tensor(0.6915, device='cuda:0'),\n",
       " tensor(0.6858, device='cuda:0'),\n",
       " tensor(0.6830, device='cuda:0'),\n",
       " tensor(0.6813, device='cuda:0'),\n",
       " tensor(0.6801, device='cuda:0'),\n",
       " tensor(0.6792, device='cuda:0'),\n",
       " tensor(0.6786, device='cuda:0'),\n",
       " tensor(0.6781, device='cuda:0'),\n",
       " tensor(0.6777, device='cuda:0'),\n",
       " tensor(0.6773, device='cuda:0'),\n",
       " tensor(0.6770, device='cuda:0'),\n",
       " tensor(0.6768, device='cuda:0'),\n",
       " tensor(0.6765, device='cuda:0'),\n",
       " tensor(0.6764, device='cuda:0'),\n",
       " tensor(0.6762, device='cuda:0'),\n",
       " tensor(0.6760, device='cuda:0'),\n",
       " tensor(0.6759, device='cuda:0'),\n",
       " tensor(0.6758, device='cuda:0'),\n",
       " tensor(0.6757, device='cuda:0'),\n",
       " tensor(0.6756, device='cuda:0'),\n",
       " tensor(0.6755, device='cuda:0'),\n",
       " tensor(0.6754, device='cuda:0'),\n",
       " tensor(0.6753, device='cuda:0'),\n",
       " tensor(0.6753, device='cuda:0'),\n",
       " tensor(0.6752, device='cuda:0'),\n",
       " tensor(0.6751, device='cuda:0'),\n",
       " tensor(0.6751, device='cuda:0'),\n",
       " tensor(0.6750, device='cuda:0'),\n",
       " tensor(0.6750, device='cuda:0'),\n",
       " tensor(0.6749, device='cuda:0'),\n",
       " tensor(0.6749, device='cuda:0'),\n",
       " tensor(0.6748, device='cuda:0'),\n",
       " tensor(0.6748, device='cuda:0'),\n",
       " tensor(0.6748, device='cuda:0'),\n",
       " tensor(0.6747, device='cuda:0'),\n",
       " tensor(0.6747, device='cuda:0'),\n",
       " tensor(0.6747, device='cuda:0'),\n",
       " tensor(0.6746, device='cuda:0'),\n",
       " tensor(0.6746, device='cuda:0'),\n",
       " tensor(0.6746, device='cuda:0'),\n",
       " tensor(0.6746, device='cuda:0'),\n",
       " tensor(0.6745, device='cuda:0'),\n",
       " tensor(0.6745, device='cuda:0'),\n",
       " tensor(0.6745, device='cuda:0'),\n",
       " tensor(0.6745, device='cuda:0'),\n",
       " tensor(0.6745, device='cuda:0'),\n",
       " tensor(0.6744, device='cuda:0'),\n",
       " tensor(0.6744, device='cuda:0'),\n",
       " tensor(0.6744, device='cuda:0')]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[tensor(0.4664, device='cuda:0'),\n",
       " tensor(0.4493, device='cuda:0'),\n",
       " tensor(0.4414, device='cuda:0'),\n",
       " tensor(0.4365, device='cuda:0'),\n",
       " tensor(0.4331, device='cuda:0'),\n",
       " tensor(0.4305, device='cuda:0'),\n",
       " tensor(0.4285, device='cuda:0'),\n",
       " tensor(0.4268, device='cuda:0'),\n",
       " tensor(0.4255, device='cuda:0'),\n",
       " tensor(0.4243, device='cuda:0'),\n",
       " tensor(0.4234, device='cuda:0'),\n",
       " tensor(0.4225, device='cuda:0'),\n",
       " tensor(0.4218, device='cuda:0'),\n",
       " tensor(0.4211, device='cuda:0'),\n",
       " tensor(0.4205, device='cuda:0'),\n",
       " tensor(0.4200, device='cuda:0'),\n",
       " tensor(0.4195, device='cuda:0'),\n",
       " tensor(0.4190, device='cuda:0'),\n",
       " tensor(0.4186, device='cuda:0'),\n",
       " tensor(0.4182, device='cuda:0'),\n",
       " tensor(0.4179, device='cuda:0'),\n",
       " tensor(0.4176, device='cuda:0'),\n",
       " tensor(0.4173, device='cuda:0'),\n",
       " tensor(0.4170, device='cuda:0'),\n",
       " tensor(0.4168, device='cuda:0'),\n",
       " tensor(0.4165, device='cuda:0'),\n",
       " tensor(0.4163, device='cuda:0'),\n",
       " tensor(0.4161, device='cuda:0'),\n",
       " tensor(0.4159, device='cuda:0'),\n",
       " tensor(0.4157, device='cuda:0'),\n",
       " tensor(0.4155, device='cuda:0'),\n",
       " tensor(0.4154, device='cuda:0'),\n",
       " tensor(0.4152, device='cuda:0'),\n",
       " tensor(0.4150, device='cuda:0'),\n",
       " tensor(0.4149, device='cuda:0'),\n",
       " tensor(0.4148, device='cuda:0'),\n",
       " tensor(0.4146, device='cuda:0'),\n",
       " tensor(0.4145, device='cuda:0'),\n",
       " tensor(0.4144, device='cuda:0'),\n",
       " tensor(0.4143, device='cuda:0'),\n",
       " tensor(0.4142, device='cuda:0'),\n",
       " tensor(0.4141, device='cuda:0'),\n",
       " tensor(0.4140, device='cuda:0'),\n",
       " tensor(0.4139, device='cuda:0'),\n",
       " tensor(0.4138, device='cuda:0'),\n",
       " tensor(0.4137, device='cuda:0'),\n",
       " tensor(0.4136, device='cuda:0'),\n",
       " tensor(0.4135, device='cuda:0'),\n",
       " tensor(0.4135, device='cuda:0'),\n",
       " tensor(0.4134, device='cuda:0')]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(train_errors)\n",
    "display(test_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76561198037833890    1\n",
       "76561197992194309    1\n",
       "76561198043292775    1\n",
       "76561198030442121    1\n",
       "76561197963870074    1\n",
       "                    ..\n",
       "76561198345086561    1\n",
       "76561198054491833    1\n",
       "76561198095690287    1\n",
       "76561198301658414    1\n",
       "76561198089897928    1\n",
       "Name: user_id, Length: 904268, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "76561198011965365    1254\n",
       "76561198094803808     900\n",
       "76561197969749884     750\n",
       "76561198094321628     669\n",
       "76561198073092169     549\n",
       "                     ... \n",
       "76561198098554655       2\n",
       "76561198044342349       2\n",
       "76561198122784122       2\n",
       "76561198076341138       2\n",
       "76561198102545130       2\n",
       "Name: user_id, Length: 581343, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "76561198011965365    1254\n",
       "76561198094803808     900\n",
       "76561197969749884     750\n",
       "76561198094321628     669\n",
       "76561198073092169     549\n",
       "                     ... \n",
       "76561198345086561       1\n",
       "76561198054491833       1\n",
       "76561198095690287       1\n",
       "76561198301658414       1\n",
       "76561198089897928       1\n",
       "Name: user_id, Length: 1485611, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "s = steam_reviews_df_small[\"user_id\"].value_counts(dropna=False)\n",
    "display(s.loc[s < 2])\n",
    "display(s.loc[s >= 2])\n",
    "display(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(0.4664, device='cuda:0'),\n",
       " tensor(0.4493, device='cuda:0'),\n",
       " tensor(0.4414, device='cuda:0'),\n",
       " tensor(0.4365, device='cuda:0'),\n",
       " tensor(0.4331, device='cuda:0'),\n",
       " tensor(0.4305, device='cuda:0'),\n",
       " tensor(0.4285, device='cuda:0'),\n",
       " tensor(0.4268, device='cuda:0'),\n",
       " tensor(0.4255, device='cuda:0'),\n",
       " tensor(0.4243, device='cuda:0'),\n",
       " tensor(0.4234, device='cuda:0'),\n",
       " tensor(0.4225, device='cuda:0'),\n",
       " tensor(0.4218, device='cuda:0'),\n",
       " tensor(0.4211, device='cuda:0'),\n",
       " tensor(0.4205, device='cuda:0'),\n",
       " tensor(0.4200, device='cuda:0'),\n",
       " tensor(0.4195, device='cuda:0'),\n",
       " tensor(0.4190, device='cuda:0'),\n",
       " tensor(0.4186, device='cuda:0'),\n",
       " tensor(0.4182, device='cuda:0'),\n",
       " tensor(0.4179, device='cuda:0'),\n",
       " tensor(0.4176, device='cuda:0'),\n",
       " tensor(0.4173, device='cuda:0'),\n",
       " tensor(0.4170, device='cuda:0'),\n",
       " tensor(0.4168, device='cuda:0'),\n",
       " tensor(0.4165, device='cuda:0'),\n",
       " tensor(0.4163, device='cuda:0'),\n",
       " tensor(0.4161, device='cuda:0'),\n",
       " tensor(0.4159, device='cuda:0'),\n",
       " tensor(0.4157, device='cuda:0'),\n",
       " tensor(0.4155, device='cuda:0'),\n",
       " tensor(0.4154, device='cuda:0'),\n",
       " tensor(0.4152, device='cuda:0'),\n",
       " tensor(0.4150, device='cuda:0'),\n",
       " tensor(0.4149, device='cuda:0'),\n",
       " tensor(0.4148, device='cuda:0'),\n",
       " tensor(0.4146, device='cuda:0'),\n",
       " tensor(0.4145, device='cuda:0'),\n",
       " tensor(0.4144, device='cuda:0'),\n",
       " tensor(0.4143, device='cuda:0'),\n",
       " tensor(0.4142, device='cuda:0'),\n",
       " tensor(0.4141, device='cuda:0'),\n",
       " tensor(0.4140, device='cuda:0'),\n",
       " tensor(0.4139, device='cuda:0'),\n",
       " tensor(0.4138, device='cuda:0'),\n",
       " tensor(0.4137, device='cuda:0'),\n",
       " tensor(0.4136, device='cuda:0'),\n",
       " tensor(0.4135, device='cuda:0'),\n",
       " tensor(0.4135, device='cuda:0'),\n",
       " tensor(0.4134, device='cuda:0')]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ac59ebe37160ed0dfa835113d9b8498d9f09ceb179beaac4002f036b9467c963"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

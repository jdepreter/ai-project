{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Restricted Boltzmann Machine Defintion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# TODO g = 1 + ap of g = ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Import PyTorch library\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "device = torch.device('cpu')\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# https://github.com/khanhnamle1994/MetaRec/blob/b5e36cb579a88b32cdfb728f35f645d76b24ad95/Boltzmann-Machines-Experiments/RBM-CF-PyTorch/rbm.py#L23\n",
    "# Create the Restricted Boltzmann Machine architecture\n",
    "class RBM(nn.Module):\n",
    "    def __init__(self, n_vis, n_hid, k, batch_size):\n",
    "        \"\"\"\n",
    "        Initialize the parameters (weights and biases) we optimize during the training process\n",
    "        :param n_vis: number of visible units\n",
    "        :param n_hid: number of hidden units\n",
    "        \"\"\"\n",
    "        self.i = 0\n",
    "        self.K = k\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        # Weights used for the probability of the visible units given the hidden units\n",
    "        super().__init__()\n",
    "        self.W = torch.zeros(k, n_hid, n_vis)  # torch.rand: random normal distribution mean = 0, variance = 1\n",
    "\n",
    "        # Bias probability of the visible units is activated, given the value of the hidden units (p_v_given_h)\n",
    "        self.v_bias = torch.zeros(k, 1, n_vis)  # fake dimension for the batch = 1\n",
    "\n",
    "        # Bias probability of the hidden units is activated, given the value of the visible units (p_h_given_v)\n",
    "        self.h_bias = torch.zeros(1, n_hid)  # fake dimension for the batch = 1\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            self.W = self.W.cuda()\n",
    "            self.v_bias = self.v_bias.cuda()\n",
    "            self.h_bias = self.h_bias.cuda()\n",
    "    \n",
    "    def lr(self):\n",
    "        return 0.01 / self.batch_size\n",
    "\n",
    "    def sample_h(self, x):\n",
    "        \"\"\"\n",
    "        Sample the hidden units\n",
    "        :param x: the dataset\n",
    "        \"\"\"\n",
    "\n",
    "        # Probability h is activated given that the value v is sigmoid(Wx + a)\n",
    "        # torch.mm make the product of 2 tensors\n",
    "        # W.t() take the transpose because W is used for the p_v_given_h\n",
    "\n",
    "        temp = torch.transpose(self.W, 1, 2)\n",
    "\n",
    "        wxs = []\n",
    "        for i in range(self.K):\n",
    "            wxs.append(torch.mm(x[i], temp[i]))\n",
    "            \n",
    "        wx = torch.stack(wxs)\n",
    "        # wx = torch.bmm(x.cpu(), temp.cpu())\n",
    "        # if torch.cuda.is_available():\n",
    "            # wx = wx.cuda()\n",
    "        wx_sum = torch.sum(wx, 0)\n",
    "        # print(wx.shape)\n",
    "\n",
    "        # Expand the mini-batch\n",
    "        activation = wx_sum + self.h_bias.expand_as(wx_sum)\n",
    "        # print(activation.shape)\n",
    "\n",
    "        # Calculate the probability p_h_given_v\n",
    "        p_h_given_v = torch.sigmoid(activation)\n",
    "\n",
    "        # print(\"h sparse\", p_h_given_v.is_sparse, torch.bernoulli(p_h_given_v).is_sparse)\n",
    "\n",
    "        # Construct a Bernoulli RBM to predict whether an user loves the movie or not (0 or 1)\n",
    "        # This corresponds to whether the n_hid is activated or not activated\n",
    "        return p_h_given_v, torch.bernoulli(p_h_given_v)\n",
    "\n",
    "    def sample_v(self, y):\n",
    "        \"\"\"\n",
    "        Sample the visible units\n",
    "        :param y: the dataset\n",
    "        \"\"\"\n",
    "        # print(y.mean(), y.min(), y.max())\n",
    "\n",
    "        exponents = []\n",
    "        for k in range(self.K):\n",
    "            wy = torch.mm(y, self.W[k])\n",
    "            activation = wy + self.v_bias[k].expand_as(wy)\n",
    "            exponents.append(torch.exp(activation))\n",
    "\n",
    "        exponent_tensor = torch.stack(exponents)\n",
    "        exponent_sum = torch.sum(exponent_tensor, 0)\n",
    "        probs = []\n",
    "        for k in range(self.K):\n",
    "            p_v_k_given_h = exponent_tensor[k] / exponent_sum\n",
    "            # print(p_v_k_given_h.mean(), p_v_k_given_h.min(), p_v_k_given_h.max())\n",
    "            probs.append(p_v_k_given_h)\n",
    "\n",
    "        p_v_given_h = torch.stack(probs)\n",
    "        # try:\n",
    "        # print(p_v_given_h.mean(), p_v_given_h.max(), p_v_given_h.min())\n",
    "        # todo multinomial\n",
    "        bern = torch.bernoulli(p_v_given_h)\n",
    "        # if self.i == 0:\n",
    "        #     print(p_v_given_h[0][0][0])\n",
    "        #     print(p_v_given_h[0][0].min(), p_v_given_h[0][0].max())\n",
    "        return p_v_given_h, bern\n",
    "        # except Exception as e:\n",
    "            # raise Exception(\"bernoulli kapot\")\n",
    "\n",
    "\n",
    "    def train_model(self, v0, vk, ph0, phk):\n",
    "        \"\"\"\n",
    "        Perform contrastive divergence algorithm to optimize the weights that minimize the energy\n",
    "        This maximizes the log-likelihood of the model\n",
    "        \"\"\"\n",
    "\n",
    "        ph0_K = torch.stack([ph0 for _ in range(self.K)])\n",
    "        phk_K = torch.stack([phk for _ in range(self.K)])\n",
    "\n",
    "        poss = []\n",
    "        negs = []\n",
    "        for i in range(self.K):\n",
    "            poss.append(torch.mm(torch.transpose(v0, 1, 2)[i], ph0_K[i]))\n",
    "            negs.append(torch.mm(torch.transpose(vk, 1, 2)[i], phk_K[i]))\n",
    "\n",
    "        pos = torch.stack(poss)\n",
    "        neg = torch.stack(negs)\n",
    "\n",
    "        # pos = torch.bmm(torch.transpose(v0, 1, 2).cpu(), ph0_K.cpu())\n",
    "        # neg = torch.bmm(torch.transpose(vk, 1, 2).cpu(), phk_K.cpu())\n",
    "        # if torch.cuda.is_available():\n",
    "        #     pos = pos.cuda()\n",
    "        #     neg = neg.cuda()\n",
    "\n",
    "        w_extra = torch.transpose(pos - neg, 1, 2)\n",
    "        v_extra = torch.sum((v0 - vk), 1)\n",
    "        h_extra = torch.sum((ph0 - phk), 0)\n",
    "\n",
    "        # if self.i % 45 == 0:\n",
    "            # print(torch.max(w_extra), torch.max(v_extra), torch.max(h_extra), flush=True)\n",
    "\n",
    "        # Approximate the gradients with the CD algorithm\n",
    "        # TODO learning rate toevoegen\n",
    "        self.W += self.lr() * w_extra\n",
    "\n",
    "        # Add (difference, 0) for the tensor of 2 dimensions\n",
    "        self.v_bias += self.lr() * v_extra.unsqueeze(1)\n",
    "        self.h_bias += self.lr() * h_extra\n",
    "        self.i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "cuda = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle as pickle\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "import gzip\n",
    "import json\n",
    "from tqdm import tqdm, trange\n",
    "import os\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "import math\n",
    "tqdm.pandas() #for progres_apply etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_interactions(path, n_splits=5):\n",
    "    df = pd.read_pickle(os.path.join(os.getcwd(), path))\n",
    "    df[['interactions', 'train', 'val', 'test']] = df[['interactions', 'train', 'val', 'test']].applymap(lambda x: np.array(x, dtype=np.int32))\n",
    "    interactions_dict = {}\n",
    "    for split in trange(n_splits):\n",
    "        for column in ['train', 'val', 'test']:\n",
    "            interactions_dict[split, column] = pd.DataFrame({\n",
    "                'user_id': df['user_id'],\n",
    "                'steam_id': df['steam_id'],\n",
    "                'item_id': df[column].apply(lambda x: x[split, 0]),\n",
    "                'playtime_forever': df[column].apply(lambda x: x[split, 1]),\n",
    "                'playtime_2weeks': df[column].apply(lambda x: x[split, 2])})\n",
    "    return interactions_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00,  7.24it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>steam_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>playtime_forever</th>\n",
       "      <th>playtime_2weeks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>76561197981203305</td>\n",
       "      <td>76561197981203305</td>\n",
       "      <td>[3485, 2370, 163, 2188, 2484, 2130, 3197, 413,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bosslucek</td>\n",
       "      <td>76561198029968002</td>\n",
       "      <td>[470, 3223, 1912, 4349, 2249, 380, 3860, 1483,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>76561198067911521</td>\n",
       "      <td>76561198067911521</td>\n",
       "      <td>[173, 139, 2088, 2132, 285, 352, 678, 521, 798...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>icantwait</td>\n",
       "      <td>76561197971666535</td>\n",
       "      <td>[206, 299, 354, 1125, 2196, 2839, 1752, 1410, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kushziller</td>\n",
       "      <td>76561198021307778</td>\n",
       "      <td>[417, 1897, 4786, 840, 1637, 3957, 926, 505, 4...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             user_id           steam_id  \\\n",
       "0  76561197981203305  76561197981203305   \n",
       "1          bosslucek  76561198029968002   \n",
       "2  76561198067911521  76561198067911521   \n",
       "3          icantwait  76561197971666535   \n",
       "4         kushziller  76561198021307778   \n",
       "\n",
       "                                             item_id  \\\n",
       "0  [3485, 2370, 163, 2188, 2484, 2130, 3197, 413,...   \n",
       "1  [470, 3223, 1912, 4349, 2249, 380, 3860, 1483,...   \n",
       "2  [173, 139, 2088, 2132, 285, 352, 678, 521, 798...   \n",
       "3  [206, 299, 354, 1125, 2196, 2839, 1752, 1410, ...   \n",
       "4  [417, 1897, 4786, 840, 1637, 3957, 926, 505, 4...   \n",
       "\n",
       "                                    playtime_forever  \\\n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                     playtime_2weeks  \n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interactions = load_interactions(\"./data-cleaned/interactions_splits.pkl.gz\")\n",
    "interactions[0, 'train'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>publisher</th>\n",
       "      <th>genres</th>\n",
       "      <th>app_name</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>release_date</th>\n",
       "      <th>tags</th>\n",
       "      <th>discount_price</th>\n",
       "      <th>reviews_url</th>\n",
       "      <th>specs</th>\n",
       "      <th>price</th>\n",
       "      <th>early_access</th>\n",
       "      <th>id</th>\n",
       "      <th>developer</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>metascore</th>\n",
       "      <th>users_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Valve</td>\n",
       "      <td>[Action]</td>\n",
       "      <td>Counter-Strike: Global Offensive</td>\n",
       "      <td>Counter-Strike: Global Offensive</td>\n",
       "      <td>http://store.steampowered.com/app/730/CounterS...</td>\n",
       "      <td>2012-08-21</td>\n",
       "      <td>[FPS, Multiplayer, Shooter, Action, Team-Based...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://steamcommunity.com/app/730/reviews/?bro...</td>\n",
       "      <td>[Multi-player, Steam Achievements, Full contro...</td>\n",
       "      <td>14.99</td>\n",
       "      <td>False</td>\n",
       "      <td>730</td>\n",
       "      <td>Valve</td>\n",
       "      <td>Very Positive</td>\n",
       "      <td>83</td>\n",
       "      <td>42618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Valve</td>\n",
       "      <td>[Indie, Simulation]</td>\n",
       "      <td>Garry's Mod</td>\n",
       "      <td>Garry's Mod</td>\n",
       "      <td>http://store.steampowered.com/app/4000/Garrys_...</td>\n",
       "      <td>2006-11-29</td>\n",
       "      <td>[Sandbox, Multiplayer, Funny, Moddable, Buildi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://steamcommunity.com/app/4000/reviews/?br...</td>\n",
       "      <td>[Single-player, Multi-player, Co-op, Cross-Pla...</td>\n",
       "      <td>9.99</td>\n",
       "      <td>False</td>\n",
       "      <td>4000</td>\n",
       "      <td>Facepunch Studios</td>\n",
       "      <td>Overwhelmingly Positive</td>\n",
       "      <td>NA</td>\n",
       "      <td>42156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Smartly Dressed Games</td>\n",
       "      <td>[Action, Adventure, Casual, Free to Play, Indie]</td>\n",
       "      <td>Unturned</td>\n",
       "      <td>Unturned</td>\n",
       "      <td>http://store.steampowered.com/app/304930/Untur...</td>\n",
       "      <td>2017-07-07</td>\n",
       "      <td>[Free to Play, Survival, Zombies, Multiplayer,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://steamcommunity.com/app/304930/reviews/?...</td>\n",
       "      <td>[Single-player, Online Multi-Player, Online Co...</td>\n",
       "      <td>Free to Play</td>\n",
       "      <td>False</td>\n",
       "      <td>304930</td>\n",
       "      <td>Smartly Dressed Games</td>\n",
       "      <td>Very Positive</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Valve</td>\n",
       "      <td>[Action]</td>\n",
       "      <td>Left 4 Dead 2</td>\n",
       "      <td>Left 4 Dead 2</td>\n",
       "      <td>http://store.steampowered.com/app/550/Left_4_D...</td>\n",
       "      <td>2009-11-16</td>\n",
       "      <td>[Zombies, Co-op, FPS, Multiplayer, Action, Onl...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://steamcommunity.com/app/550/reviews/?bro...</td>\n",
       "      <td>[Single-player, Multi-player, Co-op, Steam Ach...</td>\n",
       "      <td>19.99</td>\n",
       "      <td>False</td>\n",
       "      <td>550</td>\n",
       "      <td>Valve</td>\n",
       "      <td>Overwhelmingly Positive</td>\n",
       "      <td>89</td>\n",
       "      <td>35986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Re-Logic</td>\n",
       "      <td>[Action, Adventure, Indie, RPG]</td>\n",
       "      <td>Terraria</td>\n",
       "      <td>Terraria</td>\n",
       "      <td>http://store.steampowered.com/app/105600/Terra...</td>\n",
       "      <td>2011-05-16</td>\n",
       "      <td>[Sandbox, Adventure, Survival, 2D, Multiplayer...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://steamcommunity.com/app/105600/reviews/?...</td>\n",
       "      <td>[Single-player, Multi-player, Online Multi-Pla...</td>\n",
       "      <td>9.99</td>\n",
       "      <td>False</td>\n",
       "      <td>105600</td>\n",
       "      <td>Re-Logic</td>\n",
       "      <td>Overwhelmingly Positive</td>\n",
       "      <td>83</td>\n",
       "      <td>28551</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               publisher                                            genres  \\\n",
       "0                  Valve                                          [Action]   \n",
       "1                  Valve                               [Indie, Simulation]   \n",
       "2  Smartly Dressed Games  [Action, Adventure, Casual, Free to Play, Indie]   \n",
       "3                  Valve                                          [Action]   \n",
       "4               Re-Logic                   [Action, Adventure, Indie, RPG]   \n",
       "\n",
       "                           app_name                             title  \\\n",
       "0  Counter-Strike: Global Offensive  Counter-Strike: Global Offensive   \n",
       "1                       Garry's Mod                       Garry's Mod   \n",
       "2                          Unturned                          Unturned   \n",
       "3                     Left 4 Dead 2                     Left 4 Dead 2   \n",
       "4                          Terraria                          Terraria   \n",
       "\n",
       "                                                 url release_date  \\\n",
       "0  http://store.steampowered.com/app/730/CounterS...   2012-08-21   \n",
       "1  http://store.steampowered.com/app/4000/Garrys_...   2006-11-29   \n",
       "2  http://store.steampowered.com/app/304930/Untur...   2017-07-07   \n",
       "3  http://store.steampowered.com/app/550/Left_4_D...   2009-11-16   \n",
       "4  http://store.steampowered.com/app/105600/Terra...   2011-05-16   \n",
       "\n",
       "                                                tags  discount_price  \\\n",
       "0  [FPS, Multiplayer, Shooter, Action, Team-Based...             NaN   \n",
       "1  [Sandbox, Multiplayer, Funny, Moddable, Buildi...             NaN   \n",
       "2  [Free to Play, Survival, Zombies, Multiplayer,...             NaN   \n",
       "3  [Zombies, Co-op, FPS, Multiplayer, Action, Onl...             NaN   \n",
       "4  [Sandbox, Adventure, Survival, 2D, Multiplayer...             NaN   \n",
       "\n",
       "                                         reviews_url  \\\n",
       "0  http://steamcommunity.com/app/730/reviews/?bro...   \n",
       "1  http://steamcommunity.com/app/4000/reviews/?br...   \n",
       "2  http://steamcommunity.com/app/304930/reviews/?...   \n",
       "3  http://steamcommunity.com/app/550/reviews/?bro...   \n",
       "4  http://steamcommunity.com/app/105600/reviews/?...   \n",
       "\n",
       "                                               specs         price  \\\n",
       "0  [Multi-player, Steam Achievements, Full contro...         14.99   \n",
       "1  [Single-player, Multi-player, Co-op, Cross-Pla...          9.99   \n",
       "2  [Single-player, Online Multi-Player, Online Co...  Free to Play   \n",
       "3  [Single-player, Multi-player, Co-op, Steam Ach...         19.99   \n",
       "4  [Single-player, Multi-player, Online Multi-Pla...          9.99   \n",
       "\n",
       "   early_access      id              developer                sentiment  \\\n",
       "0         False     730                  Valve            Very Positive   \n",
       "1         False    4000      Facepunch Studios  Overwhelmingly Positive   \n",
       "2         False  304930  Smartly Dressed Games            Very Positive   \n",
       "3         False     550                  Valve  Overwhelmingly Positive   \n",
       "4         False  105600               Re-Logic  Overwhelmingly Positive   \n",
       "\n",
       "  metascore  users_count  \n",
       "0        83        42618  \n",
       "1        NA        42156  \n",
       "2       NaN        37654  \n",
       "3        89        35986  \n",
       "4        83        28551  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "games = pd.read_pickle(os.path.join(os.getcwd(), \"./data-cleaned/games.pkl.gz\"))\n",
    "games.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# with open(\"stijn-data/item_dct.p\", \"rb\") as f:\n",
    "#     item_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# def parse_csv(filename):\n",
    "#     df_string = pd.read_csv(filename, index_col=0)\n",
    "#     df = df_string.loc[:,:]\n",
    "#     df[\"item_id\"] = df[\"item_id\"].apply(eval)\n",
    "#     df[\"playtime_forever\"] = df[\"playtime_forever\"].apply(eval)\n",
    "#     df[\"playtime_2weeks\"] = df[\"playtime_2weeks\"].apply(eval)\n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# train0 = parse_csv(\"stijn-data/train_split_0.csv\")\n",
    "# test0 = parse_csv(\"stijn-data/test_split_0.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train0 = interactions[0, 'train']\n",
    "test0 = interactions[0, 'test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    62970.000000\n",
       "mean        34.222106\n",
       "std         45.688536\n",
       "min          1.000000\n",
       "25%          9.000000\n",
       "50%         21.000000\n",
       "75%         42.000000\n",
       "max        713.000000\n",
       "Name: item_id, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train0[\"item_id\"].map(len).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id                                                        fobbsy\n",
       "steam_id                                            76561198014263581\n",
       "item_id             [398, 1403, 1738, 1530, 238, 878, 37, 944, 428...\n",
       "playtime_forever    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "playtime_2weeks     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "Name: 100, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train0.iloc[100,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sparse Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Sparse Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def score_playtime(playtime):\n",
    "    if playtime < 120:\n",
    "        # less than 2 hrs\n",
    "        return 0\n",
    "    elif playtime < 240:\n",
    "        # less than 4 hrs\n",
    "        return 1\n",
    "    elif playtime < 600:\n",
    "        # less than 10 hrs\n",
    "        return 2\n",
    "    elif playtime < 24*60:\n",
    "        # less than 24 hrs\n",
    "        return 3\n",
    "    else:\n",
    "        return 4\n",
    "\n",
    "#Create scipy csr matrix\n",
    "def get_sparse_matrix(df):\n",
    "    shape = (df.shape[0], games.shape[0])\n",
    "    \n",
    "    user_ids = []\n",
    "    item_ids = []\n",
    "    values = []\n",
    "    for idx, row in df.iterrows():\n",
    "        user = idx\n",
    "        items = row['item_id']\n",
    "        score = row[\"playtime_forever\"] + 2* row[\"playtime_2weeks\"]\n",
    "        # print(score)\n",
    "        \n",
    "        # recommended = row['recommended']\n",
    "        user_ids.extend([user] * len(items))\n",
    "        item_ids.extend(items)\n",
    "        values.extend([score_playtime(score[i]) for i in range(len(items))])\n",
    "    # create csr matrix\n",
    "    # values = np.ones(len(user_ids))\n",
    "    matrix = scipy.sparse.csr_matrix((values, (user_ids, item_ids)), shape=shape, dtype=np.int32)\n",
    "    return matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<62970x7350 sparse matrix of type '<class 'numpy.intc'>'\n",
       "\twith 2154966 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_matrix = get_sparse_matrix(test0)\n",
    "\n",
    "train_matrix = get_sparse_matrix(train0)\n",
    "train_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def score_model(rbm: RBM, batch_size, train_matrix, test_matrix):\n",
    "    test_recon_error = 0  # RMSE reconstruction error initialized to 0 at the beginning of training\n",
    "    s = 0  # a counter (float type) \n",
    "    # for loop - go through every single user\n",
    "    for id_user in range(0, train_matrix.shape[0] - batch_size, batch_size):\n",
    "        v = train_matrix[id_user:id_user + batch_size]  # training set inputs are used to activate neurons of my RBM\n",
    "        vt = test_matrix[id_user:id_user + batch_size]  # target\n",
    "        v = convert_sparse_matrix_to_sparse_tensor(v)\n",
    "        vt = convert_sparse_matrix_to_sparse_tensor(vt)\n",
    "\n",
    "        v = v.to_dense()\n",
    "        vt = vt.to_dense()\n",
    "        v = v.sub(1)\n",
    "        vt = vt.sub(1)\n",
    "        if torch.cuda.is_available():\n",
    "            v = v.cuda()\n",
    "            vt = vt.cuda()\n",
    "\n",
    "        if len(vt[vt > -1]) > 0:\n",
    "            _, h = rbm.sample_h(v)\n",
    "            _, v = rbm.sample_v(h)\n",
    "\n",
    "            # Update test RMSE reconstruction error\n",
    "            test_recon_error += torch.mean((vt[vt > -1] - v[vt > -1])**2) * len(vt > -1) \n",
    "            s += len(vt > -1)\n",
    "\n",
    "    return torch.sqrt(test_recon_error / s)\n",
    "\n",
    "\n",
    "# https://stackoverflow.com/questions/40896157/scipy-sparse-csr-matrix-to-tensorflow-sparsetensor-mini-batch-gradient-descent\n",
    "def convert_sparse_matrix_to_sparse_tensor(X, k=5):\n",
    "    coo = X.tocoo()\n",
    "\n",
    "    values = coo.data\n",
    "    indices = np.vstack((coo.row, coo.col))\n",
    "    i = torch.LongTensor(indices)\n",
    "    v = torch.DoubleTensor(values)\n",
    "    tensor_list = []\n",
    "\n",
    "    for index in range(k):\n",
    "        value = index\n",
    "        yeet = torch.where(v == value, 2., 1.)\n",
    "        shape = coo.shape\n",
    "        tensor = torch.sparse.DoubleTensor(i, yeet, torch.Size(shape)) \n",
    "        if torch.cuda.is_available():\n",
    "            tensor = tensor.cuda()\n",
    "\n",
    "        tensor_list.append(tensor)\n",
    "\n",
    "    tensor = torch.stack(tensor_list) \n",
    "    return tensor\n",
    "\n",
    "def create_rbm(train_matrix, test_matrix, n_hidden, batch_size, epochs, rbm=None, k=5, train_errors=[], test_errors=[]) -> RBM:\n",
    "    n_vis = train_matrix.shape[1]\n",
    "    if rbm is None:\n",
    "        rbm = RBM(n_vis, n_hidden, k, batch_size)\n",
    "\n",
    "    print(\"start training\")\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        rbm.train()\n",
    "        train_recon_error = 0  # RMSE reconstruction error initialized to 0 at the beginning of training\n",
    "        s = 0\n",
    "        \n",
    "        for user_id in range(0, train_matrix.shape[0] - batch_size, batch_size):\n",
    "            training_sample = train_matrix[user_id : user_id + batch_size]\n",
    "            v0 = convert_sparse_matrix_to_sparse_tensor(training_sample)\n",
    "\n",
    "            v0 = v0.to_dense()\n",
    "            v0 = v0.sub(1)\n",
    "            \n",
    "            vk = v0.detach().clone()\n",
    "\n",
    "            ph0, _ = rbm.sample_h(v0)\n",
    "            # todo cd = 3\n",
    "            _, hk = rbm.sample_h(vk)\n",
    "            _, vk = rbm.sample_v(hk)\n",
    "            vk[v0 < 0] = v0[v0 < 0]\n",
    "                \n",
    "            phk, _ = rbm.sample_h(vk)\n",
    "\n",
    "            rbm.train_model(v0, vk, ph0, phk)\n",
    "            \n",
    "            train_recon_error += torch.mean((v0[v0 > -1] - vk[v0 > -1])**2) * len(v0 > -1)\n",
    "            s += len(v0 > -1)\n",
    "            \n",
    "        train_errors.append(torch.sqrt(train_recon_error / s))\n",
    "\n",
    "        # print('calculating test scores')\n",
    "        rbm.eval()\n",
    "        test_errors.append(score_model(rbm, batch_size, train_matrix, test_matrix))\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "    # Plot the RMSE reconstruction error with respect to increasing number of epochs\n",
    "    plt.plot(torch.Tensor(train_errors, device='cpu'), label=\"train\")\n",
    "    plt.plot(torch.Tensor(test_errors, device='cpu'), label=\"test\")\n",
    "    plt.ylabel('Error')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend()\n",
    "    plt.savefig(f'steam-cleaned-{n_hidden}-{batch_size}-{epochs}.jpg')\n",
    "    plt.clf()\n",
    "\n",
    "    return rbm, train_errors, test_errors\n",
    "\n",
    "# Evaluate the RBM on test set\n",
    "# test_recon_error = score_model(rbm)\n",
    "# print(\"Final error\", test_recon_error)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HR / Recall / NDCG Function Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vanilla Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_hr(train_matrix, test_matrix, rbm, k=10, batch_size=100):\n",
    "    hitrates = []\n",
    "    recall = []\n",
    "    nDCG = []\n",
    "    # for loop - go through every single user\n",
    "    for id_user in tqdm(range(0, train_matrix.shape[0] - rbm.batch_size, rbm.batch_size)): # - batch_size, batch_size):\n",
    "        v = train_matrix[id_user:id_user + rbm.batch_size]  # training set inputs are used to activate neurons of my RBM\n",
    "        vt = test_matrix[id_user:id_user + rbm.batch_size]  # target\n",
    "        if vt.getnnz() == 0:\n",
    "            continue\n",
    "\n",
    "        v = convert_sparse_matrix_to_sparse_tensor(v)\n",
    "        vt = convert_sparse_matrix_to_sparse_tensor(vt)\n",
    "        v = v.to_dense()\n",
    "        vt = vt.to_dense()\n",
    "        v = v.sub(1)\n",
    "        vt = vt.sub(1)\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            vt = vt.cuda()\n",
    "            v = v.cuda()\n",
    "\n",
    "        # ground truth\n",
    "        ratings, users, movies = (vt > 0).nonzero(as_tuple=True)\n",
    "\n",
    "        indices = torch.stack([users, movies])\n",
    "        shape = (rbm.batch_size, train_matrix.shape[1])\n",
    "        target = torch.sparse.LongTensor(indices, torch.add(ratings, 1), torch.Size(shape))\n",
    "        target_dense = target.to_dense()\n",
    "\n",
    "        target_rating, target_movie = torch.topk(target_dense, k, 1)\n",
    "        target_movie[target_rating < 3] = -1 # remove all bad movies from top k\n",
    "\n",
    "        values, _ = torch.max(target_movie, dim=1)\n",
    "        users_with_target = (values > -1).nonzero(as_tuple=True)[0].cpu().tolist()\n",
    "\n",
    "        # _, order = torch.sort(ratings[ratings >= 2], descending=True)\n",
    "        # target_users = torch.index_select(users[ratings >= 2], 0, order) \n",
    "        # target_recommendations = torch.index_select(movies[ratings >= 2], 0, order) \n",
    "\n",
    "        # predicted\n",
    "        _, h = rbm.sample_h(v)\n",
    "        recommended, _ = rbm.sample_v(h)\n",
    "\n",
    "        scaled_tensors = [recommended[0]]\n",
    "        for i in range(1, rbm.K):\n",
    "            scaled_tensors.append(recommended[i] * (i+1))\n",
    "        recommended_scaled = torch.stack(scaled_tensors)\n",
    "        recommended_summed = torch.sum(recommended_scaled, 0)\n",
    "        predicted_rating, predicted_movie = torch.topk(recommended_summed, k)\n",
    "\n",
    "        # TODO optimize range s.t. users without target are skipped\n",
    "\n",
    "        for user in users_with_target:\n",
    "\n",
    "            # all recommendations\n",
    "            user_target = target_movie[user].cpu().tolist()\n",
    "            user_pred = predicted_movie[user].cpu().tolist()\n",
    "\n",
    "            counter = 0\n",
    "            total = min(k, len(user_target))\n",
    "            for target in user_target:\n",
    "                if target in user_pred:\n",
    "                    counter += 1\n",
    "            # counter = len(recommendations)\n",
    "\n",
    "            recall.append(counter / total)\n",
    "            hitrates.append(min(1, counter))\n",
    "\n",
    "            # nDCG\n",
    "            idcg = np.sum([1 / np.log2(i+2) for i in range(min(k, len(user_target)))])\n",
    "            dcg = 0\n",
    "            for i, r in enumerate(user_pred):\n",
    "                if r in user_target:\n",
    "                    dcg += 1 / np.log2(i+2)\n",
    "\n",
    "            nDCG.append(dcg / idcg) \n",
    "\n",
    "    return hitrates, recall, nDCG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rbm10 = create_rbm(train_matrix, test_matrix, 1000, 10000, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rbm20 =create_rbm(train_matrix, test_matrix, 1000, 10000, 10, rbm10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def compute_hr2(pops, k=10, batch_size=100):\n",
    "    s = 0  # a counter (float type) \n",
    "    hitrates = []\n",
    "    recall = []\n",
    "    nDCG = []\n",
    "    # idcg = np.sum([1 / np.log2(i+2) for i in range(k)])\n",
    "    # for loop - go through every single user\n",
    "    for id_user in range(0, train_matrix.shape[0]): # - batch_size, batch_size):\n",
    "        v = train_matrix[id_user]  # training set inputs are used to activate neurons of my RBM\n",
    "        vt = test_matrix[id_user]  # target\n",
    "\n",
    "        target_data = vt.data\n",
    "        target_index = vt.indices\n",
    "        target_recommendations = target_index[target_data == 2]\n",
    "        # print(target_test)\n",
    "\n",
    "        \n",
    "        if len(target_recommendations) > 0: # check that target contains recommendations (only needed for aussies)\n",
    "            # _, h = rbm.sample_h(v)\n",
    "            # recommended, _ = rbm.sample_v(h)\n",
    "            # \n",
    "            # # all recommendations\n",
    "            # _, indices =  torch.topk(recommended[v < 0], k)\n",
    "            recommendations = pops[:k]\n",
    "\n",
    "            counter = 0\n",
    "            total = min(len(target_recommendations), k)\n",
    "            for target in target_recommendations:\n",
    "                if target in recommendations:\n",
    "                    counter += 1\n",
    "            # counter = len(recommendations)\n",
    "\n",
    "            recall.append(counter / total)\n",
    "            hitrates.append(min(1, counter))\n",
    "\n",
    "            # nDCG\n",
    "            idcg = np.sum([1 / np.log2(i+2) for i in range(min(k, len(target_recommendations)))])\n",
    "            counter = 0\n",
    "            dcg = 0\n",
    "            for i, r in enumerate(recommendations):\n",
    "                if r in target_recommendations:\n",
    "                    dcg += 1 / np.log2(i+2)\n",
    "\n",
    "            nDCG.append(dcg / idcg) \n",
    "\n",
    "    return hitrates, recall, nDCG\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RBM + Popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def compute_hr3(rbm, popularity_dict, k=10):\n",
    "    s = 0  # a counter (float type) \n",
    "    hitrates = []\n",
    "    recall = []\n",
    "    nDCG = []\n",
    "    idcg = np.sum([1 / np.log2(i+2) for i in range(k)])\n",
    "    pop = torch.FloatTensor(popularity_dict)\n",
    "    if torch.cuda.is_available():\n",
    "        pop = pop.cuda()\n",
    "\n",
    "    # for loop - go through every single user\n",
    "    for id_user in range(0, train_matrix.shape[0]): # - batch_size, batch_size):\n",
    "        v = train_matrix[id_user]  # training set inputs are used to activate neurons of my RBM\n",
    "        vt = test_matrix[id_user]  # target\n",
    "\n",
    "        target_data = vt.data\n",
    "        target_index = vt.indices\n",
    "        target_recommendations = target_index[target_data == 2]\n",
    "        # print(target_test)\n",
    "\n",
    "        v = v.todense()\n",
    "\n",
    "        v = v - 1\n",
    "        v = torch.Tensor(v)\n",
    "        if torch.cuda.is_available():\n",
    "            v = v.cuda()\n",
    "        \n",
    "        if len(target_recommendations) > 0: # check that target contains recommendations (only needed for aussies)\n",
    "            _, h = rbm.sample_h(v)\n",
    "            recommended, _ = rbm.sample_v(h)\n",
    "\n",
    "            # all recommendations\n",
    "            # multiply recommendations by the games popularity\n",
    "            # print(recommended)\n",
    "            recommended = torch.mul(recommended, pop)\n",
    "            # print(recommended)\n",
    "            _, indices =  torch.topk(recommended[v < 0], k)\n",
    "            # recommendations = torch.tensor(indices, device='cpu').tolist()\n",
    "            recommendations = indices.cpu().tolist()\n",
    "\n",
    "            counter = 0\n",
    "            total = min(len(target_recommendations), k)\n",
    "            for target in target_recommendations:\n",
    "                if target in recommendations:\n",
    "                    counter += 1\n",
    "            # counter = len(recommendations)\n",
    "\n",
    "            recall.append(counter / total)\n",
    "            hitrates.append(min(1, counter))\n",
    "\n",
    "            # nDCG\n",
    "            counter = 0\n",
    "            dcg = 0\n",
    "            for i, r in enumerate(recommendations):\n",
    "                if r in target_recommendations:\n",
    "                    dcg += 1 / np.log2(i+2)\n",
    "\n",
    "            nDCG.append(dcg / idcg) \n",
    "\n",
    "    return hitrates, recall, nDCG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HR / Recall / NDCG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_rbm(rbm):\n",
    "    print(\"Vanilla RBM\")\n",
    "    hr, r, ndcg = compute_hr(train_matrix, test_matrix, rbm)\n",
    "    # print(hr, r, ndcg)\n",
    "    print(\"hr\", np.average(hr))\n",
    "    print(\"recall\", np.average(r))\n",
    "    print(\"ndcg\", np.average(ndcg))\n",
    "\n",
    "    # print(\"popularity incorporated\")\n",
    "    # hr, r, ndcg = compute_hr3(rbm, value_list)\n",
    "    # print(\"hr\", np.average(hr))\n",
    "    # print(\"recall\", np.average(r))\n",
    "    # print(\"ndcg\", np.average(ndcg))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rbm100 = create_rbm(train_matrix, test_matrix, 1024, 2000, 100)\n",
    "# evaluate_rbm(rbm100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rbm10 = create_rbm(train_matrix, test_matrix, 1024, 2000, 10)\n",
    "# evaluate_rbm(rbm10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(rbm100.state_dict(), \"./network-steam100-train0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend(rbm, v, vt, k, p=True):\n",
    "    target_data = vt.data\n",
    "    target_index = vt.indices\n",
    "    target_recommendations = target_index[target_data == 1]\n",
    "    v = v.todense()\n",
    "    # v = v - 1\n",
    "    v = torch.Tensor(v)\n",
    "    if torch.cuda.is_available():\n",
    "        v = v.cuda()\n",
    "    \n",
    "    _, h = rbm.sample_h(v)\n",
    "    recommended, _ = rbm.sample_v(h)\n",
    "\n",
    "    # all recommendations\n",
    "    values, indices =  torch.topk(recommended[v < 1], k)\n",
    "    recommendations = indices.cpu().tolist()\n",
    "\n",
    "    if p:\n",
    "        # print('20', recommended[0][20])\n",
    "        # print('21', recommended[0][21])\n",
    "        print(\"average value\", torch.mean(recommended[0]))\n",
    "\n",
    "    found = True\n",
    "    for r in recommendations:\n",
    "        if r in target_recommendations:\n",
    "            if p:\n",
    "                print(\"HIT\")\n",
    "            found = True\n",
    "            break\n",
    "\n",
    "    if found and p:\n",
    "        print(\"values\", values)\n",
    "        print(\"recommended\", recommendations)\n",
    "        print(\"real\", target_recommendations)\n",
    "        print(\"len real\", len(target_recommendations))\n",
    "\n",
    "    return recommendations\n",
    "\n",
    "user = 100\n",
    "# print(\"train\", train_matrix[user])\n",
    "# print(\"test\", test_matrix[user])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparam searching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:30<00:00,  6.19s/it]\n",
      "100%|██████████| 31/31 [00:07<00:00,  4.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:30<00:00,  6.18s/it]\n",
      "100%|██████████| 31/31 [00:07<00:00,  4.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:30<00:00,  6.05s/it]\n",
      "100%|██████████| 31/31 [00:07<00:00,  4.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [02:20<00:00,  5.62s/it]\n",
      "100%|██████████| 31/31 [00:07<00:00,  4.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [04:35<00:00,  5.52s/it]\n",
      "100%|██████████| 31/31 [00:07<00:00,  4.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:29<00:00,  5.85s/it]\n",
      "100%|██████████| 31/31 [00:07<00:00,  4.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:28<00:00,  5.79s/it]\n",
      "100%|██████████| 31/31 [00:08<00:00,  3.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:29<00:00,  5.94s/it]\n",
      "100%|██████████| 31/31 [00:07<00:00,  4.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [02:27<00:00,  5.92s/it]\n",
      "100%|██████████| 31/31 [00:07<00:00,  4.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [04:52<00:00,  5.86s/it]\n",
      "100%|██████████| 31/31 [00:07<00:00,  4.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:28<00:00,  5.74s/it]\n",
      "100%|██████████| 31/31 [00:07<00:00,  4.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:29<00:00,  5.92s/it]\n",
      " 74%|███████▍  | 23/31 [00:06<00:02,  3.57it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_26164/4117137640.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrbm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mf\"./network-{n_hidden}-steam{epoch}-train0\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m         \u001b[0mhr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mndcg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute_hr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_matrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_matrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrbm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m         \u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34mf\"{epoch}-{n_hidden}\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maverage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maverage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maverage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mndcg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mprev_epoch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_26164/2455127381.py\u001b[0m in \u001b[0;36mcompute_hr\u001b[1;34m(train_matrix, test_matrix, rbm, k, batch_size)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m             \u001b[1;31m# all recommendations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m             \u001b[0muser_target\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtarget_movie\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0muser\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m             \u001b[0muser_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredicted_movie\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0muser\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = [5, 10, 25, 50, 100]\n",
    "hidden = [10, 25, 50, 75, 100]\n",
    "rbms = []\n",
    "results = {}\n",
    "\n",
    "for n_hidden in hidden:\n",
    "    rbm = None\n",
    "    prev_epoch = 0\n",
    "    train = []\n",
    "    test = []\n",
    "    for epoch in epochs:\n",
    "        rbm, train, test = create_rbm(train_matrix, test_matrix, n_hidden, 2000, epoch - prev_epoch, rbm, train_errors=train, test_errors=test)\n",
    "        torch.save(rbm.state_dict(), f\"./network-{n_hidden}-steam{epoch}-train0\")\n",
    "\n",
    "        hr, r, ndcg = compute_hr(train_matrix, test_matrix, rbm)\n",
    "        results[f\"{epoch}-{n_hidden}\"] = (np.average(hr), np.average(r), np.average(ndcg))\n",
    "        prev_epoch = epoch\n",
    "    rbms.append(rbm)\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'5-10': (0.4721990519398612, 0.05909100156653714, 0.07120696088053108),\n",
       " '10-10': (0.43171322198034706, 0.05335991699387626, 0.06565479366046802),\n",
       " '25-10': (0.43171322198034706, 0.05335991699387626, 0.06094485311186548),\n",
       " '50-10': (0.3867922608996399, 0.04605415742681016, 0.04719004218773954),\n",
       " '100-10': (0.34368197261611705, 0.03988566313348117, 0.04007417769328265),\n",
       " '5-25': (0.43171322198034706, 0.05335991699387626, 0.06537104644730532),\n",
       " '10-25': (0.43171322198034706, 0.05335991699387626, 0.06094485311186548),\n",
       " '25-25': (0.3867922608996399, 0.04605415742681016, 0.04702979551207349),\n",
       " '50-25': (0.3430105995564869, 0.03976766423209163, 0.039296668975174746),\n",
       " '100-25': (0.330010375765467, 0.03787154395459077, 0.037258968450636275),\n",
       " '5-50': (0.43171322198034706, 0.05335991699387626, 0.06094485311186548)}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ac59ebe37160ed0dfa835113d9b8498d9f09ceb179beaac4002f036b9467c963"
  },
  "kernelspec": {
   "display_name": "PyCharm (ai-project)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

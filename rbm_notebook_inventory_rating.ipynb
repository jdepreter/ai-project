{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Restricted Boltzmann Machine Defintion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Import PyTorch library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "device = torch.device('cpu')\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### the Restricted Boltzmann Machine architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# https://github.com/khanhnamle1994/MetaRec/blob/b5e36cb579a88b32cdfb728f35f645d76b24ad95/Boltzmann-Machines-Experiments/RBM-CF-PyTorch/rbm.py#L23\n",
    "# \n",
    "class RBM(nn.Module):\n",
    "    def __init__(self, n_vis, n_hid, k, batch_size):\n",
    "        \"\"\"\n",
    "        Initialize the parameters (weights and biases) we optimize during the training process\n",
    "        :param n_vis: number of visible units\n",
    "        :param n_hid: number of hidden units\n",
    "        \"\"\"\n",
    "        self.i = 0\n",
    "        self.K = k\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        # Weights used for the probability of the visible units given the hidden units\n",
    "        super().__init__()\n",
    "        self.W = torch.randn(k, n_hid, n_vis)  # torch.rand: random normal distribution mean = 0, variance = 1\n",
    "\n",
    "        # Bias probability of the visible units is activated, given the value of the hidden units (p_v_given_h)\n",
    "        self.v_bias = torch.zeros(k, 1, n_vis)  # fake dimension for the batch = 1\n",
    "\n",
    "        # Bias probability of the hidden units is activated, given the value of the visible units (p_h_given_v)\n",
    "        self.h_bias = torch.zeros(1, n_hid)  # fake dimension for the batch = 1\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            self.W = self.W.cuda()\n",
    "            self.v_bias = self.v_bias.cuda()\n",
    "            self.h_bias = self.h_bias.cuda()\n",
    "    \n",
    "    def lr(self):\n",
    "        \"\"\"\n",
    "        return the learning rate of the model, lr is based on batchsize\n",
    "        :return: constant/batch_size\n",
    "        \"\"\"\n",
    "        return 0.01 / self.batch_size\n",
    "\n",
    "    def sample_h(self, x):\n",
    "        \"\"\"\n",
    "        Sample the hidden units\n",
    "        :param x: the dataset\n",
    "        \"\"\"\n",
    "\n",
    "        # Probability h is activated given that the value v is sigmoid(Wx + a)\n",
    "        # torch.mm make the product of 2 tensors\n",
    "        # W.t() take the transpose because W is used for the p_v_given_h\n",
    "\n",
    "        temp = torch.transpose(self.W, 1, 2)\n",
    "\n",
    "        wxs = []\n",
    "        for i in range(self.K):\n",
    "            wxs.append(torch.mm(x[i], temp[i]))\n",
    "            \n",
    "        wx = torch.stack(wxs)\n",
    "        wx_sum = torch.sum(wx, 0)\n",
    "\n",
    "        # Expand the mini-batch\n",
    "        activation = wx_sum + self.h_bias.expand_as(wx_sum)\n",
    "\n",
    "        # Calculate the probability p_h_given_v\n",
    "        p_h_given_v = torch.sigmoid(activation)\n",
    "\n",
    "        # Construct a Bernoulli RBM to predict whether an user loves the movie or not (0 or 1)\n",
    "        # This corresponds to whether the n_hid is activated or not activated\n",
    "        return p_h_given_v, torch.bernoulli(p_h_given_v)\n",
    "\n",
    "    def sample_v(self, y):\n",
    "        \"\"\"\n",
    "        Sample the visible units\n",
    "        :param y: the dataset\n",
    "        \"\"\"\n",
    "\n",
    "        exponents = []\n",
    "        for k in range(self.K):\n",
    "            wy = torch.mm(y, self.W[k])\n",
    "            activation = wy + self.v_bias[k].expand_as(wy)\n",
    "            exponents.append(torch.exp(activation))\n",
    "\n",
    "        exponent_tensor = torch.stack(exponents)\n",
    "        exponent_sum = torch.sum(exponent_tensor, 0)\n",
    "        probs = []\n",
    "        for k in range(self.K):\n",
    "            p_v_k_given_h = exponent_tensor[k] / exponent_sum\n",
    "            probs.append(p_v_k_given_h)\n",
    "\n",
    "        p_v_given_h = torch.stack(probs)\n",
    "        # todo multinomial\n",
    "        bern = torch.bernoulli(p_v_given_h)\n",
    "        return p_v_given_h, bern\n",
    "\n",
    "\n",
    "    def train_model(self, v0, vk, ph0, phk):\n",
    "        \"\"\"\n",
    "        Perform contrastive divergence algorithm to optimize the weights that minimize the energy\n",
    "        This maximizes the log-likelihood of the model\n",
    "        \"\"\"\n",
    "\n",
    "        ph0_K = torch.stack([ph0 for _ in range(self.K)])\n",
    "        phk_K = torch.stack([phk for _ in range(self.K)])\n",
    "\n",
    "        poss = []\n",
    "        negs = []\n",
    "        for i in range(self.K):\n",
    "            poss.append(torch.mm(torch.transpose(v0, 1, 2)[i], ph0_K[i]))\n",
    "            negs.append(torch.mm(torch.transpose(vk, 1, 2)[i], phk_K[i]))\n",
    "\n",
    "        pos = torch.stack(poss)\n",
    "        neg = torch.stack(negs)\n",
    "\n",
    "        w_extra = torch.transpose(pos - neg, 1, 2)\n",
    "        v_extra = torch.sum((v0 - vk), 1)\n",
    "        h_extra = torch.sum((ph0 - phk), 0)\n",
    "\n",
    "        # Approximate the gradients with the CD algorithm\n",
    "        self.W -= self.lr() * w_extra\n",
    "\n",
    "        # Add (difference, 0) for the tensor of 2 dimensions\n",
    "        self.v_bias -= self.lr() * v_extra.unsqueeze(1)\n",
    "        self.h_bias -= self.lr() * h_extra\n",
    "        self.i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "cuda = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle as pickle\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "import gzip\n",
    "import json\n",
    "from tqdm import tqdm, trange\n",
    "import os\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "import math\n",
    "tqdm.pandas() #for progres_apply etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in steamdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def load_interactions(path, n_splits=5):\n",
    "    \"\"\"\n",
    "    load in the interactions_splits.pkl.gz file with our data for the various users\n",
    "    :param path: path location of the data\n",
    "    :param n_splits: split in n_split splits\n",
    "    :return: interactions\n",
    "    \"\"\"\n",
    "    df = pd.read_pickle(os.path.join(os.getcwd(), path))\n",
    "    df[['interactions', 'train', 'val', 'test']] = df[['interactions', 'train', 'val', 'test']].applymap(lambda x: np.array(x, dtype=np.int32))\n",
    "    interactions_dict = {}\n",
    "    for split in trange(n_splits):\n",
    "        for column in ['train', 'val', 'test']:\n",
    "            interactions_dict[split, column] = pd.DataFrame({\n",
    "                'user_id': df['user_id'],\n",
    "                'steam_id': df['steam_id'],\n",
    "                'item_id': df[column].apply(lambda x: x[split, 0]),\n",
    "                'playtime_forever': df[column].apply(lambda x: x[split, 1]),\n",
    "                'playtime_2weeks': df[column].apply(lambda x: x[split, 2])})\n",
    "    return interactions_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Reading and showning train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "\r  0%|          | 0/5 [00:00<?, ?it/s]",
      "\r 20%|██        | 1/5 [00:00<00:01,  3.04it/s]",
      "\r 40%|████      | 2/5 [00:00<00:00,  3.23it/s]",
      "\r 60%|██████    | 3/5 [00:00<00:00,  3.00it/s]",
      "\r 80%|████████  | 4/5 [00:01<00:00,  3.09it/s]",
      "\r100%|██████████| 5/5 [00:02<00:00,  2.20it/s]",
      "\r100%|██████████| 5/5 [00:02<00:00,  2.44it/s]",
      "\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "             user_id           steam_id  \\\n0  76561197981203305  76561197981203305   \n1          bosslucek  76561198029968002   \n2          icantwait  76561197971666535   \n3  76561198067911521  76561198067911521   \n4         kushziller  76561198021307778   \n\n                                             item_id  \\\n0  [1461, 1999, 1984, 761, 2820, 819, 187, 506, 3...   \n1  [4014, 1018, 3632, 2843, 2755, 219, 6245, 2621...   \n2  [886, 2010, 419, 2217, 1293, 2809, 802, 155, 2...   \n3  [1849, 1038, 229, 400, 1386, 1437, 1363, 515, ...   \n4  [2883, 401, 2243, 4408, 3966, 1487, 1888, 2708...   \n\n                                    playtime_forever  \\\n0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n\n                                     playtime_2weeks  \n0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>steam_id</th>\n      <th>item_id</th>\n      <th>playtime_forever</th>\n      <th>playtime_2weeks</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>76561197981203305</td>\n      <td>76561197981203305</td>\n      <td>[1461, 1999, 1984, 761, 2820, 819, 187, 506, 3...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>bosslucek</td>\n      <td>76561198029968002</td>\n      <td>[4014, 1018, 3632, 2843, 2755, 219, 6245, 2621...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>icantwait</td>\n      <td>76561197971666535</td>\n      <td>[886, 2010, 419, 2217, 1293, 2809, 802, 155, 2...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>76561198067911521</td>\n      <td>76561198067911521</td>\n      <td>[1849, 1038, 229, 400, 1386, 1437, 1363, 515, ...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>kushziller</td>\n      <td>76561198021307778</td>\n      <td>[2883, 401, 2243, 4408, 3966, 1487, 1888, 2708...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 29
    }
   ],
   "source": [
    "interactions = load_interactions(\"./data-cleaned/interactions_splits.pkl.gz\")\n",
    "interactions[0, 'train'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Reading and showing list of games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                      publisher  \\\n0                Rockstar Games   \n1                         Valve   \n2            Trion Worlds, Inc.   \n3           Bohemia Interactive   \n4  Unknown Worlds Entertainment   \n\n                                              genres  \\\n0                                           [Action]   \n1                                           [Action]   \n2  [Action, Free to Play, Massively Multiplayer, ...   \n3                     [Action, Simulation, Strategy]   \n4                          [Action, Indie, Strategy]   \n\n                                       app_name  \\\n0  Grand Theft Auto: Episodes from Liberty City   \n1                                     Half-Life   \n2                                      Defiance   \n3                                        Arma 3   \n4                           Natural Selection 2   \n\n                                          title  \\\n0  Grand Theft Auto: Episodes from Liberty City   \n1                                     Half-Life   \n2                                      Defiance   \n3                                        Arma 3   \n4                           Natural Selection 2   \n\n                                                 url release_date  \\\n0  http://store.steampowered.com/app/12220/Grand_...   2010-04-12   \n1     http://store.steampowered.com/app/70/HalfLife/   1998-11-08   \n2  http://store.steampowered.com/app/224600/Defia...   2014-06-04   \n3   http://store.steampowered.com/app/107410/Arma_3/   2013-09-12   \n4  http://store.steampowered.com/app/4920/Natural...   2012-10-30   \n\n                                                tags  discount_price  \\\n0  [Open World, Action, Third Person, Multiplayer...             NaN   \n1  [FPS, Classic, Action, Sci-fi, Singleplayer, S...             NaN   \n2  [Free to Play, Action, Open World, Massively M...             NaN   \n3  [Simulation, Military, Multiplayer, Realistic,...             NaN   \n4  [Multiplayer, Strategy, FPS, Team-Based, Actio...             NaN   \n\n                                         reviews_url  \\\n0  http://steamcommunity.com/app/12220/reviews/?b...   \n1  http://steamcommunity.com/app/70/reviews/?brow...   \n2  http://steamcommunity.com/app/224600/reviews/?...   \n3  http://steamcommunity.com/app/107410/reviews/?...   \n4  http://steamcommunity.com/app/4920/reviews/?br...   \n\n                                               specs         price  \\\n0                      [Single-player, Multi-player]         19.99   \n1  [Single-player, Multi-player, Valve Anti-Cheat...          9.99   \n2  [Multi-player, MMO, Co-op, Steam Trading Cards...  Free to Play   \n3  [Single-player, Multi-player, Online Multi-Pla...         39.99   \n4  [Multi-player, Online Multi-Player, Steam Achi...          9.99   \n\n   early_access      id                     developer  \\\n0         False   12220      Rockstar North / Toronto   \n1         False      70                         Valve   \n2         False  224600            Trion Worlds, Inc.   \n3         False  107410           Bohemia Interactive   \n4         False    4920  Unknown Worlds Entertainment   \n\n                 sentiment metascore  users_count  \n0          Mostly Positive       NaN         7597  \n1  Overwhelmingly Positive        96         7575  \n2          Mostly Positive        64         7539  \n3            Very Positive        74         7527  \n4            Very Positive        80         7502  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>publisher</th>\n      <th>genres</th>\n      <th>app_name</th>\n      <th>title</th>\n      <th>url</th>\n      <th>release_date</th>\n      <th>tags</th>\n      <th>discount_price</th>\n      <th>reviews_url</th>\n      <th>specs</th>\n      <th>price</th>\n      <th>early_access</th>\n      <th>id</th>\n      <th>developer</th>\n      <th>sentiment</th>\n      <th>metascore</th>\n      <th>users_count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Rockstar Games</td>\n      <td>[Action]</td>\n      <td>Grand Theft Auto: Episodes from Liberty City</td>\n      <td>Grand Theft Auto: Episodes from Liberty City</td>\n      <td>http://store.steampowered.com/app/12220/Grand_...</td>\n      <td>2010-04-12</td>\n      <td>[Open World, Action, Third Person, Multiplayer...</td>\n      <td>NaN</td>\n      <td>http://steamcommunity.com/app/12220/reviews/?b...</td>\n      <td>[Single-player, Multi-player]</td>\n      <td>19.99</td>\n      <td>False</td>\n      <td>12220</td>\n      <td>Rockstar North / Toronto</td>\n      <td>Mostly Positive</td>\n      <td>NaN</td>\n      <td>7597</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Valve</td>\n      <td>[Action]</td>\n      <td>Half-Life</td>\n      <td>Half-Life</td>\n      <td>http://store.steampowered.com/app/70/HalfLife/</td>\n      <td>1998-11-08</td>\n      <td>[FPS, Classic, Action, Sci-fi, Singleplayer, S...</td>\n      <td>NaN</td>\n      <td>http://steamcommunity.com/app/70/reviews/?brow...</td>\n      <td>[Single-player, Multi-player, Valve Anti-Cheat...</td>\n      <td>9.99</td>\n      <td>False</td>\n      <td>70</td>\n      <td>Valve</td>\n      <td>Overwhelmingly Positive</td>\n      <td>96</td>\n      <td>7575</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Trion Worlds, Inc.</td>\n      <td>[Action, Free to Play, Massively Multiplayer, ...</td>\n      <td>Defiance</td>\n      <td>Defiance</td>\n      <td>http://store.steampowered.com/app/224600/Defia...</td>\n      <td>2014-06-04</td>\n      <td>[Free to Play, Action, Open World, Massively M...</td>\n      <td>NaN</td>\n      <td>http://steamcommunity.com/app/224600/reviews/?...</td>\n      <td>[Multi-player, MMO, Co-op, Steam Trading Cards...</td>\n      <td>Free to Play</td>\n      <td>False</td>\n      <td>224600</td>\n      <td>Trion Worlds, Inc.</td>\n      <td>Mostly Positive</td>\n      <td>64</td>\n      <td>7539</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Bohemia Interactive</td>\n      <td>[Action, Simulation, Strategy]</td>\n      <td>Arma 3</td>\n      <td>Arma 3</td>\n      <td>http://store.steampowered.com/app/107410/Arma_3/</td>\n      <td>2013-09-12</td>\n      <td>[Simulation, Military, Multiplayer, Realistic,...</td>\n      <td>NaN</td>\n      <td>http://steamcommunity.com/app/107410/reviews/?...</td>\n      <td>[Single-player, Multi-player, Online Multi-Pla...</td>\n      <td>39.99</td>\n      <td>False</td>\n      <td>107410</td>\n      <td>Bohemia Interactive</td>\n      <td>Very Positive</td>\n      <td>74</td>\n      <td>7527</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Unknown Worlds Entertainment</td>\n      <td>[Action, Indie, Strategy]</td>\n      <td>Natural Selection 2</td>\n      <td>Natural Selection 2</td>\n      <td>http://store.steampowered.com/app/4920/Natural...</td>\n      <td>2012-10-30</td>\n      <td>[Multiplayer, Strategy, FPS, Team-Based, Actio...</td>\n      <td>NaN</td>\n      <td>http://steamcommunity.com/app/4920/reviews/?br...</td>\n      <td>[Multi-player, Online Multi-Player, Steam Achi...</td>\n      <td>9.99</td>\n      <td>False</td>\n      <td>4920</td>\n      <td>Unknown Worlds Entertainment</td>\n      <td>Very Positive</td>\n      <td>80</td>\n      <td>7502</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 30
    }
   ],
   "source": [
    "games = pd.read_pickle(os.path.join(os.getcwd(), \"./data-cleaned/games.pkl.gz\"))\n",
    "games.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "train0 = interactions[0, 'train']\n",
    "test0 = interactions[0, 'test']\n",
    "val0 = interactions[0, 'val']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "train1 = interactions[1, 'train']\n",
    "test1 = interactions[1, 'test']\n",
    "val1 = interactions[1, 'val']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "train2 = interactions[2, 'train']\n",
    "test2 = interactions[2, 'test']\n",
    "val2 = interactions[2, 'val']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sparse Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method to create Sparse Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def score_playtime(playtime):\n",
    "    \"\"\"\n",
    "    give a game a rating score between 0 and 4 \n",
    "    :param playtime: the playtime to give a score by\n",
    "    :return: 0,1,2,3 or 4 based on playtime\n",
    "    \"\"\"\n",
    "    if playtime < 120:\n",
    "        # less than 2 hrs\n",
    "        return 0\n",
    "    elif playtime < 240:\n",
    "        # less than 4 hrs\n",
    "        return 1\n",
    "    elif playtime < 600:\n",
    "        # less than 10 hrs\n",
    "        return 2\n",
    "    elif playtime < 24*60:\n",
    "        # less than 24 hrs\n",
    "        return 3\n",
    "    else:\n",
    "        return 4\n",
    "\n",
    "from os import path\n",
    "if not path.isfile('index_random_ordering.pkl'):\n",
    "    import random\n",
    "    index_random_list =list(range(games.shape[0]))\n",
    "    random.shuffle(index_random_list)\n",
    "    # print(index_random_list)\n",
    "    file = open(\"index_random_ordering.pkl\", \"wb\")\n",
    "    pickle.dump(index_random_list, file)\n",
    "    file.close()\n",
    "else:\n",
    "    f = open(\"index_random_ordering.pkl\", \"rb\")\n",
    "    index_random_list = pickle.load(f)\n",
    "    f.close()\n",
    "\n",
    "def shuffle_item_index(items):\n",
    "    global index_random_list\n",
    "    return [index_random_list[item] for item in items]\n",
    "\n",
    "def invert_items(items, max_item: int):\n",
    "    return [max_item - item for item in items]\n",
    "\n",
    "#Create scipy csr matrix\n",
    "def get_sparse_matrix(df):\n",
    "    \"\"\"\n",
    "    generate a sparse matrix of user-game pairs based on our dataframe\n",
    "    :param df: the dataframe to base the sparse matrix upon\n",
    "    :return: a sparse matrix of user-game pairs with a score based on playtime\n",
    "    \"\"\"\n",
    "    shape = (df.shape[0], games.shape[0])\n",
    "    max_game = games.shape[0] - 1\n",
    "    \n",
    "    user_ids = []\n",
    "    item_ids = []\n",
    "    values = []\n",
    "    for idx, row in df.iterrows():\n",
    "        user = idx\n",
    "        items = row['item_id']\n",
    "        # items = invert_items(items, max_game)\n",
    "        items = shuffle_item_index(items)\n",
    "        score = row[\"playtime_forever\"] + 2* row[\"playtime_2weeks\"]\n",
    "        \n",
    "        user_ids.extend([user] * len(items))\n",
    "        item_ids.extend(items)\n",
    "        values.extend([score_playtime(score[i]) for i in range(len(items))])\n",
    "    # create csr matrix\n",
    "    matrix = scipy.sparse.csr_matrix((values, (user_ids, item_ids)), shape=shape, dtype=np.int32)\n",
    "    return matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### generate the Sparse Matrisces for train AND test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<54190x7276 sparse matrix of type '<class 'numpy.intc'>'\n\twith 1407708 stored elements in Compressed Sparse Row format>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 35
    }
   ],
   "source": [
    "train_matrix = get_sparse_matrix(train0)\n",
    "test_matrix = get_sparse_matrix(test0)\n",
    "val_matrix = get_sparse_matrix(val0)\n",
    "train_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Method to convert Sparse Matrix to pytorch tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# https://stackoverflow.com/questions/40896157/scipy-sparse-csr-matrix-to-tensorflow-sparsetensor-mini-batch-gradient-descent\n",
    "def convert_sparse_matrix_to_sparse_tensor(X, k=5):\n",
    "    \"\"\"\n",
    "    turn the Sparse scipy matrix into a sparse pytorch tensor\n",
    "    :param X: the Sparse scipy matrix\n",
    "    :param k: the amount of possible ratings we have given to our user-game pairs\n",
    "    :return: a sparse 3-D pytorch tensor of dimensions game-user-rating\n",
    "    \"\"\"\n",
    "    coo = X.tocoo()\n",
    "\n",
    "    values = coo.data\n",
    "    indices = np.vstack((coo.row, coo.col))\n",
    "    i = torch.LongTensor(indices)\n",
    "    v = torch.DoubleTensor(values)\n",
    "    tensor_list = []\n",
    "\n",
    "    for index in range(k):\n",
    "        value = index\n",
    "        yeet = torch.where(v == value, 2., 1.)\n",
    "        shape = coo.shape\n",
    "        tensor = torch.sparse.DoubleTensor(i, yeet, torch.Size(shape)) \n",
    "        if torch.cuda.is_available():\n",
    "            tensor = tensor.cuda()\n",
    "\n",
    "        tensor_list.append(tensor)\n",
    "\n",
    "    tensor = torch.stack(tensor_list) \n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def score_model(rbm: RBM, batch_size, train_matrix, test_matrix):\n",
    "    \"\"\"\n",
    "    calculate an error for the output of our rbm for the unseen (and untrained upon) test-values\n",
    "    :param rbm: the model for which we test values\n",
    "    :param batch_size: the batchsize used for training/testing\n",
    "    :param train_matrix: the original input with which we try to get our test-values\n",
    "    :param test_matrix: the values we try for our model to acquire based on train_matrix\n",
    "    :return: the RMSE for our test-values\n",
    "    \"\"\"\n",
    "    test_recon_error = 0  # RMSE reconstruction error initialized to 0 at the beginning of training\n",
    "    s = 0  # a counter (float type) \n",
    "    # for loop - go through every single user\n",
    "    for id_user in range(0, train_matrix.shape[0] - batch_size, batch_size):\n",
    "        v = train_matrix[id_user:id_user + batch_size]  # training set inputs are used to activate neurons of my RBM\n",
    "        vt = test_matrix[id_user:id_user + batch_size]  # target\n",
    "        v = convert_sparse_matrix_to_sparse_tensor(v)\n",
    "        vt = convert_sparse_matrix_to_sparse_tensor(vt)\n",
    "\n",
    "        v = v.to_dense()\n",
    "        vt = vt.to_dense()\n",
    "        v = v.sub(1)\n",
    "        vt = vt.sub(1)\n",
    "        if torch.cuda.is_available():\n",
    "            v = v.cuda()\n",
    "            vt = vt.cuda()\n",
    "\n",
    "        if len(vt[vt > -1]) > 0:\n",
    "            _, h = rbm.sample_h(v)\n",
    "            _, v = rbm.sample_v(h)\n",
    "\n",
    "            # Update test RMSE reconstruction error\n",
    "            test_recon_error += torch.mean((vt[vt > -1] - v[vt > -1])**2) * len(vt > -1) \n",
    "            s += len(vt > -1)\n",
    "\n",
    "    return torch.sqrt(test_recon_error / s)\n",
    "\n",
    "\n",
    "def create_rbm(train_matrix, test_matrix, n_hidden, batch_size, epochs, rbm=None, k=5, train_errors=[], test_errors=[]) -> RBM:\n",
    "    \"\"\"\n",
    "    generate and train an RBM based on train_matrix as input\n",
    "    :param train_matrix: the input upon which our model is trained\n",
    "    :param test_matrix: the input upon which our model is validated\n",
    "    :param n_hidden: the amount of hidden features our model uses\n",
    "    :param batch_size: the batchsize we use\n",
    "    :param epochs: the amount of epochs we will be running\n",
    "    :param rbm: an optional variable that if not None trains a pre-generated model further instead of generating a new one\n",
    "    :param k: the amount of possible ratings we have given to our user-game pairs\n",
    "    :return: a trained RBM\n",
    "    \"\"\"\n",
    "    n_vis = train_matrix.shape[1]\n",
    "    if rbm is None:\n",
    "        rbm = RBM(n_vis, n_hidden, k, batch_size)\n",
    "    \n",
    "    oldhr, oldr, oldndcg = 0, 0, 0\n",
    "    # hr, r, ndcg = compute_hr(train_matrix, test_matrix, rbm)\n",
    "    # print(\"pre training\", np.average(hr), np.average(r), np.average(ndcg))\n",
    "\n",
    "    print(\"start training\")\n",
    "    for epoch in range(epochs):\n",
    "        rbm.train()\n",
    "        train_recon_error = 0  # RMSE reconstruction error initialized to 0 at the beginning of training\n",
    "        s = 0\n",
    "        \n",
    "        for user_id in range(0, train_matrix.shape[0] - batch_size, batch_size):\n",
    "            training_sample = train_matrix[user_id : user_id + batch_size]\n",
    "            v0 = convert_sparse_matrix_to_sparse_tensor(training_sample)\n",
    "\n",
    "            v0 = v0.to_dense()\n",
    "            v0 = v0.sub(1)\n",
    "            \n",
    "            vk = v0.detach().clone()\n",
    "\n",
    "            ph0, _ = rbm.sample_h(v0)\n",
    "            # todo cd = 3\n",
    "            _, hk = rbm.sample_h(vk)\n",
    "            _, vk = rbm.sample_v(hk)\n",
    "            vk[v0 < 0] = v0[v0 < 0]\n",
    "                \n",
    "            phk, _ = rbm.sample_h(vk)\n",
    "\n",
    "            rbm.train_model(v0, vk, ph0, phk)\n",
    "            \n",
    "            train_recon_error += torch.mean((v0[v0 > -1] - vk[v0 > -1])**2) * len(v0 > -1)\n",
    "            s += len(v0 > -1)\n",
    "            \n",
    "        train_errors.append(torch.sqrt(train_recon_error / s))\n",
    "\n",
    "        rbm.eval()\n",
    "        test_errors.append(score_model(rbm, batch_size, train_matrix, test_matrix))\n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "    # Plot the RMSE reconstruction error with respect to increasing number of epochs\n",
    "    plt.clf()\n",
    "    plt.plot(torch.Tensor(train_errors, device='cpu'), label=\"train\")\n",
    "    plt.plot(torch.Tensor(test_errors, device='cpu'), label=\"test\")\n",
    "    plt.ylabel('Error')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend()\n",
    "    plt.savefig(f'steam-cleaned-{n_hidden}-{batch_size}-{epochs}.jpg')\n",
    "\n",
    "    return rbm, train_errors, test_errors\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HR / Recall / NDCG Function Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vanilla Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def compute_hr(train_matrix, test_matrix, rbm, k=10, rating_cutoff=-1, p=False):\n",
    "    \"\"\"\n",
    "    compute the various metrics of our model, hr, recall and ndcg\n",
    "    :param train_matrix: the input wich our user already has\n",
    "    :param test_matrix: the games we are trying to recommend to each user\n",
    "    :param rbm: our model used to make recommendations\n",
    "    :param k: the amount of recommendations we are going to give\n",
    "    :param batch_size: UNUSED, uses rbm.batch_size instead\n",
    "    :return: hitrates, recall, nDCG as an array, use np.average to get value\n",
    "    \"\"\"\n",
    "    hitrates = []\n",
    "    recall = []\n",
    "    nDCG = []\n",
    "\n",
    "    recommended_games_set = set()\n",
    "    # for loop - go through every single user\n",
    "    # for id_user in tqdm(range(0, train_matrix.shape[0] - rbm.batch_size, rbm.batch_size)): # - batch_size, batch_size):\n",
    "    for id_user in range(0, train_matrix.shape[0] - rbm.batch_size, rbm.batch_size): # - batch_size, batch_size):\n",
    "        v = train_matrix[id_user:id_user + rbm.batch_size]  # training set inputs are used to activate neurons of my RBM\n",
    "        vt = test_matrix[id_user:id_user + rbm.batch_size]  # target\n",
    "        if vt.getnnz() == 0:\n",
    "            continue\n",
    "\n",
    "        v = convert_sparse_matrix_to_sparse_tensor(v)\n",
    "        vt = convert_sparse_matrix_to_sparse_tensor(vt)\n",
    "        v = v.to_dense()\n",
    "        vt = vt.to_dense()\n",
    "        v = v.sub(1)\n",
    "        vt = vt.sub(1)\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            vt = vt.cuda()\n",
    "            v = v.cuda()\n",
    "\n",
    "        # ground truth\n",
    "        ratings, users, movies = (vt > 0).nonzero(as_tuple=True)\n",
    "\n",
    "        indices = torch.stack([users, movies])\n",
    "        shape = (rbm.batch_size, train_matrix.shape[1])\n",
    "        target = torch.sparse.LongTensor(indices, torch.add(ratings, 1), torch.Size(shape))\n",
    "        target_dense = target.to_dense()\n",
    "\n",
    "        target_recommended = torch.argsort(target_dense, 1, descending=True)\n",
    "        \n",
    "\n",
    "        # predicted\n",
    "        _, h = rbm.sample_h(v)\n",
    "        recommended, _ = rbm.sample_v(h)\n",
    "\n",
    "        scaled_tensors = [recommended[0]]\n",
    "        for i in range(1, rbm.K):\n",
    "            scaled_tensors.append(recommended[i] * (i+1))\n",
    "        recommended_scaled = torch.stack(scaled_tensors)\n",
    "        recommended_summed = torch.sum(recommended_scaled, 0)\n",
    "        predicted_rating, predicted_movie = torch.topk(recommended_summed, k)\n",
    "\n",
    "\n",
    "        for user in range(rbm.batch_size):\n",
    "            # all recommendations\n",
    "            user_ratings = torch.index_select(target_dense[user], 0, target_recommended[user])\n",
    "            user_target = target_recommended[user][user_ratings > 0].cpu().tolist()\n",
    "\n",
    "            # user_target = target_recommended[user][target_rating[user] > rating_cutoff].cpu().tolist()\n",
    "            user_pred = predicted_movie[user].cpu().tolist()\n",
    "\n",
    "            recommended_games_set = recommended_games_set.union(set(user_pred))\n",
    "\n",
    "            counter = 0\n",
    "            total = min(k, len(user_target))\n",
    "            for target in user_target:\n",
    "                if target in user_pred:\n",
    "                    counter += 1\n",
    "            # counter = len(recommendations)\n",
    "\n",
    "            recall.append(counter / total)\n",
    "            hitrates.append(min(1, counter))\n",
    "\n",
    "            # nDCG\n",
    "            idcg = np.sum([1 / np.log2(i+2) for i in range(min(k, len(user_target)))])\n",
    "            dcg = 0\n",
    "            for i, r in enumerate(user_pred):\n",
    "                if r in user_target:\n",
    "                    dcg += 1 / np.log2(i+2)\n",
    "\n",
    "            nDCG.append(dcg / idcg) \n",
    "\n",
    "    if p:\n",
    "        print(recommended_games_set)\n",
    "        print(len(recommended_games_set))\n",
    "    return hitrates, recall, nDCG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# rbm10 = create_rbm(train_matrix, test_matrix, 1000, 10000, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# rbm20 =create_rbm(train_matrix, test_matrix, 1000, 10000, 10, rbm10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def get_pop(train_df):\n",
    "    \"\"\"\n",
    "    get the items based on there occurence in train_df\n",
    "    :param train_df: the train_data\n",
    "    :return: list ordered from most to least common item\n",
    "    \"\"\"\n",
    "    popularity = train_df.explode('item_id')['item_id'].value_counts()\n",
    "    l = list(popularity.index)\n",
    "    global index_random_list\n",
    "    return [index_random_list[item] for item in l]\n",
    "    \n",
    "\n",
    "\n",
    "pop = get_pop(train0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "\r  0%|          | 0/27 [00:00<?, ?it/s]",
      "\r  4%|▎         | 1/27 [00:16<07:20, 16.92s/it]",
      "\r  7%|▋         | 2/27 [00:25<05:57, 14.31s/it]",
      "\r 11%|█         | 3/27 [00:30<04:41, 11.74s/it]",
      "\r 15%|█▍        | 4/27 [00:36<03:47,  9.90s/it]",
      "\r 19%|█▊        | 5/27 [00:41<03:06,  8.48s/it]",
      "\r 22%|██▏       | 6/27 [00:47<02:39,  7.61s/it]",
      "\r 26%|██▌       | 7/27 [00:52<02:16,  6.81s/it]",
      "\r 30%|██▉       | 8/27 [00:56<01:53,  5.98s/it]",
      "\r 33%|███▎      | 9/27 [01:00<01:37,  5.39s/it]",
      "\r 37%|███▋      | 10/27 [01:04<01:26,  5.06s/it]",
      "\r 41%|████      | 11/27 [01:08<01:17,  4.82s/it]",
      "\r 44%|████▍     | 12/27 [01:13<01:12,  4.81s/it]",
      "\r 48%|████▊     | 13/27 [01:17<01:03,  4.52s/it]",
      "\r 52%|█████▏    | 14/27 [01:20<00:54,  4.23s/it]",
      "\r 56%|█████▌    | 15/27 [01:25<00:50,  4.19s/it]",
      "\r 59%|█████▉    | 16/27 [01:28<00:43,  3.93s/it]",
      "\r 63%|██████▎   | 17/27 [01:31<00:37,  3.77s/it]",
      "\r 67%|██████▋   | 18/27 [01:35<00:32,  3.65s/it]",
      "\r 70%|███████   | 19/27 [01:38<00:28,  3.51s/it]",
      "\r 74%|███████▍  | 20/27 [01:42<00:25,  3.67s/it]",
      "\r 78%|███████▊  | 21/27 [01:45<00:21,  3.56s/it]",
      "\r 81%|████████▏ | 22/27 [01:48<00:16,  3.33s/it]",
      "\r 85%|████████▌ | 23/27 [01:51<00:12,  3.11s/it]",
      "\r 89%|████████▉ | 24/27 [01:53<00:08,  2.98s/it]",
      "\r 93%|█████████▎| 25/27 [01:56<00:05,  2.82s/it]",
      "\r 96%|█████████▋| 26/27 [01:58<00:02,  2.75s/it]",
      "\r100%|██████████| 27/27 [02:01<00:00,  2.70s/it]",
      "\r100%|██████████| 27/27 [02:01<00:00,  4.50s/it]",
      "\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": [
      "hr 0.2101111111111111\nrecall 0.06400038947677837\nndcg 0.04219204395037143\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "def compute_hr2(train_matrix, test_matrix, pops, k=10, rating_cutoff=-1, p=False, batch_size = 2000):\n",
    "    \"\"\"\n",
    "    compute the various metrics of popularity: hr, recall and ndcg\n",
    "    :param train_matrix: the input wich our user already has\n",
    "    :param test_matrix: the games we are trying to recommend to each user\n",
    "    :param pops: the list of the ordered most items\n",
    "    :param k: the amount of items to recommend\n",
    "    :param rating_cutoff: UNUSED \n",
    "    :param p: UNUSED\n",
    "    :param batch_size: used for increased efficiency\n",
    "    :return: \n",
    "    \"\"\"\n",
    "    hitrates = []\n",
    "    recall = []\n",
    "    nDCG = []\n",
    "    # for loop - go through every single user\n",
    "    for id_user in tqdm(range(0, train_matrix.shape[0] - batch_size, batch_size)): # - batch_size, batch_size):\n",
    "        v = train_matrix[id_user:id_user + batch_size]  # training set inputs are used to activate neurons of my RBM\n",
    "        vt = test_matrix[id_user:id_user + batch_size]  # target\n",
    "        if vt.getnnz() == 0:\n",
    "            continue\n",
    "\n",
    "        v = convert_sparse_matrix_to_sparse_tensor(v)\n",
    "        vt = convert_sparse_matrix_to_sparse_tensor(vt)\n",
    "        v = v.to_dense()\n",
    "        vt = vt.to_dense()\n",
    "        v = v.sub(1)\n",
    "        vt = vt.sub(1)\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            vt = vt.cuda()\n",
    "            v = v.cuda()\n",
    "            \n",
    "        ratings, users, movies = (v > 0).nonzero(as_tuple=True)\n",
    "\n",
    "        indices = torch.stack([users, movies])\n",
    "        shape = (batch_size, train_matrix.shape[1])\n",
    "        target = torch.sparse.LongTensor(indices, torch.add(ratings, 1), torch.Size(shape))\n",
    "        target_start_dense = target.to_dense()\n",
    "        target_start = torch.argsort(target_start_dense, 1, descending=True)\n",
    "\n",
    "        # ground truth\n",
    "        ratings, users, movies = (vt > 0).nonzero(as_tuple=True)\n",
    "\n",
    "        indices = torch.stack([users, movies])\n",
    "        shape = (batch_size, train_matrix.shape[1])\n",
    "        target = torch.sparse.LongTensor(indices, torch.add(ratings, 1), torch.Size(shape))\n",
    "        target_dense = target.to_dense()\n",
    "        target_recommended = torch.argsort(target_dense, 1, descending=True)\n",
    "         # remove all bad movies from top k\n",
    "\n",
    "\n",
    "        # predicted\n",
    "        \n",
    "\n",
    "\n",
    "        for user in range(batch_size):\n",
    "\n",
    "            # all recommendations\n",
    "            user_current_ratings = torch.index_select(target_start_dense[user], 0, target_start[user])\n",
    "            user_current = target_start[user][user_current_ratings > 0].cpu().tolist()\n",
    "            \n",
    "            user_ratings = torch.index_select(target_dense[user], 0, target_recommended[user])\n",
    "            user_target = target_recommended[user][user_ratings > 0].cpu().tolist()\n",
    "            \n",
    "            import copy\n",
    "            user_pred = copy.copy(pops)\n",
    "            for item in user_current:\n",
    "                if item in user_pred:\n",
    "                    user_pred.remove(item)\n",
    "            \n",
    "            user_pred = user_pred[:k]    \n",
    "            counter = 0\n",
    "            total = min(k, len(user_target))\n",
    "            for target in user_target:\n",
    "                if target in user_pred:\n",
    "                    counter += 1\n",
    "            # counter = len(recommendations)\n",
    "\n",
    "            recall.append(counter / total)\n",
    "            hitrates.append(min(1, counter))\n",
    "\n",
    "            # nDCG\n",
    "            idcg = np.sum([1 / np.log2(i+2) for i in range(min(k, len(user_target)))])\n",
    "            dcg = 0\n",
    "            for i, r in enumerate(user_pred):\n",
    "                if r in user_target:\n",
    "                    dcg += 1 / np.log2(i+2)\n",
    "\n",
    "            nDCG.append(dcg / idcg) \n",
    "\n",
    "    return hitrates, recall, nDCG"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "hr, r, ndcg = compute_hr2(train_matrix, test_matrix, pop)\n",
    "# print(hr, r, ndcg)\n",
    "print(\"hr\", np.average(hr))\n",
    "print(\"recall\", np.average(r))\n",
    "print(\"ndcg\", np.average(ndcg))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## calculate HR , Recall & NDCG for our RBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_rbm(rbm):\n",
    "    print(\"Vanilla RBM\")\n",
    "    hr, r, ndcg = compute_hr(train_matrix, test_matrix, rbm, p=True)\n",
    "    # print(hr, r, ndcg)\n",
    "    print(\"hr\", np.average(hr))\n",
    "    print(\"recall\", np.average(r))\n",
    "    print(\"ndcg\", np.average(ndcg))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training\n",
      "RBM 0\n",
      "Vanilla RBM\n",
      "{7168, 1923, 5128, 5384, 5642, 268, 7183, 6801, 1682, 6933, 2454, 3991, 5787, 1567, 7199, 1825, 1826, 3876, 4142, 1200, 7219, 1459, 5300, 5432, 5434, 6459, 6719, 7104, 7107, 323, 3907, 6980, 976, 4946, 7251, 1620, 5204, 7256, 2016, 96, 3297, 7268, 7269, 487, 109, 3057, 3446, 3832, 506}\n",
      "49\n",
      "hr 0.06722222222222222\n",
      "recall 0.018407480893592006\n",
      "ndcg 0.013182916231564994\n",
      "start training\n",
      "RBM 1\n",
      "Vanilla RBM\n",
      "{6149, 5770, 2319, 6288, 5010, 789, 2074, 3741, 6440, 4272, 690, 1843, 2994, 1715, 4278, 5690, 2619, 4158, 461, 5714, 5846, 5720, 2009, 5337, 1754, 4443, 2781, 6367, 7267, 3686, 2923, 3821, 4462, 2286, 3184, 5616, 5234, 6902, 2173}\n",
      "39\n",
      "hr 0.02624074074074074\n",
      "recall 0.007698949147560258\n",
      "ndcg 0.003972225849196765\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rbms = []\n",
    "for i in range(2):\n",
    "    rbm = create_rbm(train_matrix, test_matrix, 5, 2000, 10, train_errors=[], test_errors=[])[0]\n",
    "    print(f\"RBM {i}\")\n",
    "    evaluate_rbm(rbm)\n",
    "    torch.save(rbm.state_dict(), f\"./rbm5-10-nr{i}.network\")\n",
    "    rbms.append(rbm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# recommend for single user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend(rbm, v, vt, k, p=True):\n",
    "    \"\"\"\n",
    "    use our model to get recommendations for a single user to reach qualitative metrics\n",
    "    :param rbm: our model\n",
    "    :param v: \n",
    "    :param vt: \n",
    "    :param k: \n",
    "    :param p: \n",
    "    :return: \n",
    "    \"\"\"\n",
    "    target_data = vt.data\n",
    "    target_index = vt.indices\n",
    "    target_recommendations = target_index[target_data == 1]\n",
    "    v = v.todense()\n",
    "    v = torch.Tensor(v)\n",
    "    if torch.cuda.is_available():\n",
    "        v = v.cuda()\n",
    "    \n",
    "    _, h = rbm.sample_h(v)\n",
    "    recommended, _ = rbm.sample_v(h)\n",
    "\n",
    "    # all recommendations\n",
    "    values, indices =  torch.topk(recommended[v < 1], k)\n",
    "    recommendations = indices.cpu().tolist()\n",
    "\n",
    "    if p:\n",
    "        print(\"average value\", torch.mean(recommended[0]))\n",
    "\n",
    "    found = True\n",
    "    for r in recommendations:\n",
    "        if r in target_recommendations:\n",
    "            if p:\n",
    "                print(\"HIT\")\n",
    "            found = True\n",
    "            break\n",
    "\n",
    "    if found and p:\n",
    "        print(\"values\", values)\n",
    "        print(\"recommended\", recommendations)\n",
    "        print(\"real\", target_recommendations)\n",
    "        print(\"len real\", len(target_recommendations))\n",
    "\n",
    "    \n",
    "    \n",
    "    return recommendations\n",
    "\n",
    "user = 100\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparam searching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [04:52<00:00,  5.86s/it]\n",
      "100%|██████████| 31/31 [00:07<00:00,  4.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:28<00:00,  5.74s/it]\n",
      "100%|██████████| 31/31 [00:07<00:00,  4.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:29<00:00,  5.92s/it]\n",
      " 74%|███████▍  | 23/31 [00:06<00:02,  3.57it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_26164/4117137640.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrbm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mf\"./network-{n_hidden}-steam{epoch}-train0\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m         \u001b[0mhr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mndcg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute_hr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_matrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_matrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrbm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m         \u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34mf\"{epoch}-{n_hidden}\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maverage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maverage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maverage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mndcg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mprev_epoch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_26164/2455127381.py\u001b[0m in \u001b[0;36mcompute_hr\u001b[1;34m(train_matrix, test_matrix, rbm, k, batch_size)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m             \u001b[1;31m# all recommendations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m             \u001b[0muser_target\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtarget_movie\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0muser\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m             \u001b[0muser_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredicted_movie\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0muser\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = [5, 10, 25, 50, 100]\n",
    "hidden = [10, 25, 50, 75, 100]\n",
    "rbms = []\n",
    "results = {}\n",
    "\n",
    "for n_hidden in hidden:\n",
    "    rbm = None\n",
    "    prev_epoch = 0\n",
    "    train = []\n",
    "    test = []\n",
    "    for epoch in epochs:\n",
    "        rbm, train, test = create_rbm(train_matrix, test_matrix, n_hidden, 2000, epoch - prev_epoch, rbm, train_errors=train, test_errors=test)\n",
    "        torch.save(rbm.state_dict(), f\"./network-{n_hidden}-steam{epoch}-train0\")\n",
    "\n",
    "        hr, r, ndcg = compute_hr(train_matrix, test_matrix, rbm)\n",
    "        results[f\"{epoch}-{n_hidden}\"] = (np.average(hr), np.average(r), np.average(ndcg))\n",
    "        prev_epoch = epoch\n",
    "    rbms.append(rbm)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble of ANTI-RBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ensemble_hr(train_matrix, test_matrix, rbms: list[RBM], k=10, rating_cutoff=-1, p=False):\n",
    "    \"\"\"\n",
    "    compute the various metrics of our model, hr, recall and ndcg\n",
    "    :param train_matrix: the input wich our user already has\n",
    "    :param test_matrix: the games we are trying to recommend to each user\n",
    "    :param rbm: our model used to make recommendations\n",
    "    :param k: the amount of recommendations we are going to give\n",
    "    :param batch_size: UNUSED, uses rbm.batch_size instead\n",
    "    :return: hitrates, recall, nDCG as an array, use np.average to get value\n",
    "    \"\"\"\n",
    "    hitrates = []\n",
    "    recall = []\n",
    "    nDCG = []\n",
    "    batch_size = rbms[0].batch_size\n",
    "\n",
    "    recommended_games_set = set()\n",
    "    # for loop - go through every single user\n",
    "    # for id_user in tqdm(range(0, train_matrix.shape[0] - rbm.batch_size, rbm.batch_size)): # - batch_size, batch_size):\n",
    "    for id_user in trange(0, train_matrix.shape[0] - batch_size, batch_size): # - batch_size, batch_size):\n",
    "        v = train_matrix[id_user:id_user + batch_size]  # training set inputs are used to activate neurons of my RBM\n",
    "        vt = test_matrix[id_user:id_user + batch_size]  # target\n",
    "        if vt.getnnz() == 0:\n",
    "            continue\n",
    "\n",
    "        v = convert_sparse_matrix_to_sparse_tensor(v)\n",
    "        vt = convert_sparse_matrix_to_sparse_tensor(vt)\n",
    "        v = v.to_dense()\n",
    "        vt = vt.to_dense()\n",
    "        v = v.sub(1)\n",
    "        vt = vt.sub(1)\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            vt = vt.cuda()\n",
    "            v = v.cuda()\n",
    "\n",
    "        # ground truth\n",
    "        ratings, users, movies = (vt > 0).nonzero(as_tuple=True)\n",
    "\n",
    "        indices = torch.stack([users, movies])\n",
    "        shape = (batch_size, train_matrix.shape[1])\n",
    "        target = torch.sparse.LongTensor(indices, torch.add(ratings, 1), torch.Size(shape))\n",
    "        target_dense = target.to_dense()\n",
    "\n",
    "        target_recommended = torch.argsort(target_dense, 1, descending=True)\n",
    "\n",
    "        # predicted\n",
    "        pred_ratings = []\n",
    "        pred_movies = []\n",
    "        for rbm in rbms:\n",
    "            _, h = rbm.sample_h(v)\n",
    "            recommended, _ = rbm.sample_v(h)\n",
    "\n",
    "            scaled_tensors = [recommended[0]]\n",
    "            for i in range(1, rbm.K):\n",
    "                scaled_tensors.append(recommended[i] * (i+1))\n",
    "            recommended_scaled = torch.stack(scaled_tensors)\n",
    "            recommended_summed = torch.sum(recommended_scaled, 0)\n",
    "            pred_rating, pred_movie = torch.topk(recommended_summed, k)\n",
    "            pred_ratings.append(pred_rating)\n",
    "            pred_movies.append(pred_movie)\n",
    "\n",
    "        predicted_ratings = torch.cat(pred_ratings, dim=1)\n",
    "        predicted_movies = torch.cat(pred_movies, dim=1)\n",
    "        _, predicted_indices = torch.topk(predicted_ratings, k)\n",
    "\n",
    "\n",
    "        for user in range(batch_size):\n",
    "            # all recommendations\n",
    "            user_ratings = torch.index_select(target_dense[user], 0, target_recommended[user])\n",
    "            user_target = target_recommended[user][user_ratings > 0].cpu().tolist()\n",
    "\n",
    "            # user_target = target_recommended[user][target_rating[user] > rating_cutoff].cpu().tolist()\n",
    "            user_pred = torch.index_select(predicted_movies[user], 0, predicted_indices[0])\n",
    "\n",
    "            recommended_games_set = recommended_games_set.union(set(user_pred))\n",
    "            counter = 0\n",
    "            total = min(k, len(user_target))\n",
    "            for target in user_target:\n",
    "                if target in user_pred:\n",
    "                    counter += 1\n",
    "            # counter = len(recommendations)\n",
    "\n",
    "            recall.append(counter / total)\n",
    "            hitrates.append(min(1, counter))\n",
    "\n",
    "            # nDCG\n",
    "            idcg = np.sum([1 / np.log2(i+2) for i in range(min(k, len(user_target)))])\n",
    "            dcg = 0\n",
    "            for i, r in enumerate(user_pred):\n",
    "                if r in user_target:\n",
    "                    dcg += 1 / np.log2(i+2)\n",
    "\n",
    "            nDCG.append(dcg / idcg) \n",
    "\n",
    "    if p:\n",
    "        print(recommended_games_set)\n",
    "        print(len(recommended_games_set))\n",
    "    return hitrates, recall, nDCG\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_28924/1209570929.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcompute_ensemble_hr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_matrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_matrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrbms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_28924/1150893796.py\u001b[0m in \u001b[0;36mcompute_ensemble_hr\u001b[1;34m(train_matrix, test_matrix, rbms, k, rating_cutoff, p)\u001b[0m\n\u001b[0;32m     87\u001b[0m             \u001b[0midcg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muser_target\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m             \u001b[0mdcg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muser_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     90\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0muser_target\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m                     \u001b[0mdcg\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hr, r, ndcg = compute_ensemble_hr(train_matrix, test_matrix, rbms)\n",
    "print(np.average(hr), np.average(r), np.average(ndcg))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ac59ebe37160ed0dfa835113d9b8498d9f09ceb179beaac4002f036b9467c963"
  },
  "kernelspec": {
   "display_name": "PyCharm (ai-project)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
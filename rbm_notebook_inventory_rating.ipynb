{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Restricted Boltzmann Machine Defintion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Import PyTorch library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "device = torch.device('cpu')\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### the Restricted Boltzmann Machine architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# https://github.com/khanhnamle1994/MetaRec/blob/b5e36cb579a88b32cdfb728f35f645d76b24ad95/Boltzmann-Machines-Experiments/RBM-CF-PyTorch/rbm.py#L23\n",
    "# \n",
    "class RBM(nn.Module):\n",
    "    def __init__(self, n_vis, n_hid, k, batch_size):\n",
    "        \"\"\"\n",
    "        Initialize the parameters (weights and biases) we optimize during the training process\n",
    "        :param n_vis: number of visible units\n",
    "        :param n_hid: number of hidden units\n",
    "        \"\"\"\n",
    "        self.i = 0\n",
    "        self.K = k\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        # Weights used for the probability of the visible units given the hidden units\n",
    "        super().__init__()\n",
    "        self.W = torch.randn(k, n_hid, n_vis)  # torch.rand: random normal distribution mean = 0, variance = 1\n",
    "\n",
    "        # Bias probability of the visible units is activated, given the value of the hidden units (p_v_given_h)\n",
    "        self.v_bias = torch.zeros(k, 1, n_vis)  # fake dimension for the batch = 1\n",
    "\n",
    "        # Bias probability of the hidden units is activated, given the value of the visible units (p_h_given_v)\n",
    "        self.h_bias = torch.zeros(1, n_hid)  # fake dimension for the batch = 1\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            self.W = self.W.cuda()\n",
    "            self.v_bias = self.v_bias.cuda()\n",
    "            self.h_bias = self.h_bias.cuda()\n",
    "    \n",
    "    def lr(self):\n",
    "        \"\"\"\n",
    "        return the learning rate of the model, lr is based on batchsize\n",
    "        :return: constant/batch_size\n",
    "        \"\"\"\n",
    "        return 0.01 / self.batch_size\n",
    "\n",
    "    def sample_h(self, x):\n",
    "        \"\"\"\n",
    "        Sample the hidden units\n",
    "        :param x: the dataset\n",
    "        \"\"\"\n",
    "\n",
    "        # Probability h is activated given that the value v is sigmoid(Wx + a)\n",
    "        # torch.mm make the product of 2 tensors\n",
    "        # W.t() take the transpose because W is used for the p_v_given_h\n",
    "\n",
    "        temp = torch.transpose(self.W, 1, 2)\n",
    "\n",
    "        wxs = []\n",
    "        for i in range(self.K):\n",
    "            wxs.append(torch.mm(x[i], temp[i]))\n",
    "            \n",
    "        wx = torch.stack(wxs)\n",
    "        wx_sum = torch.sum(wx, 0)\n",
    "\n",
    "        # Expand the mini-batch\n",
    "        activation = wx_sum + self.h_bias.expand_as(wx_sum)\n",
    "\n",
    "        # Calculate the probability p_h_given_v\n",
    "        p_h_given_v = torch.sigmoid(activation)\n",
    "\n",
    "        # Construct a Bernoulli RBM to predict whether an user loves the movie or not (0 or 1)\n",
    "        # This corresponds to whether the n_hid is activated or not activated\n",
    "        return p_h_given_v, torch.bernoulli(p_h_given_v)\n",
    "\n",
    "    def sample_v(self, y):\n",
    "        \"\"\"\n",
    "        Sample the visible units\n",
    "        :param y: the dataset\n",
    "        \"\"\"\n",
    "\n",
    "        exponents = []\n",
    "        for k in range(self.K):\n",
    "            wy = torch.mm(y, self.W[k])\n",
    "            activation = wy + self.v_bias[k].expand_as(wy)\n",
    "            exponents.append(torch.exp(activation))\n",
    "\n",
    "        exponent_tensor = torch.stack(exponents)\n",
    "        exponent_sum = torch.sum(exponent_tensor, 0)\n",
    "        probs = []\n",
    "        for k in range(self.K):\n",
    "            p_v_k_given_h = exponent_tensor[k] / exponent_sum\n",
    "            probs.append(p_v_k_given_h)\n",
    "\n",
    "        p_v_given_h = torch.stack(probs)\n",
    "        # todo multinomial\n",
    "        bern = torch.bernoulli(p_v_given_h)\n",
    "        return p_v_given_h, bern\n",
    "\n",
    "\n",
    "    def train_model(self, v0, vk, ph0, phk):\n",
    "        \"\"\"\n",
    "        Perform contrastive divergence algorithm to optimize the weights that minimize the energy\n",
    "        This maximizes the log-likelihood of the model\n",
    "        \"\"\"\n",
    "\n",
    "        ph0_K = torch.stack([ph0 for _ in range(self.K)])\n",
    "        phk_K = torch.stack([phk for _ in range(self.K)])\n",
    "\n",
    "        poss = []\n",
    "        negs = []\n",
    "        for i in range(self.K):\n",
    "            poss.append(torch.mm(torch.transpose(v0, 1, 2)[i], ph0_K[i]))\n",
    "            negs.append(torch.mm(torch.transpose(vk, 1, 2)[i], phk_K[i]))\n",
    "\n",
    "        pos = torch.stack(poss)\n",
    "        neg = torch.stack(negs)\n",
    "\n",
    "        w_extra = torch.transpose(pos - neg, 1, 2)\n",
    "        v_extra = torch.sum((v0 - vk), 1)\n",
    "        h_extra = torch.sum((ph0 - phk), 0)\n",
    "\n",
    "        # Approximate the gradients with the CD algorithm\n",
    "        self.W -= self.lr() * w_extra\n",
    "\n",
    "        # Add (difference, 0) for the tensor of 2 dimensions\n",
    "        self.v_bias -= self.lr() * v_extra.unsqueeze(1)\n",
    "        self.h_bias -= self.lr() * h_extra\n",
    "        self.i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "cuda = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle as pickle\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "import gzip\n",
    "import json\n",
    "from tqdm import tqdm, trange\n",
    "import os\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "import math\n",
    "tqdm.pandas() #for progres_apply etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in steamdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_interactions(path, n_splits=5):\n",
    "    \"\"\"\n",
    "    load in the interactions_splits.pkl.gz file with our data for the various users\n",
    "    :param path: path location of the data\n",
    "    :param n_splits: split in n_split splits\n",
    "    :return: \n",
    "    \"\"\"\n",
    "    df = pd.read_pickle(os.path.join(os.getcwd(), path))\n",
    "    df[['interactions', 'train', 'val', 'test']] = df[['interactions', 'train', 'val', 'test']].applymap(lambda x: np.array(x, dtype=np.int32))\n",
    "    interactions_dict = {}\n",
    "    for split in trange(n_splits):\n",
    "        for column in ['train', 'val', 'test']:\n",
    "            interactions_dict[split, column] = pd.DataFrame({\n",
    "                'user_id': df['user_id'],\n",
    "                'steam_id': df['steam_id'],\n",
    "                'item_id': df[column].apply(lambda x: x[split, 0]),\n",
    "                'playtime_forever': df[column].apply(lambda x: x[split, 1]),\n",
    "                'playtime_2weeks': df[column].apply(lambda x: x[split, 2])})\n",
    "    return interactions_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Reading and showning train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00,  8.26it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>steam_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>playtime_forever</th>\n",
       "      <th>playtime_2weeks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>76561197981203305</td>\n",
       "      <td>76561197981203305</td>\n",
       "      <td>[1461, 1999, 1984, 761, 2820, 819, 187, 506, 3...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bosslucek</td>\n",
       "      <td>76561198029968002</td>\n",
       "      <td>[4014, 1018, 3632, 2843, 2755, 219, 6245, 2621...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>icantwait</td>\n",
       "      <td>76561197971666535</td>\n",
       "      <td>[886, 2010, 419, 2217, 1293, 2809, 802, 155, 2...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>76561198067911521</td>\n",
       "      <td>76561198067911521</td>\n",
       "      <td>[1849, 1038, 229, 400, 1386, 1437, 1363, 515, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kushziller</td>\n",
       "      <td>76561198021307778</td>\n",
       "      <td>[2883, 401, 2243, 4408, 3966, 1487, 1888, 2708...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             user_id           steam_id  \\\n",
       "0  76561197981203305  76561197981203305   \n",
       "1          bosslucek  76561198029968002   \n",
       "2          icantwait  76561197971666535   \n",
       "3  76561198067911521  76561198067911521   \n",
       "4         kushziller  76561198021307778   \n",
       "\n",
       "                                             item_id  \\\n",
       "0  [1461, 1999, 1984, 761, 2820, 819, 187, 506, 3...   \n",
       "1  [4014, 1018, 3632, 2843, 2755, 219, 6245, 2621...   \n",
       "2  [886, 2010, 419, 2217, 1293, 2809, 802, 155, 2...   \n",
       "3  [1849, 1038, 229, 400, 1386, 1437, 1363, 515, ...   \n",
       "4  [2883, 401, 2243, 4408, 3966, 1487, 1888, 2708...   \n",
       "\n",
       "                                    playtime_forever  \\\n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                     playtime_2weeks  \n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interactions = load_interactions(\"./data-cleaned/interactions_splits.pkl.gz\")\n",
    "interactions[0, 'train'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Reading and showing list of games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>publisher</th>\n",
       "      <th>genres</th>\n",
       "      <th>app_name</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>release_date</th>\n",
       "      <th>tags</th>\n",
       "      <th>discount_price</th>\n",
       "      <th>reviews_url</th>\n",
       "      <th>specs</th>\n",
       "      <th>price</th>\n",
       "      <th>early_access</th>\n",
       "      <th>id</th>\n",
       "      <th>developer</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>metascore</th>\n",
       "      <th>users_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rockstar Games</td>\n",
       "      <td>[Action]</td>\n",
       "      <td>Grand Theft Auto: Episodes from Liberty City</td>\n",
       "      <td>Grand Theft Auto: Episodes from Liberty City</td>\n",
       "      <td>http://store.steampowered.com/app/12220/Grand_...</td>\n",
       "      <td>2010-04-12</td>\n",
       "      <td>[Open World, Action, Third Person, Multiplayer...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://steamcommunity.com/app/12220/reviews/?b...</td>\n",
       "      <td>[Single-player, Multi-player]</td>\n",
       "      <td>19.99</td>\n",
       "      <td>False</td>\n",
       "      <td>12220</td>\n",
       "      <td>Rockstar North / Toronto</td>\n",
       "      <td>Mostly Positive</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Valve</td>\n",
       "      <td>[Action]</td>\n",
       "      <td>Half-Life</td>\n",
       "      <td>Half-Life</td>\n",
       "      <td>http://store.steampowered.com/app/70/HalfLife/</td>\n",
       "      <td>1998-11-08</td>\n",
       "      <td>[FPS, Classic, Action, Sci-fi, Singleplayer, S...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://steamcommunity.com/app/70/reviews/?brow...</td>\n",
       "      <td>[Single-player, Multi-player, Valve Anti-Cheat...</td>\n",
       "      <td>9.99</td>\n",
       "      <td>False</td>\n",
       "      <td>70</td>\n",
       "      <td>Valve</td>\n",
       "      <td>Overwhelmingly Positive</td>\n",
       "      <td>96</td>\n",
       "      <td>7575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Trion Worlds, Inc.</td>\n",
       "      <td>[Action, Free to Play, Massively Multiplayer, ...</td>\n",
       "      <td>Defiance</td>\n",
       "      <td>Defiance</td>\n",
       "      <td>http://store.steampowered.com/app/224600/Defia...</td>\n",
       "      <td>2014-06-04</td>\n",
       "      <td>[Free to Play, Action, Open World, Massively M...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://steamcommunity.com/app/224600/reviews/?...</td>\n",
       "      <td>[Multi-player, MMO, Co-op, Steam Trading Cards...</td>\n",
       "      <td>Free to Play</td>\n",
       "      <td>False</td>\n",
       "      <td>224600</td>\n",
       "      <td>Trion Worlds, Inc.</td>\n",
       "      <td>Mostly Positive</td>\n",
       "      <td>64</td>\n",
       "      <td>7539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bohemia Interactive</td>\n",
       "      <td>[Action, Simulation, Strategy]</td>\n",
       "      <td>Arma 3</td>\n",
       "      <td>Arma 3</td>\n",
       "      <td>http://store.steampowered.com/app/107410/Arma_3/</td>\n",
       "      <td>2013-09-12</td>\n",
       "      <td>[Simulation, Military, Multiplayer, Realistic,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://steamcommunity.com/app/107410/reviews/?...</td>\n",
       "      <td>[Single-player, Multi-player, Online Multi-Pla...</td>\n",
       "      <td>39.99</td>\n",
       "      <td>False</td>\n",
       "      <td>107410</td>\n",
       "      <td>Bohemia Interactive</td>\n",
       "      <td>Very Positive</td>\n",
       "      <td>74</td>\n",
       "      <td>7527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Unknown Worlds Entertainment</td>\n",
       "      <td>[Action, Indie, Strategy]</td>\n",
       "      <td>Natural Selection 2</td>\n",
       "      <td>Natural Selection 2</td>\n",
       "      <td>http://store.steampowered.com/app/4920/Natural...</td>\n",
       "      <td>2012-10-30</td>\n",
       "      <td>[Multiplayer, Strategy, FPS, Team-Based, Actio...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://steamcommunity.com/app/4920/reviews/?br...</td>\n",
       "      <td>[Multi-player, Online Multi-Player, Steam Achi...</td>\n",
       "      <td>9.99</td>\n",
       "      <td>False</td>\n",
       "      <td>4920</td>\n",
       "      <td>Unknown Worlds Entertainment</td>\n",
       "      <td>Very Positive</td>\n",
       "      <td>80</td>\n",
       "      <td>7502</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      publisher  \\\n",
       "0                Rockstar Games   \n",
       "1                         Valve   \n",
       "2            Trion Worlds, Inc.   \n",
       "3           Bohemia Interactive   \n",
       "4  Unknown Worlds Entertainment   \n",
       "\n",
       "                                              genres  \\\n",
       "0                                           [Action]   \n",
       "1                                           [Action]   \n",
       "2  [Action, Free to Play, Massively Multiplayer, ...   \n",
       "3                     [Action, Simulation, Strategy]   \n",
       "4                          [Action, Indie, Strategy]   \n",
       "\n",
       "                                       app_name  \\\n",
       "0  Grand Theft Auto: Episodes from Liberty City   \n",
       "1                                     Half-Life   \n",
       "2                                      Defiance   \n",
       "3                                        Arma 3   \n",
       "4                           Natural Selection 2   \n",
       "\n",
       "                                          title  \\\n",
       "0  Grand Theft Auto: Episodes from Liberty City   \n",
       "1                                     Half-Life   \n",
       "2                                      Defiance   \n",
       "3                                        Arma 3   \n",
       "4                           Natural Selection 2   \n",
       "\n",
       "                                                 url release_date  \\\n",
       "0  http://store.steampowered.com/app/12220/Grand_...   2010-04-12   \n",
       "1     http://store.steampowered.com/app/70/HalfLife/   1998-11-08   \n",
       "2  http://store.steampowered.com/app/224600/Defia...   2014-06-04   \n",
       "3   http://store.steampowered.com/app/107410/Arma_3/   2013-09-12   \n",
       "4  http://store.steampowered.com/app/4920/Natural...   2012-10-30   \n",
       "\n",
       "                                                tags  discount_price  \\\n",
       "0  [Open World, Action, Third Person, Multiplayer...             NaN   \n",
       "1  [FPS, Classic, Action, Sci-fi, Singleplayer, S...             NaN   \n",
       "2  [Free to Play, Action, Open World, Massively M...             NaN   \n",
       "3  [Simulation, Military, Multiplayer, Realistic,...             NaN   \n",
       "4  [Multiplayer, Strategy, FPS, Team-Based, Actio...             NaN   \n",
       "\n",
       "                                         reviews_url  \\\n",
       "0  http://steamcommunity.com/app/12220/reviews/?b...   \n",
       "1  http://steamcommunity.com/app/70/reviews/?brow...   \n",
       "2  http://steamcommunity.com/app/224600/reviews/?...   \n",
       "3  http://steamcommunity.com/app/107410/reviews/?...   \n",
       "4  http://steamcommunity.com/app/4920/reviews/?br...   \n",
       "\n",
       "                                               specs         price  \\\n",
       "0                      [Single-player, Multi-player]         19.99   \n",
       "1  [Single-player, Multi-player, Valve Anti-Cheat...          9.99   \n",
       "2  [Multi-player, MMO, Co-op, Steam Trading Cards...  Free to Play   \n",
       "3  [Single-player, Multi-player, Online Multi-Pla...         39.99   \n",
       "4  [Multi-player, Online Multi-Player, Steam Achi...          9.99   \n",
       "\n",
       "   early_access      id                     developer  \\\n",
       "0         False   12220      Rockstar North / Toronto   \n",
       "1         False      70                         Valve   \n",
       "2         False  224600            Trion Worlds, Inc.   \n",
       "3         False  107410           Bohemia Interactive   \n",
       "4         False    4920  Unknown Worlds Entertainment   \n",
       "\n",
       "                 sentiment metascore  users_count  \n",
       "0          Mostly Positive       NaN         7597  \n",
       "1  Overwhelmingly Positive        96         7575  \n",
       "2          Mostly Positive        64         7539  \n",
       "3            Very Positive        74         7527  \n",
       "4            Very Positive        80         7502  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "games = pd.read_pickle(os.path.join(os.getcwd(), \"./data-cleaned/games.pkl.gz\"))\n",
    "games.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train0 = interactions[0, 'train']\n",
    "test0 = interactions[0, 'test']\n",
    "val0 = interactions[0, 'val']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train1 = interactions[1, 'train']\n",
    "test1 = interactions[1, 'test']\n",
    "val1 = interactions[1, 'val']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train2 = interactions[2, 'train']\n",
    "test2 = interactions[2, 'test']\n",
    "val2 = interactions[2, 'val']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sparse Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method to create Sparse Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def score_playtime(playtime):\n",
    "    \"\"\"\n",
    "    give a game a raining score between 0 and 4 \n",
    "    :param playtime: the playtime to give a score by\n",
    "    :return: 0,1,2,3 or 4 based on playtime\n",
    "    \"\"\"\n",
    "    if playtime < 120:\n",
    "        # less than 2 hrs\n",
    "        return 0\n",
    "    elif playtime < 240:\n",
    "        # less than 4 hrs\n",
    "        return 1\n",
    "    elif playtime < 600:\n",
    "        # less than 10 hrs\n",
    "        return 2\n",
    "    elif playtime < 24*60:\n",
    "        # less than 24 hrs\n",
    "        return 3\n",
    "    else:\n",
    "        return 4\n",
    "\n",
    "from os import path\n",
    "if not path.isfile('index_random_ordering-cedric-new.pkl'):\n",
    "    import random\n",
    "    index_random_list =list(range(games.shape[0]))\n",
    "    random.shuffle(index_random_list)\n",
    "    # print(index_random_list)\n",
    "    file = open(\"index_random_ordering-new.pkl\", \"wb\")\n",
    "    pickle.dump(index_random_list, file)\n",
    "    file.close()\n",
    "else:\n",
    "    f = open(\"index_random_ordering-cedric-new.pkl\", \"rb\")\n",
    "    index_random_list = pickle.load(f)\n",
    "    f.close()\n",
    "\n",
    "def shuffle_item_index(items):\n",
    "    global index_random_list\n",
    "    return [index_random_list[item] for item in items]\n",
    "\n",
    "def invert_items(items, max_item: int):\n",
    "    return [max_item - item for item in items]\n",
    "\n",
    "#Create scipy csr matrix\n",
    "def get_sparse_matrix(df):\n",
    "    \"\"\"\n",
    "    generate a sparse matrix of user-game pairs based on our dataframe\n",
    "    :param df: the dataframe to base the sparse matrix upon\n",
    "    :return: a sparse matrix of user-game pairs with a score based on playtime\n",
    "    \"\"\"\n",
    "    shape = (df.shape[0], games.shape[0])\n",
    "    max_game = games.shape[0] - 1\n",
    "    \n",
    "    user_ids = []\n",
    "    item_ids = []\n",
    "    values = []\n",
    "    for idx, row in df.iterrows():\n",
    "        user = idx\n",
    "        items = row['item_id']\n",
    "        # items = invert_items(items, max_game)\n",
    "        items = shuffle_item_index(items)\n",
    "        score = row[\"playtime_forever\"] + 2* row[\"playtime_2weeks\"]\n",
    "        \n",
    "        user_ids.extend([user] * len(items))\n",
    "        item_ids.extend(items)\n",
    "        values.extend([score_playtime(score[i]) for i in range(len(items))])\n",
    "    # create csr matrix\n",
    "    matrix = scipy.sparse.csr_matrix((values, (user_ids, item_ids)), shape=shape, dtype=np.int32)\n",
    "    return matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### generate the Sparse Matrisces for train AND test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<54190x7276 sparse matrix of type '<class 'numpy.intc'>'\n",
       "\twith 1407708 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_matrix = get_sparse_matrix(train0)\n",
    "test_matrix = get_sparse_matrix(test0)\n",
    "val_matrix = get_sparse_matrix(val0)\n",
    "train_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Method to convert Sparse Matrix to pytorch tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# https://stackoverflow.com/questions/40896157/scipy-sparse-csr-matrix-to-tensorflow-sparsetensor-mini-batch-gradient-descent\n",
    "def convert_sparse_matrix_to_sparse_tensor(X, k=5):\n",
    "    \"\"\"\n",
    "    turn the Sparse scipy matrix into a sparse pytorch tensor\n",
    "    :param X: the Sparse scipy matrix\n",
    "    :param k: the amount of possible ratings we have given to our user-game pairs\n",
    "    :return: a sparse 3-D pytorch tensor of dimensions game-user-rating\n",
    "    \"\"\"\n",
    "    coo = X.tocoo()\n",
    "\n",
    "    values = coo.data\n",
    "    indices = np.vstack((coo.row, coo.col))\n",
    "    i = torch.LongTensor(indices)\n",
    "    v = torch.DoubleTensor(values)\n",
    "    tensor_list = []\n",
    "\n",
    "    for index in range(k):\n",
    "        value = index\n",
    "        yeet = torch.where(v == value, 2., 1.)\n",
    "        shape = coo.shape\n",
    "        tensor = torch.sparse.DoubleTensor(i, yeet, torch.Size(shape)) \n",
    "        if torch.cuda.is_available():\n",
    "            tensor = tensor.cuda()\n",
    "\n",
    "        tensor_list.append(tensor)\n",
    "\n",
    "    tensor = torch.stack(tensor_list) \n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def score_model(rbm: RBM, batch_size, train_matrix, test_matrix):\n",
    "    \"\"\"\n",
    "    calculate an error for the output of our rbm for the unseen (and untrained upon) test-values\n",
    "    :param rbm: the model for which we test values\n",
    "    :param batch_size: the batchsize used for training/testing\n",
    "    :param train_matrix: the original input with which we try to get our test-values\n",
    "    :param test_matrix: the values we try for our model to acquire based on train_matrix\n",
    "    :return: the RMSE for our test-values\n",
    "    \"\"\"\n",
    "    test_recon_error = 0  # RMSE reconstruction error initialized to 0 at the beginning of training\n",
    "    s = 0  # a counter (float type) \n",
    "    # for loop - go through every single user\n",
    "    for id_user in range(0, train_matrix.shape[0] - batch_size, batch_size):\n",
    "        v = train_matrix[id_user:id_user + batch_size]  # training set inputs are used to activate neurons of my RBM\n",
    "        vt = test_matrix[id_user:id_user + batch_size]  # target\n",
    "        v = convert_sparse_matrix_to_sparse_tensor(v)\n",
    "        vt = convert_sparse_matrix_to_sparse_tensor(vt)\n",
    "\n",
    "        v = v.to_dense()\n",
    "        vt = vt.to_dense()\n",
    "        v = v.sub(1)\n",
    "        vt = vt.sub(1)\n",
    "        if torch.cuda.is_available():\n",
    "            v = v.cuda()\n",
    "            vt = vt.cuda()\n",
    "\n",
    "        if len(vt[vt > -1]) > 0:\n",
    "            _, h = rbm.sample_h(v)\n",
    "            _, v = rbm.sample_v(h)\n",
    "\n",
    "            # Update test RMSE reconstruction error\n",
    "            test_recon_error += torch.mean((vt[vt > -1] - v[vt > -1])**2) * len(vt > -1) \n",
    "            s += len(vt > -1)\n",
    "\n",
    "    return torch.sqrt(test_recon_error / s)\n",
    "\n",
    "\n",
    "def create_rbm(train_matrix, test_matrix, n_hidden, batch_size, epochs, rbm=None, k=5, train_errors=[], test_errors=[]) -> RBM:\n",
    "    \"\"\"\n",
    "    generate and train an RBM based on train_matrix as input\n",
    "    :param train_matrix: the input upon which our model is trained\n",
    "    :param test_matrix: the input upon which our model is validated\n",
    "    :param n_hidden: the amount of hidden features our model uses\n",
    "    :param batch_size: the batchsize we use\n",
    "    :param epochs: the amount of epochs we will be running\n",
    "    :param rbm: an optional variable that if not None trains a pre-generated model further instead of generating a new one\n",
    "    :param k: the amount of possible ratings we have given to our user-game pairs\n",
    "    :return: a trained RBM\n",
    "    \"\"\"\n",
    "    n_vis = train_matrix.shape[1]\n",
    "    if rbm is None:\n",
    "        rbm = RBM(n_vis, n_hidden, k, batch_size)\n",
    "    \n",
    "    oldhr, oldr, oldndcg = 0, 0, 0\n",
    "    # hr, r, ndcg = compute_hr(train_matrix, test_matrix, rbm)\n",
    "    # print(\"pre training\", np.average(hr), np.average(r), np.average(ndcg))\n",
    "\n",
    "    print(\"start training\")\n",
    "    for epoch in range(epochs):\n",
    "        rbm.train()\n",
    "        train_recon_error = 0  # RMSE reconstruction error initialized to 0 at the beginning of training\n",
    "        s = 0\n",
    "        \n",
    "        for user_id in range(0, train_matrix.shape[0] - batch_size, batch_size):\n",
    "            training_sample = train_matrix[user_id : user_id + batch_size]\n",
    "            v0 = convert_sparse_matrix_to_sparse_tensor(training_sample)\n",
    "\n",
    "            v0 = v0.to_dense()\n",
    "            v0 = v0.sub(1)\n",
    "            \n",
    "            vk = v0.detach().clone()\n",
    "\n",
    "            ph0, _ = rbm.sample_h(v0)\n",
    "            # todo cd = 3\n",
    "            _, hk = rbm.sample_h(vk)\n",
    "            _, vk = rbm.sample_v(hk)\n",
    "            vk[v0 < 0] = v0[v0 < 0]\n",
    "                \n",
    "            phk, _ = rbm.sample_h(vk)\n",
    "\n",
    "            rbm.train_model(v0, vk, ph0, phk)\n",
    "            \n",
    "            train_recon_error += torch.mean((v0[v0 > -1] - vk[v0 > -1])**2) * len(v0 > -1)\n",
    "            s += len(v0 > -1)\n",
    "            \n",
    "        train_errors.append(torch.sqrt(train_recon_error / s))\n",
    "\n",
    "        rbm.eval()\n",
    "        test_errors.append(score_model(rbm, batch_size, train_matrix, test_matrix))\n",
    "\n",
    "        # if epoch % 10 == 9:\n",
    "        #     hr, r, ndcg = compute_hr(train_matrix, test_matrix, rbm)\n",
    "        #     hr, r, ndcg = np.average(hr), np.average(r), np.average(ndcg)\n",
    "        #     print(epoch, hr, r, ndcg)\n",
    "        #     if ndcg < oldndcg:\n",
    "        #         print(\"Stopping training, ndcg decreasing\")\n",
    "        #         break\n",
    "        #     oldhr, oldr, oldndcg = hr, r, ndcg\n",
    "            \n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "    # Plot the RMSE reconstruction error with respect to increasing number of epochs\n",
    "    plt.clf()\n",
    "    plt.plot(torch.Tensor(train_errors, device='cpu'), label=\"train\")\n",
    "    plt.plot(torch.Tensor(test_errors, device='cpu'), label=\"test\")\n",
    "    plt.ylabel('Error')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend()\n",
    "    plt.savefig(f'steam-cleaned-{n_hidden}-{batch_size}-{epochs}.jpg')\n",
    "\n",
    "    return rbm, train_errors, test_errors\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HR / Recall / NDCG Function Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vanilla Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_hr(train_matrix, test_matrix, rbm, k=10, rating_cutoff=-1, p=False):\n",
    "    \"\"\"\n",
    "    compute the various metrics of our model, hr, recall and ndcg\n",
    "    :param train_matrix: the input wich our user already has\n",
    "    :param test_matrix: the games we are trying to recommend to each user\n",
    "    :param rbm: our model used to make recommendations\n",
    "    :param k: the amount of recommendations we are going to give\n",
    "    :param batch_size: UNUSED, uses rbm.batch_size instead\n",
    "    :return: hitrates, recall, nDCG as an array, use np.average to get value\n",
    "    \"\"\"\n",
    "    hitrates = []\n",
    "    recall = []\n",
    "    nDCG = []\n",
    "\n",
    "    recommended_games_set = set()\n",
    "    # for loop - go through every single user\n",
    "    # for id_user in tqdm(range(0, train_matrix.shape[0] - rbm.batch_size, rbm.batch_size)): # - batch_size, batch_size):\n",
    "    for id_user in range(0, train_matrix.shape[0] - rbm.batch_size, rbm.batch_size): # - batch_size, batch_size):\n",
    "        v = train_matrix[id_user:id_user + rbm.batch_size]  # training set inputs are used to activate neurons of my RBM\n",
    "        vt = test_matrix[id_user:id_user + rbm.batch_size]  # target\n",
    "        if vt.getnnz() == 0:\n",
    "            continue\n",
    "\n",
    "        v = convert_sparse_matrix_to_sparse_tensor(v)\n",
    "        vt = convert_sparse_matrix_to_sparse_tensor(vt)\n",
    "        v = v.to_dense()\n",
    "        vt = vt.to_dense()\n",
    "        v = v.sub(1)\n",
    "        vt = vt.sub(1)\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            vt = vt.cuda()\n",
    "            v = v.cuda()\n",
    "\n",
    "        # ground truth\n",
    "        ratings, users, movies = (vt > 0).nonzero(as_tuple=True)\n",
    "\n",
    "        indices = torch.stack([users, movies])\n",
    "        shape = (rbm.batch_size, train_matrix.shape[1])\n",
    "        target = torch.sparse.LongTensor(indices, torch.add(ratings, 1), torch.Size(shape))\n",
    "        target_dense = target.to_dense()\n",
    "\n",
    "        target_recommended = torch.argsort(target_dense, 1, descending=True)\n",
    "        # target_rating, target_movie = torch.topk(target_dense, k, 1)\n",
    "        # target_movie[target_rating < rating_cutoff] = -1 # remove all bad movies from top k\n",
    "\n",
    "        # values, _ = torch.max(target_rating, dim=1)\n",
    "        # users_with_target = (values > rating_cutoff).nonzero(as_tuple=True)[0].cpu().tolist()\n",
    "\n",
    "        # predicted\n",
    "        _, h = rbm.sample_h(v)\n",
    "        recommended, _ = rbm.sample_v(h)\n",
    "\n",
    "        scaled_tensors = [recommended[0]]\n",
    "        for i in range(1, rbm.K):\n",
    "            scaled_tensors.append(recommended[i] * (i+1))\n",
    "        recommended_scaled = torch.stack(scaled_tensors)\n",
    "        recommended_summed = torch.sum(recommended_scaled, 0)\n",
    "        recommended_summed[v[0] != -1] = -10 # remove games in user lib\n",
    "        predicted_rating, predicted_movie = torch.topk(recommended_summed, k)\n",
    "\n",
    "\n",
    "        for user in range(rbm.batch_size):\n",
    "            # all recommendations\n",
    "            user_ratings = torch.index_select(target_dense[user], 0, target_recommended[user])\n",
    "            user_target = target_recommended[user][user_ratings > 0].cpu().tolist()\n",
    "\n",
    "            # user_target = target_recommended[user][target_rating[user] > rating_cutoff].cpu().tolist()\n",
    "            user_pred = predicted_movie[user].cpu().tolist()\n",
    "\n",
    "            recommended_games_set = recommended_games_set.union(set(user_pred))\n",
    "\n",
    "            counter = 0\n",
    "            total = min(k, len(user_target))\n",
    "            for target in user_target:\n",
    "                if target in user_pred:\n",
    "                    counter += 1\n",
    "            # counter = len(recommendations)\n",
    "\n",
    "            recall.append(counter / total)\n",
    "            hitrates.append(min(1, counter))\n",
    "\n",
    "            # nDCG\n",
    "            idcg = np.sum([1 / np.log2(i+2) for i in range(min(k, len(user_target)))])\n",
    "            dcg = 0\n",
    "            for i, r in enumerate(user_pred):\n",
    "                if r in user_target:\n",
    "                    dcg += 1 / np.log2(i+2)\n",
    "\n",
    "            nDCG.append(dcg / idcg) \n",
    "\n",
    "    if p:\n",
    "        print(recommended_games_set)\n",
    "        print(len(recommended_games_set))\n",
    "    return hitrates, recall, nDCG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rbm10 = create_rbm(train_matrix, test_matrix, 1000, 10000, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rbm20 =create_rbm(train_matrix, test_matrix, 1000, 10000, 10, rbm10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_pop(train_df):\n",
    "    popularity = train_df.explode('item_id')['item_id'].value_counts()\n",
    "    # print(list(popularity.index))\n",
    "    l = list(popularity.index)\n",
    "    global index_random_list\n",
    "    return [index_random_list[item] for item in l]\n",
    "    \n",
    "    # for i in range(user_reviews_df_exploded['item_id_int'].max() + 1):\n",
    "    #     if i not in popularity.index:\n",
    "    #         popularity[i]=0\n",
    "    #     value_list.append(popularity[i])\n",
    "    # # print(popularity.value.tolist())\n",
    "    # print(value_list)\n",
    "\n",
    "pop = get_pop(train0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def compute_hr2(train_matrix, test_matrix, pops, k=10, rating_cutoff=-1, p=False, batch_size = 2000):\n",
    "    hitrates = []\n",
    "    recall = []\n",
    "    nDCG = []\n",
    "    # for loop - go through every single user\n",
    "    for id_user in tqdm(range(0, train_matrix.shape[0] - batch_size, batch_size)): # - batch_size, batch_size):\n",
    "        v = train_matrix[id_user:id_user + batch_size]  # training set inputs are used to activate neurons of my RBM\n",
    "        vt = test_matrix[id_user:id_user + batch_size]  # target\n",
    "        if vt.getnnz() == 0:\n",
    "            continue\n",
    "\n",
    "        v = convert_sparse_matrix_to_sparse_tensor(v)\n",
    "        vt = convert_sparse_matrix_to_sparse_tensor(vt)\n",
    "        v = v.to_dense()\n",
    "        vt = vt.to_dense()\n",
    "        v = v.sub(1)\n",
    "        vt = vt.sub(1)\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            vt = vt.cuda()\n",
    "            v = v.cuda()\n",
    "\n",
    "        # ground truth\n",
    "        ratings, users, movies = (vt > 0).nonzero(as_tuple=True)\n",
    "\n",
    "        indices = torch.stack([users, movies])\n",
    "        shape = (batch_size, train_matrix.shape[1])\n",
    "        target = torch.sparse.LongTensor(indices, torch.add(ratings, 1), torch.Size(shape))\n",
    "        target_dense = target.to_dense()\n",
    "        target_recommended = torch.argsort(target_dense, 1, descending=True)\n",
    "         # remove all bad movies from top k\n",
    "\n",
    "\n",
    "        # predicted\n",
    "        \n",
    "\n",
    "\n",
    "        for user in range(batch_size):\n",
    "\n",
    "            # all recommendations\n",
    "            user_ratings = torch.index_select(target_dense[user], 0, target_recommended[user])\n",
    "            user_target = target_recommended[user][user_ratings > 0].cpu().tolist()\n",
    "            user_pred = pops[:k]\n",
    "\n",
    "            counter = 0\n",
    "            total = min(k, len(user_target))\n",
    "            for target in user_target:\n",
    "                if target in user_pred:\n",
    "                    counter += 1\n",
    "            # counter = len(recommendations)\n",
    "\n",
    "            recall.append(counter / total)\n",
    "            hitrates.append(min(1, counter))\n",
    "\n",
    "            # nDCG\n",
    "            idcg = np.sum([1 / np.log2(i+2) for i in range(min(k, len(user_target)))])\n",
    "            dcg = 0\n",
    "            for i, r in enumerate(user_pred):\n",
    "                if r in user_target:\n",
    "                    dcg += 1 / np.log2(i+2)\n",
    "\n",
    "            nDCG.append(dcg / idcg) \n",
    "\n",
    "    return hitrates, recall, nDCG\n",
    "\n",
    "# hr, r, ndcg = compute_hr2(train_matrix, test_matrix, pop)\n",
    "# print(hr, r, ndcg)\n",
    "# print(\"hr\", np.average(hr))\n",
    "# print(\"recall\", np.average(r))\n",
    "# print(\"ndcg\", np.average(ndcg))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RBM + Popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def compute_hr3(rbm, popularity_dict, k=10):\n",
    "    \"\"\"\n",
    "    \n",
    "    :param rbm: \n",
    "    :param popularity_dict: \n",
    "    :param k: \n",
    "    :return: \n",
    "    \"\"\"\n",
    "\n",
    "    # return hitrates, recall, nDCG\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## calculate HR , Recall & NDCG for our RBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_rbm(rbm, train_matrix, test_matrix, p=True):\n",
    "    print(\"Vanilla RBM\")\n",
    "    hr, r, ndcg = compute_hr(train_matrix, test_matrix, rbm, p=p)\n",
    "    # print(hr, r, ndcg)\n",
    "    print(\"hr\", np.average(hr))\n",
    "    print(\"recall\", np.average(r))\n",
    "    print(\"ndcg\", np.average(ndcg))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbms = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_27576/1778357492.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mrbm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_rbm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_matrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_matrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_errors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_errors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"RBM {i}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mevaluate_rbm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrbm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_matrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_matrix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"./rbm5-5run2-100-nr{i}.pickle\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"wb\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_27576/385660800.py\u001b[0m in \u001b[0;36mcreate_rbm\u001b[1;34m(train_matrix, test_matrix, n_hidden, batch_size, epochs, rbm, k, train_errors, test_errors)\u001b[0m\n\u001b[0;32m     75\u001b[0m             \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrbm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample_h\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m             \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrbm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample_v\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m             \u001b[0mvk\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mv0\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mv0\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mv0\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m             \u001b[0mphk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrbm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample_h\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    rbm = create_rbm(train_matrix, val_matrix, 5, 2000, 100, train_errors=[], test_errors=[])[0]\n",
    "    print(f\"RBM {i}\")\n",
    "    evaluate_rbm(rbm, train_matrix, val_matrix)\n",
    "    with open(f\"./rbm5-5run2-100-nr{i}.pickle\", \"wb\") as f:\n",
    "        pickle.dump(rbm, f)\n",
    "    # torch.save(rbm.state_dict(), f\"./rbm5-run2-100-nr{i}.network\")\n",
    "    rbms.append(rbm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# recommend for single user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend(rbm, v, vt, k, p=True):\n",
    "    \"\"\"\n",
    "    use our model to get recommendations for a single user to reach qualitative metrics\n",
    "    :param rbm: our model\n",
    "    :param v: \n",
    "    :param vt: \n",
    "    :param k: \n",
    "    :param p: \n",
    "    :return: \n",
    "    \"\"\"\n",
    "    target_data = vt.data\n",
    "    target_index = vt.indices\n",
    "    target_recommendations = target_index[target_data == 1]\n",
    "    v = v.todense()\n",
    "    v = torch.Tensor(v)\n",
    "    if torch.cuda.is_available():\n",
    "        v = v.cuda()\n",
    "    \n",
    "    _, h = rbm.sample_h(v)\n",
    "    recommended, _ = rbm.sample_v(h)\n",
    "\n",
    "    # all recommendations\n",
    "    values, indices =  torch.topk(recommended[v < 1], k)\n",
    "    recommendations = indices.cpu().tolist()\n",
    "\n",
    "    if p:\n",
    "        print(\"average value\", torch.mean(recommended[0]))\n",
    "\n",
    "    found = True\n",
    "    for r in recommendations:\n",
    "        if r in target_recommendations:\n",
    "            if p:\n",
    "                print(\"HIT\")\n",
    "            found = True\n",
    "            break\n",
    "\n",
    "    if found and p:\n",
    "        print(\"values\", values)\n",
    "        print(\"recommended\", recommendations)\n",
    "        print(\"real\", target_recommendations)\n",
    "        print(\"len real\", len(target_recommendations))\n",
    "\n",
    "    \n",
    "    \n",
    "    return recommendations\n",
    "\n",
    "user = 100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparam searching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epochs = [5, 10, 25, 50, 100]\n",
    "# hidden = [10, 25, 50, 75, 100]\n",
    "# rbms = []\n",
    "# results = {}\n",
    "\n",
    "# for n_hidden in hidden:\n",
    "#     rbm = None\n",
    "#     prev_epoch = 0\n",
    "#     train = []\n",
    "#     test = []\n",
    "#     for epoch in epochs:\n",
    "#         rbm, train, test = create_rbm(train_matrix, test_matrix, n_hidden, 2000, epoch - prev_epoch, rbm, train_errors=train, test_errors=test)\n",
    "#         torch.save(rbm.state_dict(), f\"./network-{n_hidden}-steam{epoch}-train0\")\n",
    "\n",
    "#         hr, r, ndcg = compute_hr(train_matrix, test_matrix, rbm)\n",
    "#         results[f\"{epoch}-{n_hidden}\"] = (np.average(hr), np.average(r), np.average(ndcg))\n",
    "#         prev_epoch = epoch\n",
    "#     rbms.append(rbm)\n",
    "\n",
    "# results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble of ANTI-RBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ensemble_hr(train_matrix, test_matrix, rbms: list, k=10, rating_cutoff=-1, p=False):\n",
    "    \"\"\"\n",
    "    compute the various metrics of our model, hr, recall and ndcg\n",
    "    :param train_matrix: the input wich our user already has\n",
    "    :param test_matrix: the games we are trying to recommend to each user\n",
    "    :param rbm: our model used to make recommendations\n",
    "    :param k: the amount of recommendations we are going to give\n",
    "    :param batch_size: UNUSED, uses rbm.batch_size instead\n",
    "    :return: hitrates, recall, nDCG as an array, use np.average to get value\n",
    "    \"\"\"\n",
    "    hitrates = []\n",
    "    recall = []\n",
    "    nDCG = []\n",
    "    batch_size = rbms[0].batch_size\n",
    "\n",
    "    recommended_games_set = set()\n",
    "    # for loop - go through every single user\n",
    "    # for id_user in tqdm(range(0, train_matrix.shape[0] - rbm.batch_size, rbm.batch_size)): # - batch_size, batch_size):\n",
    "    for id_user in trange(0, train_matrix.shape[0] - batch_size, batch_size): # - batch_size, batch_size):\n",
    "        v = train_matrix[id_user:id_user + batch_size]  # training set inputs are used to activate neurons of my RBM\n",
    "        vt = test_matrix[id_user:id_user + batch_size]  # target\n",
    "        if vt.getnnz() == 0:\n",
    "            continue\n",
    "\n",
    "        v = convert_sparse_matrix_to_sparse_tensor(v)\n",
    "        vt = convert_sparse_matrix_to_sparse_tensor(vt)\n",
    "        v = v.to_dense()\n",
    "        vt = vt.to_dense()\n",
    "        v = v.sub(1)\n",
    "        vt = vt.sub(1)\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            vt = vt.cuda()\n",
    "            v = v.cuda()\n",
    "\n",
    "        # ground truth\n",
    "        ratings, users, movies = (vt > 0).nonzero(as_tuple=True)\n",
    "\n",
    "        indices = torch.stack([users, movies])\n",
    "        shape = (batch_size, train_matrix.shape[1])\n",
    "        target = torch.sparse.LongTensor(indices, torch.add(ratings, 1), torch.Size(shape))\n",
    "        target_dense = target.to_dense()\n",
    "\n",
    "        target_recommended = torch.argsort(target_dense, 1, descending=True)\n",
    "\n",
    "        # predicted\n",
    "        pred_ratings = []\n",
    "        pred_movies = []\n",
    "        for rbm in rbms:\n",
    "            _, h = rbm.sample_h(v)\n",
    "            recommended, _ = rbm.sample_v(h)\n",
    "\n",
    "            scaled_tensors = [recommended[0]]\n",
    "            for i in range(1, rbm.K):\n",
    "                scaled_tensors.append(recommended[i] * (i+1))\n",
    "            recommended_scaled = torch.stack(scaled_tensors)\n",
    "            recommended_summed = torch.sum(recommended_scaled, 0)\n",
    "            recommended_summed[v[0] != -1] = -10 # remove games in user lib\n",
    "            pred_rating, pred_movie = torch.topk(recommended_summed, k)\n",
    "            pred_ratings.append(pred_rating)\n",
    "            pred_movies.append(pred_movie)\n",
    "\n",
    "        predicted_ratings = torch.cat(pred_ratings, dim=1)\n",
    "        predicted_movies = torch.cat(pred_movies, dim=1)\n",
    "\n",
    "        # _, predicted_indices = torch.topk(predicted_ratings, k)\n",
    "\n",
    "\n",
    "        for user in range(batch_size):\n",
    "            # all recommendations\n",
    "            user_ratings = torch.index_select(target_dense[user], 0, target_recommended[user])\n",
    "            user_target = target_recommended[user][user_ratings > 0].cpu().tolist()\n",
    "\n",
    "            # user_target = target_recommended[user][target_rating[user] > rating_cutoff].cpu().tolist()\n",
    "\n",
    "            unique_movies, indices = np.unique(predicted_movies[user].cpu().tolist(), return_index=True)\n",
    "            # unique_movies, index_map = torch.unique(predicted_movies[user], return_inverse=True, sorted=False)\n",
    "            # unique_indices = torch.unique(index_map, sorted=False)\n",
    "            unique_indices = torch.from_numpy(indices)\n",
    "            if torch.cuda.is_available():\n",
    "                unique_indices = unique_indices.cuda()\n",
    "\n",
    "            user_pred_ratings = torch.index_select(predicted_ratings[user], 0, unique_indices)\n",
    "            user_pred_movies = torch.index_select(predicted_movies[user], 0, unique_indices)\n",
    "            _, predicted_indices = torch.topk(user_pred_ratings, k)\n",
    "\n",
    "            user_pred = torch.index_select(user_pred_movies, 0, predicted_indices).cpu().tolist()\n",
    "\n",
    "            recommended_games_set = recommended_games_set.union(set(user_pred))\n",
    "            counter = 0\n",
    "            total = min(k, len(user_target))\n",
    "            for target in user_target:\n",
    "                if target in user_pred:\n",
    "                    counter += 1\n",
    "            # counter = len(recommendations)\n",
    "\n",
    "            recall.append(counter / total)\n",
    "            hitrates.append(min(1, counter))\n",
    "\n",
    "            # nDCG\n",
    "            idcg = np.sum([1 / np.log2(i+2) for i in range(min(k, len(user_target)))])\n",
    "            dcg = 0\n",
    "            for i, r in enumerate(user_pred):\n",
    "                if r in user_target:\n",
    "                    dcg += 1 / np.log2(i+2)\n",
    "\n",
    "            nDCG.append(dcg / idcg) \n",
    "\n",
    "    if p:\n",
    "        print(recommended_games_set)\n",
    "        print(len(recommended_games_set))\n",
    "    return hitrates, recall, nDCG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ensemble_hr2(train_matrix, test_matrix, rbms: list, k=10, rating_cutoff=-1, p=False):\n",
    "    \"\"\"\n",
    "    compute the various metrics of our model, hr, recall and ndcg\n",
    "    :param train_matrix: the input wich our user already has\n",
    "    :param test_matrix: the games we are trying to recommend to each user\n",
    "    :param rbm: our model used to make recommendations\n",
    "    :param k: the amount of recommendations we are going to give\n",
    "    :param batch_size: UNUSED, uses rbm.batch_size instead\n",
    "    :return: hitrates, recall, nDCG as an array, use np.average to get value\n",
    "    \"\"\"\n",
    "    hitrates = []\n",
    "    recall = []\n",
    "    nDCG = []\n",
    "    batch_size = rbms[0].batch_size\n",
    "\n",
    "    recommended_games_set = set()\n",
    "    # for loop - go through every single user\n",
    "    # for id_user in tqdm(range(0, train_matrix.shape[0] - rbm.batch_size, rbm.batch_size)): # - batch_size, batch_size):\n",
    "    for id_user in trange(0, train_matrix.shape[0] - batch_size, batch_size): # - batch_size, batch_size):\n",
    "        v = train_matrix[id_user:id_user + batch_size]  # training set inputs are used to activate neurons of my RBM\n",
    "        vt = test_matrix[id_user:id_user + batch_size]  # target\n",
    "        if vt.getnnz() == 0:\n",
    "            continue\n",
    "\n",
    "        v = convert_sparse_matrix_to_sparse_tensor(v)\n",
    "        vt = convert_sparse_matrix_to_sparse_tensor(vt)\n",
    "        v = v.to_dense()\n",
    "        vt = vt.to_dense()\n",
    "        v = v.sub(1)\n",
    "        vt = vt.sub(1)\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            vt = vt.cuda()\n",
    "            v = v.cuda()\n",
    "\n",
    "        # ground truth\n",
    "        ratings, users, movies = (vt > 0).nonzero(as_tuple=True)\n",
    "\n",
    "        indices = torch.stack([users, movies])\n",
    "        shape = (batch_size, train_matrix.shape[1])\n",
    "        target = torch.sparse.LongTensor(indices, torch.add(ratings, 1), torch.Size(shape))\n",
    "        target_dense = target.to_dense()\n",
    "\n",
    "        target_recommended = torch.argsort(target_dense, 1, descending=True)\n",
    "\n",
    "        # predicted\n",
    "        pred_ratings = []\n",
    "        pred_movies = []\n",
    "        for rbm in rbms:\n",
    "            _, h = rbm.sample_h(v)\n",
    "            recommended, _ = rbm.sample_v(h)\n",
    "\n",
    "            scaled_tensors = [recommended[0]]\n",
    "            for i in range(1, rbm.K):\n",
    "                scaled_tensors.append(recommended[i] * (i+1))\n",
    "            recommended_scaled = torch.stack(scaled_tensors)\n",
    "            recommended_summed = torch.sum(recommended_scaled, 0)\n",
    "            recommended_summed[v[0] != -1] = -10 # remove games in user lib\n",
    "            pred_rating, pred_movie = torch.topk(recommended_summed, k)\n",
    "            pred_ratings.append(pred_rating)\n",
    "            pred_movies.append(pred_movie)\n",
    "\n",
    "        # predicted_ratings = torch.cat(pred_ratings, dim=1)\n",
    "        predicted_movies = torch.cat(pred_movies, dim=1)\n",
    "        # _, predicted_indices = torch.topk(predicted_ratings, k)\n",
    "\n",
    "\n",
    "        for user in range(batch_size):\n",
    "            # all recommendations\n",
    "            user_ratings = torch.index_select(target_dense[user], 0, target_recommended[user])\n",
    "            user_target = target_recommended[user][user_ratings > 0].cpu().tolist()\n",
    "\n",
    "            unique_movies, counts = np.unique(predicted_movies[user].cpu().tolist(), return_counts=True)\n",
    "            user_pred = np.random.choice(unique_movies, p=counts/sum(counts), replace=False, size=k)\n",
    "\n",
    "            recommended_games_set = recommended_games_set.union(set(user_pred))\n",
    "            counter = 0\n",
    "            total = min(k, len(user_target))\n",
    "            for target in user_target:\n",
    "                if target in user_pred:\n",
    "                    counter += 1\n",
    "            # counter = len(recommendations)\n",
    "\n",
    "            recall.append(counter / total)\n",
    "            hitrates.append(min(1, counter))\n",
    "\n",
    "            # nDCG\n",
    "            idcg = np.sum([1 / np.log2(i+2) for i in range(min(k, len(user_target)))])\n",
    "            dcg = 0\n",
    "            for i, r in enumerate(user_pred):\n",
    "                if r in user_target:\n",
    "                    dcg += 1 / np.log2(i+2)\n",
    "\n",
    "            nDCG.append(dcg / idcg) \n",
    "\n",
    "    if p:\n",
    "        print(recommended_games_set)\n",
    "        print(len(recommended_games_set))\n",
    "    return hitrates, recall, nDCG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rbms = [] \n",
    "# for i in range(5):\n",
    "#     rbm = RBM(train_matrix.shape[1], 5, 5, batch_size=2000)\n",
    "#     rbm.load_state_dict(torch.load(f\"./rbm5-100-nr{i}.network\"))\n",
    "#     rbm.eval()\n",
    "#     rbms.append(rbm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rbms[0].state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vanilla RBM\n",
      "{6149, 5770, 2319, 6288, 5010, 789, 2074, 3741, 6440, 4272, 690, 1843, 2994, 1715, 4278, 5690, 2619, 4158, 461, 5714, 5846, 5720, 2009, 5337, 1754, 4443, 2781, 6367, 7267, 3686, 2923, 3821, 4462, 2286, 3184, 5616, 5234, 6902, 2173}\n",
      "39\n",
      "hr 0.02624074074074074\n",
      "recall 0.007698949147560258\n",
      "ndcg 0.003972225849196765\n"
     ]
    }
   ],
   "source": [
    "evaluate_rbm(rbms[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [00:28<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k: 5\n",
      "0.10972222222222222 0.038522839506172836 0.0308679967292864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [00:29<00:00,  1.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k: 10\n",
      "0.1794074074074074 0.05364439300411523 0.03791345033046223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [00:30<00:00,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k: 20\n",
      "0.26585185185185184 0.08105495882805609 0.04608527220732299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for k in [5, 10, 20]:\n",
    "    hr, r, ndcg = compute_ensemble_hr(train_matrix, test_matrix, rbms, k=k)\n",
    "    print(\"k:\", k)\n",
    "    print(np.average(hr), np.average(r), np.average(ndcg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [00:26<00:00,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{2050, 4, 1801, 6412, 1550, 4622, 2832, 271, 4885, 281, 4633, 6949, 3885, 6195, 5177, 1342, 6722, 6216, 3656, 840, 7247, 6226, 1106, 1108, 1117, 2909, 5730, 6764, 6253, 2158, 3950, 3696, 4220, 7037, 6023, 4743, 2695, 1435, 2717, 5804, 7090, 1203, 2995, 4533, 1212, 3778, 452, 3529, 3786, 4816, 6611, 4564, 6359, 6616, 2012, 3041, 5351, 2796, 1264, 6641, 3570, 3312, 2549, 1526, 4343, 1276, 5117}\n",
      "67\n",
      "k: 5\n",
      "0.0945 0.030526851851851854 0.025791231626963503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [00:27<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{2050, 7170, 4, 5892, 260, 6152, 1801, 5899, 6412, 1550, 4622, 2832, 2321, 271, 4883, 4885, 5397, 4633, 281, 795, 6170, 6949, 3885, 7216, 1073, 5940, 4404, 309, 826, 1342, 2878, 6722, 3656, 6216, 840, 5711, 7247, 2897, 6226, 2386, 1108, 1106, 6994, 5721, 1117, 2909, 3680, 3681, 5730, 6244, 4966, 361, 6764, 6253, 2158, 3950, 3696, 2669, 3700, 2677, 3194, 4220, 7037, 6022, 2695, 6023, 5257, 4743, 1435, 2717, 1955, 6819, 5801, 2732, 2476, 5804, 7090, 1203, 690, 4533, 2484, 3768, 185, 1212, 2495, 3521, 452, 5828, 3529, 3786, 6603, 5836, 6350, 4816, 6611, 4564, 6359, 6616, 1242, 2012, 6368, 3041, 5346, 5351, 4842, 2796, 3565, 3312, 1264, 6641, 3570, 1525, 1526, 4343, 2549, 3065, 6906, 1276, 5117}\n",
      "119\n",
      "k: 10\n",
      "0.15237037037037038 0.04156424162257496 0.028124404827112565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [00:28<00:00,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{3073, 7170, 6658, 4, 3077, 1028, 2050, 6152, 5124, 5130, 2059, 524, 6153, 1550, 4622, 1553, 1043, 3603, 4633, 6170, 2589, 5151, 6175, 7202, 1576, 5165, 1582, 7216, 1073, 1074, 6195, 3637, 2104, 5177, 7226, 577, 6722, 6721, 6216, 3656, 7247, 5711, 6737, 1106, 6226, 1108, 3157, 3666, 4183, 602, 1117, 6750, 3680, 3681, 5730, 2147, 4193, 7272, 4714, 6764, 6253, 2669, 2158, 3696, 2672, 3700, 2677, 5750, 6262, 3194, 4219, 4220, 127, 640, 641, 5250, 2179, 5254, 2695, 4743, 5257, 5115, 4747, 2707, 2717, 670, 6815, 1183, 6819, 4774, 5801, 4778, 1194, 2732, 5804, 690, 1203, 3768, 185, 1212, 3778, 3271, 3786, 5836, 4813, 6350, 4816, 6359, 727, 1242, 2267, 2268, 733, 6368, 741, 5351, 4842, 2796, 1264, 3312, 2802, 4343, 2809, 6906, 3322, 1276, 3837, 6398, 4864, 1281, 260, 5892, 1801, 5899, 6412, 271, 2832, 2321, 4883, 4885, 5397, 278, 281, 795, 5404, 5407, 3359, 3361, 292, 6949, 300, 3885, 5940, 309, 4404, 3383, 826, 1338, 2878, 1342, 2368, 3906, 2883, 3396, 840, 6986, 2894, 335, 6991, 2897, 5970, 1878, 2909, 861, 4448, 2920, 361, 3950, 878, 881, 7030, 375, 7037, 6022, 6023, 5513, 906, 4491, 910, 7066, 1435, 4513, 1955, 932, 4005, 4009, 6061, 5038, 7090, 2484, 2996, 4533, 3005, 2495, 3521, 3010, 452, 456, 3529, 6603, 6091, 6607, 3536, 6611, 4564, 6616, 1499, 2012, 7133, 3041, 6631, 3565, 496, 5617, 3570, 6641, 5108, 1525, 1526, 2549, 3065, 6139, 5117}\n",
      "233\n",
      "k: 20\n",
      "0.2278148148148148 0.06408388829721604 0.03325503058549734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for k in [5, 10, 20]:\n",
    "    hr, r, ndcg = compute_ensemble_hr2(train_matrix, test_matrix, rbms, p=True, k=k)\n",
    "    print(\"k:\", k)\n",
    "    print(np.average(hr), np.average(r), np.average(ndcg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------\n",
      "k: 5\n",
      "0.0956111111111111 0.03210833333333333 0.028712518763621877\n",
      "k: 10\n",
      "0.1504814814814815 0.0444139403292181 0.03293246547378427\n",
      "k: 20\n",
      "0.23212962962962963 0.06751589880747304 0.040646207254896885\n",
      "---------\n",
      "k: 5\n",
      "0.099 0.0341179012345679 0.028434902230416365\n",
      "k: 10\n",
      "0.15057407407407408 0.04225169753086419 0.03145645675667161\n",
      "k: 20\n",
      "0.23422222222222222 0.06527224432861473 0.03923783168985806\n",
      "---------\n",
      "k: 5\n",
      "0.09638888888888889 0.029665740740740743 0.02637987721630488\n",
      "k: 10\n",
      "0.16187037037037036 0.04412702821869489 0.031831286379601344\n",
      "k: 20\n",
      "0.24307407407407408 0.06950559452635045 0.03978254846901732\n",
      "---------\n",
      "k: 5\n",
      "0.09566666666666666 0.029375 0.025067769037446674\n",
      "k: 10\n",
      "0.16003703703703703 0.041951734273956494 0.029660015448490028\n",
      "k: 20\n",
      "0.2542962962962963 0.07416375793849349 0.039721030086378784\n",
      "---------\n",
      "k: 5\n",
      "0.09762962962962964 0.03081265432098765 0.027368007934888562\n",
      "k: 10\n",
      "0.1459074074074074 0.03684118900646678 0.029594178349269175\n",
      "k: 20\n",
      "0.2017037037037037 0.054450037550678246 0.03480800571121221\n",
      "('hr', 5) 0.09685925925925927\n",
      "('r', 5) 0.031215925925925918\n",
      "('ndcg', 5) 0.027192615036535674\n",
      "('hr', 10) 0.15377407407407406\n",
      "('r', 10) 0.04191711787184009\n",
      "('ndcg', 10) 0.031094880481563288\n",
      "('hr', 20) 0.23308518518518517\n",
      "('r', 20) 0.06618150663032199\n",
      "('ndcg', 20) 0.03883912464227265\n"
     ]
    }
   ],
   "source": [
    "metrics_dict = {}\n",
    "for rbm in rbms:\n",
    "    print(\"---------\")\n",
    "    for k in [5, 10, 20]:\n",
    "        hr, r, ndcg = compute_hr(train_matrix, test_matrix, rbm, k=k)\n",
    "        print(\"k:\", k)\n",
    "        print(np.average(hr), np.average(r), np.average(ndcg))\n",
    "\n",
    "        if (\"hr\", k) not in metrics_dict:\n",
    "            metrics_dict[\"hr\", k] = [np.average(hr)]\n",
    "            metrics_dict[\"r\", k] = [np.average(r)]\n",
    "            metrics_dict[\"ndcg\", k] = [np.average(ndcg)]\n",
    "        else:\n",
    "            metrics_dict[\"hr\", k] += [np.average(hr)]\n",
    "            metrics_dict[\"r\", k] += [np.average(r)]\n",
    "            metrics_dict[\"ndcg\", k] += [np.average(ndcg)]\n",
    "\n",
    "for key, value in metrics_dict.items():\n",
    "    print(key, np.average(value))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rbms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"test.pickle\", \"wb\") as f:\n",
    "    pickle.dump(rbms[0], f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{4, 260, 6152, 5257, 1032, 6153, 5397, 281, 6170, 1435, 5660, 2589, 5922, 6819, 4778, 5804, 2476, 6195, 5940, 4533, 2484, 2104, 185, 826, 6722, 3778, 452, 5828, 6603, 5836, 7247, 4816, 6226, 1106, 6611, 2386, 5076, 6359, 6616, 5721, 2012, 5346, 4966, 361, 6253, 3312, 4220, 1526, 1276}\n",
      "49\n",
      "0.1597962962962963\n"
     ]
    }
   ],
   "source": [
    "rbms = []\n",
    "for i in range(5):\n",
    "    with open(f\"rbm5-cedric2-100-nr{i}.pickle\", \"rb\") as f:\n",
    "        rbmtest = pickle.load(f)\n",
    "        rbms.append(rbmtest)\n",
    "\n",
    "\n",
    "h, r, ndcg = compute_hr(train_matrix, val_matrix, rbmtest, p=True)\n",
    "print(np.average(h))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommend Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_ensemble(train_matrix, test_matrix, rbms: list, user, k=10, rating_cutoff=-1, p=False):\n",
    "    recall = []\n",
    "    nDCG = []\n",
    "\n",
    "    # for loop - go through every single user\n",
    "    # for id_user in tqdm(range(0, train_matrix.shape[0] - rbm.batch_size, rbm.batch_size)): # - batch_size, batch_size):\n",
    "    v = train_matrix[user]  # training set inputs are used to activate neurons of my RBM\n",
    "    vt = test_matrix[user]  # target\n",
    "\n",
    "    v = convert_sparse_matrix_to_sparse_tensor(v)\n",
    "    vt = convert_sparse_matrix_to_sparse_tensor(vt)\n",
    "    v = v.to_dense()\n",
    "    vt = vt.to_dense()\n",
    "    v = v.sub(1)\n",
    "    vt = vt.sub(1)\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        vt = vt.cuda()\n",
    "        v = v.cuda()\n",
    "\n",
    "    # ground truth\n",
    "    ratings, users, movies = (vt > 0).nonzero(as_tuple=True)\n",
    "\n",
    "    indices = torch.stack([users, movies])\n",
    "    shape = (1, train_matrix.shape[1])\n",
    "    target = torch.sparse.LongTensor(indices, torch.add(ratings, 1), torch.Size(shape))\n",
    "    target_dense = target.to_dense()\n",
    "\n",
    "    target_recommended = torch.argsort(target_dense, 1, descending=True)\n",
    "\n",
    "    # predicted\n",
    "    pred_ratings = []\n",
    "    pred_movies = []\n",
    "    for rbm in rbms:\n",
    "        _, h = rbm.sample_h(v)\n",
    "        recommended, _ = rbm.sample_v(h)\n",
    "\n",
    "        scaled_tensors = [recommended[0]]\n",
    "        for i in range(1, rbm.K):\n",
    "            scaled_tensors.append(recommended[i] * (i+1))\n",
    "        recommended_scaled = torch.stack(scaled_tensors)\n",
    "        recommended_summed = torch.sum(recommended_scaled, 0)\n",
    "        recommended_summed[v[0] != -1] = -10 # remove games in user lib\n",
    "        pred_rating, pred_movie = torch.topk(recommended_summed, k)\n",
    "        pred_ratings.append(pred_rating)\n",
    "        pred_movies.append(pred_movie)\n",
    "\n",
    "    predicted_ratings = torch.cat(pred_ratings, dim=1)\n",
    "    predicted_movies = torch.cat(pred_movies, dim=1)\n",
    "    # _, predicted_indices = torch.topk(predicted_ratings, k)\n",
    "\n",
    "\n",
    "    # all recommendations\n",
    "    user_ratings = torch.index_select(target_dense[0], 0, target_recommended[0])\n",
    "    user_target = target_recommended[0][user_ratings > 0].cpu().tolist()\n",
    "\n",
    "    # user_target = target_recommended[user][target_rating[user] > rating_cutoff].cpu().tolist()\n",
    "    # user_pred = torch.index_select(predicted_movies[user], 0, predicted_indices[0]).cpu().tolist()\n",
    "    unique_movies, indices = np.unique(predicted_movies[0].cpu().tolist(), return_index=True)\n",
    "    # unique_movies, index_map = torch.unique(predicted_movies[user], return_inverse=True, sorted=False)\n",
    "    # unique_indices = torch.unique(index_map, sorted=False)\n",
    "    unique_indices = torch.from_numpy(indices)\n",
    "    if torch.cuda.is_available():\n",
    "        unique_indices = unique_indices.cuda()\n",
    "\n",
    "    user_pred_ratings = torch.index_select(predicted_ratings[0], 0, unique_indices)\n",
    "    user_pred_movies = torch.index_select(predicted_movies[0], 0, unique_indices)\n",
    "    _, predicted_indices = torch.topk(user_pred_ratings, k)\n",
    "\n",
    "    user_pred = torch.index_select(user_pred_movies, 0, predicted_indices).cpu().tolist()\n",
    "\n",
    "    counter = 0\n",
    "    total = min(k, len(user_target))\n",
    "    for target in user_target:\n",
    "        if target in user_pred:\n",
    "            counter += 1\n",
    "    # counter = len(recommendations)\n",
    "\n",
    "    recall.append(counter / total)\n",
    "\n",
    "    # nDCG\n",
    "    idcg = np.sum([1 / np.log2(i+2) for i in range(min(k, len(user_target)))])\n",
    "    dcg = 0\n",
    "    for i, r in enumerate(user_pred):\n",
    "        if r in user_target:\n",
    "            dcg += 1 / np.log2(i+2)\n",
    "\n",
    "    nDCG.append(dcg / idcg) \n",
    "\n",
    "    return user_target, user_pred, recall, nDCG\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def recommend_ensemble2(train_matrix, test_matrix, rbms: list, user, k=10, rating_cutoff=-1, p=False):\n",
    "    \"\"\"\n",
    "    compute the various metrics of our model, hr, recall and ndcg\n",
    "    :param train_matrix: the input wich our user already has\n",
    "    :param test_matrix: the games we are trying to recommend to each user\n",
    "    :param rbm: our model used to make recommendations\n",
    "    :param k: the amount of recommendations we are going to give\n",
    "    :param batch_size: UNUSED, uses rbm.batch_size instead\n",
    "    :return: hitrates, recall, nDCG as an array, use np.average to get value\n",
    "    \"\"\"\n",
    "    recall = []\n",
    "    nDCG = []\n",
    "\n",
    "    # for loop - go through every single user\n",
    "    # for id_user in tqdm(range(0, train_matrix.shape[0] - rbm.batch_size, rbm.batch_size)): # - batch_size, batch_size):\n",
    "    v = train_matrix[user]  # training set inputs are used to activate neurons of my RBM\n",
    "    vt = test_matrix[user]  # target\n",
    "\n",
    "    v = convert_sparse_matrix_to_sparse_tensor(v)\n",
    "    vt = convert_sparse_matrix_to_sparse_tensor(vt)\n",
    "    v = v.to_dense()\n",
    "    vt = vt.to_dense()\n",
    "    v = v.sub(1)\n",
    "    vt = vt.sub(1)\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        vt = vt.cuda()\n",
    "        v = v.cuda()\n",
    "\n",
    "    # ground truth\n",
    "    ratings, users, movies = (vt > 0).nonzero(as_tuple=True)\n",
    "\n",
    "    indices = torch.stack([users, movies])\n",
    "    shape = (1, train_matrix.shape[1])\n",
    "    target = torch.sparse.LongTensor(indices, torch.add(ratings, 1), torch.Size(shape))\n",
    "    target_dense = target.to_dense()\n",
    "\n",
    "    target_recommended = torch.argsort(target_dense, 1, descending=True)\n",
    "\n",
    "    # predicted\n",
    "    pred_ratings = []\n",
    "    pred_movies = []\n",
    "    for rbm in rbms:\n",
    "        _, h = rbm.sample_h(v)\n",
    "        recommended, _ = rbm.sample_v(h)\n",
    "\n",
    "        scaled_tensors = [recommended[0]]\n",
    "        for i in range(1, rbm.K):\n",
    "            scaled_tensors.append(recommended[i] * (i+1))\n",
    "        recommended_scaled = torch.stack(scaled_tensors)\n",
    "        recommended_summed = torch.sum(recommended_scaled, 0)\n",
    "        recommended_summed[v[0] != -1] = -10 # remove games in user lib\n",
    "        pred_rating, pred_movie = torch.topk(recommended_summed, k)\n",
    "        pred_ratings.append(pred_rating)\n",
    "        pred_movies.append(pred_movie)\n",
    "\n",
    "    # predicted_ratings = torch.cat(pred_ratings, dim=1)\n",
    "    predicted_movies = torch.cat(pred_movies, dim=1)\n",
    "    # _, predicted_indices = torch.topk(predicted_ratings, k)\n",
    "\n",
    "\n",
    "    # all recommendations\n",
    "    user_ratings = torch.index_select(target_dense[0], 0, target_recommended[0])\n",
    "    user_target = target_recommended[0][user_ratings > 0].cpu().tolist()\n",
    "\n",
    "    # user_target = target_recommended[user][target_rating[user] > rating_cutoff].cpu().tolist()\n",
    "    # user_pred = torch.index_select(predicted_movies[user], 0, predicted_indices[0]).cpu().tolist()\n",
    "    unique_movies, counts = np.unique(predicted_movies[0].cpu().tolist(), return_counts=True)\n",
    "    user_pred = np.random.choice(unique_movies, p=counts/sum(counts), replace=False, size=k)\n",
    "\n",
    "    counter = 0\n",
    "    total = min(k, len(user_target))\n",
    "    for target in user_target:\n",
    "        if target in user_pred:\n",
    "            counter += 1\n",
    "    # counter = len(recommendations)\n",
    "\n",
    "    recall.append(counter / total)\n",
    "\n",
    "    # nDCG\n",
    "    idcg = np.sum([1 / np.log2(i+2) for i in range(min(k, len(user_target)))])\n",
    "    dcg = 0\n",
    "    for i, r in enumerate(user_pred):\n",
    "        if r in user_target:\n",
    "            dcg += 1 / np.log2(i+2)\n",
    "\n",
    "    nDCG.append(dcg / idcg) \n",
    "\n",
    "    return user_target, user_pred, recall, nDCG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([493, 653],\n",
       " [4797, 1841, 6670, 2624, 4761, 1348, 2699, 1348, 143, 3012],\n",
       " [0.0],\n",
       " [0.0])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommend_ensemble2(train_matrix, test_matrix, rbms, 30000, k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Black Rose', 'Shadow Warrior', 'Tropico 4', 'Cry of Fear', 'Resident Evil Revelations / Biohazard Revelations', 'Riders of Icarus', 'Eternal Senia', 'Resident Evil 6 / Biohazard 6', 'FINAL FANTASY X/X-2 HD Remaster', 'Dying Light', 'DARK SOULS™ II: Scholar of the First Sin']\n",
      "['Fractured Space', 'Resident Evil Revelations 2 / Biohazard Revelations 2']\n",
      "['The Expendabros', 'Dead Space', 'Grand Theft Auto: Episodes from Liberty City', 'Neverwinter', 'Dino D-Day', 'Team Fortress Classic', 'Half-Life: Opposing Force', 'Day of Defeat: Source', 'Sanctum 2', 'Super Hexagon']\n",
      "\n",
      "['Double Action: Boogaloo', 'EVGA Precision XOC', 'World of Soccer online', 'Brick-Force', 'BlackShot: Mercenary Warfare FPS', 'Block N Load', 'Survarium', 'Codename CURE', 'sZone-Online', 'BLOCKADE 3D', 'WARMODE']\n",
      "['Dungeon Defenders II', 'GunZ 2: The Second Duel']\n",
      "['The Expendabros', 'Dead Space', 'Grand Theft Auto: Episodes from Liberty City', 'Neverwinter', 'Dino D-Day', 'Team Fortress Classic', 'Half-Life: Opposing Force', 'Day of Defeat: Source', 'Sanctum 2', 'Super Hexagon']\n",
      "\n",
      "['Dungeon Defenders', 'Cry of Fear', 'The Forest', 'Dead Realm', 'Damned']\n",
      "['Space Hack']\n",
      "['The Expendabros', 'Dead Space', 'Grand Theft Auto: Episodes from Liberty City', 'Neverwinter', 'Dino D-Day', 'Team Fortress Classic', 'Half-Life: Opposing Force', 'Day of Defeat: Source', 'Sanctum 2', 'Super Hexagon']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for user in [30000, 30001, 42069]:\n",
    "    inventory = train0.loc[user][\"item_id\"]\n",
    "    target, recommended, r, ndcg = recommend_ensemble(train_matrix, test_matrix, rbms, user, k=10)\n",
    "\n",
    "    recommended = [index_random_list.index(x) for x in recommended]\n",
    "    target = [index_random_list.index(x) for x in target]\n",
    "\n",
    "    print(games.loc[inventory][\"title\"].tolist())\n",
    "    print(games.loc[target][\"title\"].tolist())\n",
    "    print(games.loc[recommended][\"title\"].tolist())\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Black Rose', 'Shadow Warrior', 'Tropico 4', 'Cry of Fear', 'Resident Evil Revelations / Biohazard Revelations', 'Riders of Icarus', 'Eternal Senia', 'Resident Evil 6 / Biohazard 6', 'FINAL FANTASY X/X-2 HD Remaster', 'Dying Light', 'DARK SOULS™ II: Scholar of the First Sin']\n",
      "['Fractured Space', 'Resident Evil Revelations 2 / Biohazard Revelations 2']\n",
      "['Sanctum 2', 'Mark of the Ninja', 'Half-Life: Blue Shift', 'Brothers - A Tale of Two Sons', 'SteamWorld Dig', 'Dino D-Day', 'Natural Selection 2', 'Grand Theft Auto: Episodes from Liberty City', 'Little Inferno', 'Saints Row 2']\n",
      "\n",
      "['Double Action: Boogaloo', 'EVGA Precision XOC', 'World of Soccer online', 'Brick-Force', 'BlackShot: Mercenary Warfare FPS', 'Block N Load', 'Survarium', 'Codename CURE', 'sZone-Online', 'BLOCKADE 3D', 'WARMODE']\n",
      "['Dungeon Defenders II', 'GunZ 2: The Second Duel']\n",
      "['Saints Row 2', 'Natural Selection 2', 'Psychonauts', 'Half-Life: Opposing Force', 'Day of Defeat: Source', 'How to Survive', 'Ricochet', 'Risk of Rain', 'Tactical Intervention', 'Brothers - A Tale of Two Sons']\n",
      "\n",
      "['Dungeon Defenders', 'Cry of Fear', 'The Forest', 'Dead Realm', 'Damned']\n",
      "['Space Hack']\n",
      "['Bastion', 'The Walking Dead', 'Natural Selection 2', 'Half-Life: Blue Shift', 'The Expendabros', 'Team Fortress Classic', 'Sanctum 2', 'Day of Defeat: Source', 'The Stanley Parable', 'Just Cause']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for user in [30000, 30001, 42069]:\n",
    "    inventory = train0.loc[user][\"item_id\"]\n",
    "    target, recommended, r, ndcg = recommend_ensemble2(train_matrix, test_matrix, rbms, user, k=10)\n",
    "\n",
    "    recommended = [index_random_list.index(x) for x in recommended]\n",
    "    target = [index_random_list.index(x) for x in target]\n",
    "\n",
    "    print(games.loc[inventory][\"title\"].tolist())\n",
    "    print(games.loc[target][\"title\"].tolist())\n",
    "    print(games.loc[recommended][\"title\"].tolist())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ac59ebe37160ed0dfa835113d9b8498d9f09ceb179beaac4002f036b9467c963"
  },
  "kernelspec": {
   "display_name": "PyCharm (ai-project)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

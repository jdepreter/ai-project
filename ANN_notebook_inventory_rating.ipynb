{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Restricted Boltzmann Machine Defintion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# TODO g = 1 + ap of g = ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Import PyTorch library\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, flatten, device\n",
    "\n",
    "device = torch.device('cpu')\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# https://github.com/khanhnamle1994/MetaRec/blob/b5e36cb579a88b32cdfb728f35f645d76b24ad95/Boltzmann-Machines-Experiments/RBM-CF-PyTorch/rbm.py#L23\n",
    "# Create the Restricted Boltzmann Machine architecture\n",
    "class network(nn.Module):\n",
    "    def __init__(self, x ):\n",
    "        super().__init__()\n",
    "        \n",
    "    #use 4 layers and fc layer\n",
    "        self.conv1 = nn.Conv1d(x, 256, kernel_size=1)\n",
    "        self.conv2 = nn.Conv1d(256, 1024, kernel_size=1)\n",
    "        self.conv3 = nn.Conv1d(1024, 512, kernel_size=1)\n",
    "        self.conv4 = nn.Conv1d(512, 64, kernel_size=1)\n",
    "        self.fc = nn.Linear(64*7*7, x)\n",
    "\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "        if torch.cuda.is_available():\n",
    "            self.device = device(\"cuda\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        if torch.cuda.is_available():\n",
    "            x = x.to(self.device)\n",
    "\n",
    "        x = F.relu(self.conv1(x))\n",
    "\n",
    "        # x = F.max_pool1d(x, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = flatten(x, 1)\n",
    "\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc(x)\n",
    "        output = F.softmax(x, dim=1)\n",
    "        return output\n",
    "    \n",
    "    def lr(self):\n",
    "        return 0.01\n",
    "\n",
    "\n",
    "\n",
    "    def train_model(self, v0, vk, ph0, phk):\n",
    "        \"\"\"\n",
    "        Perform contrastive divergence algorithm to optimize the weights that minimize the energy\n",
    "        This maximizes the log-likelihood of the model\n",
    "        \"\"\"\n",
    "\n",
    "        ph0_K = torch.stack([ph0 for _ in range(self.K)])\n",
    "        phk_K = torch.stack([phk for _ in range(self.K)])\n",
    "\n",
    "        pos = torch.bmm(torch.transpose(v0, 1, 2).cpu(), ph0_K.cpu())\n",
    "        neg = torch.bmm(torch.transpose(vk, 1, 2).cpu(), phk_K.cpu())\n",
    "        if torch.cuda.is_available():\n",
    "            pos = pos.cuda()\n",
    "            neg = neg.cuda()\n",
    "\n",
    "        w_extra = torch.transpose(pos - neg, 1, 2)\n",
    "        v_extra = torch.sum((v0 - vk), 1)\n",
    "        h_extra = torch.sum((ph0 - phk), 0)\n",
    "\n",
    "        # if self.i % 45 == 0:\n",
    "            # print(torch.max(w_extra), torch.max(v_extra), torch.max(h_extra), flush=True)\n",
    "\n",
    "        # Approximate the gradients with the CD algorithm\n",
    "        # TODO learning rate toevoegen\n",
    "        self.W += self.lr() * w_extra\n",
    "\n",
    "        # Add (difference, 0) for the tensor of 2 dimensions\n",
    "        self.v_bias += self.lr() * v_extra.unsqueeze(1)\n",
    "        self.h_bias += self.lr() * h_extra\n",
    "        self.i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "cuda = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle as pickle\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "import gzip\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "import math\n",
    "tqdm.pandas() #for progres_apply etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "with open(\"stijn-data/item_dct.p\", \"rb\") as f:\n",
    "    item_dict = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def parse_csv(filename):\n",
    "    df_string = pd.read_csv(filename, index_col=0)\n",
    "    df = df_string.loc[:,:]\n",
    "    df[\"item_id\"] = df[\"item_id\"].apply(eval)\n",
    "    df[\"playtime_forever\"] = df[\"playtime_forever\"].apply(eval)\n",
    "    df[\"playtime_2weeks\"] = df[\"playtime_2weeks\"].apply(eval)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "train0 = parse_csv(\"stijn-data/train_split_0.csv\")\n",
    "test0 = parse_csv(\"stijn-data/test_split_0.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "count    65701.000000\nmean        50.869926\nstd         64.529794\nmin          2.000000\n25%         12.000000\n50%         31.000000\n75%         64.000000\nmax        716.000000\nName: item_id, dtype: float64"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 8
    }
   ],
   "source": [
    "train0[\"item_id\"].map(len).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "user_id                                                           100\nitem_id             [221, 1698, 532, 318, 178, 101, 171, 576, 229,...\nplaytime_forever    [1254, 67, 1075, 597, 5195, 395, 212, 363, 574...\nplaytime_2weeks                     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\nName: 100, dtype: object"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 9
    }
   ],
   "source": [
    "train0.iloc[100,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sparse Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Sparse Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def score_playtime(playtime):\n",
    "    \n",
    "    if playtime < 120:\n",
    "        # less than 2 hrs\n",
    "        return 0\n",
    "    elif playtime < 240:\n",
    "        # less than 4 hrs\n",
    "        return 1\n",
    "    elif playtime < 600:\n",
    "        # less than 10 hrs\n",
    "        return 2\n",
    "    elif playtime < 24*60:\n",
    "        # less than 24 hrs\n",
    "        return 3\n",
    "    else:\n",
    "        return 4\n",
    "\n",
    "#Create scipy csr matrix\n",
    "def get_sparse_matrix(df):\n",
    "    shape = (df['user_id'].max() + 1, max(item_dict.values()) + 1)\n",
    "    \n",
    "    user_ids = []\n",
    "    item_ids = []\n",
    "    values = []\n",
    "    for idx, row in df.iterrows():\n",
    "        items = row['item_id']\n",
    "        user = row['user_id']\n",
    "        score = row[\"playtime_forever\"] + 2* row[\"playtime_2weeks\"]\n",
    "        \n",
    "        \n",
    "    \n",
    "        # recommended = row['recommended']\n",
    "        user_ids.extend([user] * len(items))\n",
    "        item_ids.extend(items)\n",
    "        values.extend([score_playtime(score[i]) for i in range(len(items))])\n",
    "    # create csr matrix\n",
    "    # values = np.ones(len(user_ids))\n",
    "    matrix = scipy.sparse.csr_matrix((values, (user_ids, item_ids)), shape=shape, dtype=np.int32)\n",
    "    return matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "hey\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "<65701x10269 sparse matrix of type '<class 'numpy.intc'>'\n\twith 3342205 stored elements in Compressed Sparse Row format>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 11
    }
   ],
   "source": [
    "print('hey')\n",
    "test_matrix = get_sparse_matrix(test0)\n",
    "\n",
    "train_matrix = get_sparse_matrix(train0)\n",
    "train_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<torch._C.Generator at 0x26f0550c2e8>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 12
    }
   ],
   "source": [
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def score_model(rbm, batch_size, train_matrix, test_matrix):\n",
    "    test_recon_error = 0  # RMSE reconstruction error initialized to 0 at the beginning of training\n",
    "    s = 0  # a counter (float type) \n",
    "    # for loop - go through every single user\n",
    "    for id_user in range(0, train_matrix.shape[0] - batch_size, batch_size):\n",
    "        v = train_matrix[id_user:id_user + batch_size]  # training set inputs are used to activate neurons of my RBM\n",
    "        vt = test_matrix[id_user:id_user + batch_size]  # target\n",
    "        v = convert_sparse_matrix_to_sparse_tensor(v)\n",
    "        vt = convert_sparse_matrix_to_sparse_tensor(vt)\n",
    "\n",
    "        v = v.to_dense()\n",
    "        vt = vt.to_dense()\n",
    "        v = v.sub(1)\n",
    "        vt = vt.sub(1)\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            v = v.cuda()\n",
    "            vt = vt.cuda()\n",
    "\n",
    "        if len(vt[vt > -1]) > 0:\n",
    "            v = rbm(v)\n",
    "            \n",
    "            # Update test RMSE reconstruction error\n",
    "            test_recon_error += torch.mean((vt[vt > -1] - v[vt > -1])**2) * len(vt > -1) \n",
    "            s += len(vt > -1)\n",
    "\n",
    "    return torch.sqrt(test_recon_error / s)\n",
    "\n",
    "\n",
    "# https://stackoverflow.com/questions/40896157/scipy-sparse-csr-matrix-to-tensorflow-sparsetensor-mini-batch-gradient-descent\n",
    "\n",
    "\n",
    "def convert_sparse_matrix_to_sparse_tensor(X, k=5):\n",
    "    coo = X.tocoo()\n",
    "\n",
    "    values = coo.data\n",
    "    indices = np.vstack((coo.row, coo.col))\n",
    "    i = torch.LongTensor(indices)\n",
    "    v = torch.DoubleTensor(values)\n",
    "    tensor_list = []\n",
    "\n",
    "    for index in range(k):\n",
    "        value = index\n",
    "        yeet = torch.where(v == value, 2., 1.)\n",
    "        shape = coo.shape\n",
    "        tensor = torch.sparse.DoubleTensor(i, yeet, torch.Size(shape)) \n",
    "        if torch.cuda.is_available():\n",
    "            tensor = tensor.cuda()\n",
    "\n",
    "        tensor_list.append(tensor)\n",
    "\n",
    "    tensor = torch.stack(tensor_list) \n",
    "    return tensor\n",
    "def create_rbm(train_matrix, test_matrix, n_hidden, batch_size, epochs, rbm=None, k=5):\n",
    "    n_vis = train_matrix.shape[1]\n",
    "    train_errors = []\n",
    "    test_errors = []\n",
    "    if rbm is None:\n",
    "        rbm = (n_vis, n_hidden, k, batch_size)\n",
    "    optim = torch.optim.SGD(rbm.parameters(), lr=0.02, momentum=0.9)\n",
    "    print(\"start training\")\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        rbm.train()\n",
    "        train_recon_error = 0  # RMSE reconstruction error initialized to 0 at the beginning of training\n",
    "        s = 0\n",
    "        \n",
    "        for user_id in range(0, train_matrix.shape[0] - batch_size, batch_size):\n",
    "            training_sample = train_matrix[user_id : user_id + batch_size]\n",
    "            v0 = convert_sparse_matrix_to_sparse_tensor(training_sample)\n",
    "\n",
    "            v0 = v0.to_dense()\n",
    "            v0 = v0.sub(1)\n",
    "            \n",
    "\n",
    "            vk = rbm(v0)\n",
    "\n",
    "\n",
    "                   \n",
    "            \n",
    "            loss = torch.sqrt(torch.mean((v0[v0 > -1] - vk[v0 > -1])**2))\n",
    "            \n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            optim.zero_grad()\n",
    "            \n",
    "            train_recon_error +=loss\n",
    "            \n",
    "            s += len(v0 > -1)\n",
    "            \n",
    "        train_errors.append(train_recon_error / s)\n",
    "\n",
    "        # print('calculating test scores')\n",
    "        rbm.eval()\n",
    "        test_errors.append(score_model(rbm, batch_size, train_matrix, test_matrix))\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "    # Plot the RMSE reconstruction error with respect to increasing number of epochs\n",
    "    plt.plot(torch.Tensor(train_errors, device='cpu'), label=\"train\")\n",
    "    plt.plot(torch.Tensor(test_errors, device='cpu'), label=\"test\")\n",
    "    plt.ylabel('Error')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend()\n",
    "    plt.savefig(f'aussies-{n_hidden}-{batch_size}-{epochs}.jpg')\n",
    "\n",
    "    return rbm\n",
    "\n",
    "# Evaluate the RBM on test set\n",
    "# test_recon_error = score_model(rbm)\n",
    "# print(\"Final error\", test_recon_error)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HR / Recall / NDCG Function Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vanilla Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def compute_hr(train_matrix, test_matrix, rbm, k=10, batch_size=100):\n",
    "    s = 0  # a counter (float type) \n",
    "    hitrates = []\n",
    "    recall = []\n",
    "    nDCG = []\n",
    "    # for loop - go through every single user\n",
    "    for id_user in range(0, train_matrix.shape[0]): # - batch_size, batch_size):\n",
    "        v = train_matrix[id_user]  # training set inputs are used to activate neurons of my RBM\n",
    "        vt = test_matrix[id_user]  # target\n",
    "\n",
    "        target_data = vt.data\n",
    "        target_index = vt.indices\n",
    "        target_recommendations = target_index[target_data == 1]\n",
    "        # print(target_test)\n",
    "\n",
    "        v = v.todense()\n",
    "\n",
    "        # v = v - 1\n",
    "        v = torch.Tensor(v)\n",
    "        if torch.cuda.is_available():\n",
    "            v = v.cuda()\n",
    "        \n",
    "        if len(target_recommendations) > 0: # check that target contains recommendations (only needed for aussies)\n",
    "            _, h = rbm.sample_h(v)\n",
    "            recommended, _ = rbm.sample_v(h)\n",
    "\n",
    "            # all recommendations\n",
    "            _, indices =  torch.topk(recommended[v < 1], k)\n",
    "            recommendations = indices.cpu().tolist()\n",
    "\n",
    "            counter = 0\n",
    "            total = min(len(target_recommendations), k)\n",
    "            for target in target_recommendations:\n",
    "                if target in recommendations:\n",
    "                    counter += 1\n",
    "            # counter = len(recommendations)\n",
    "\n",
    "            recall.append(counter / total)\n",
    "            hitrates.append(min(1, counter))\n",
    "\n",
    "            # nDCG\n",
    "            idcg = np.sum([1 / np.log2(i+2) for i in range(min(k, len(target_recommendations)))])\n",
    "            dcg = 0\n",
    "            for i, r in enumerate(recommendations):\n",
    "                if r in target_recommendations:\n",
    "                    dcg += 1 / np.log2(i+2)\n",
    "\n",
    "            nDCG.append(dcg / idcg) \n",
    "\n",
    "    return hitrates, recall, nDCG\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "\r  0%|          | 0/2 [00:00<?, ?it/s]"
     ],
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": [
      "start training\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "rbm10 = create_rbm(train_matrix, test_matrix, 1000, 10000, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# rbm20 =create_rbm(train_matrix, test_matrix, 1000, 10000, 10, rbm10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def compute_hr2(pops, k=10, batch_size=100):\n",
    "    s = 0  # a counter (float type) \n",
    "    hitrates = []\n",
    "    recall = []\n",
    "    nDCG = []\n",
    "    # idcg = np.sum([1 / np.log2(i+2) for i in range(k)])\n",
    "    # for loop - go through every single user\n",
    "    for id_user in range(0, train_matrix.shape[0]): # - batch_size, batch_size):\n",
    "        v = train_matrix[id_user]  # training set inputs are used to activate neurons of my RBM\n",
    "        vt = test_matrix[id_user]  # target\n",
    "\n",
    "        target_data = vt.data\n",
    "        target_index = vt.indices\n",
    "        target_recommendations = target_index[target_data == 2]\n",
    "        # print(target_test)\n",
    "\n",
    "        \n",
    "        if len(target_recommendations) > 0: # check that target contains recommendations (only needed for aussies)\n",
    "            # _, h = rbm.sample_h(v)\n",
    "            # recommended, _ = rbm.sample_v(h)\n",
    "            # \n",
    "            # # all recommendations\n",
    "            # _, indices =  torch.topk(recommended[v < 0], k)\n",
    "            recommendations = pops[:k]\n",
    "\n",
    "            counter = 0\n",
    "            total = min(len(target_recommendations), k)\n",
    "            for target in target_recommendations:\n",
    "                if target in recommendations:\n",
    "                    counter += 1\n",
    "            # counter = len(recommendations)\n",
    "\n",
    "            recall.append(counter / total)\n",
    "            hitrates.append(min(1, counter))\n",
    "\n",
    "            # nDCG\n",
    "            idcg = np.sum([1 / np.log2(i+2) for i in range(min(k, len(target_recommendations)))])\n",
    "            counter = 0\n",
    "            dcg = 0\n",
    "            for i, r in enumerate(recommendations):\n",
    "                if r in target_recommendations:\n",
    "                    dcg += 1 / np.log2(i+2)\n",
    "\n",
    "            nDCG.append(dcg / idcg) \n",
    "\n",
    "    return hitrates, recall, nDCG\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RBM + Popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def compute_hr3(rbm, popularity_dict, k=10):\n",
    "    s = 0  # a counter (float type) \n",
    "    hitrates = []\n",
    "    recall = []\n",
    "    nDCG = []\n",
    "    idcg = np.sum([1 / np.log2(i+2) for i in range(k)])\n",
    "    pop = torch.FloatTensor(popularity_dict)\n",
    "    if torch.cuda.is_available():\n",
    "        pop = pop.cuda()\n",
    "\n",
    "    # for loop - go through every single user\n",
    "    for id_user in range(0, train_matrix.shape[0]): # - batch_size, batch_size):\n",
    "        v = train_matrix[id_user]  # training set inputs are used to activate neurons of my RBM\n",
    "        vt = test_matrix[id_user]  # target\n",
    "\n",
    "        target_data = vt.data\n",
    "        target_index = vt.indices\n",
    "        target_recommendations = target_index[target_data == 2]\n",
    "        # print(target_test)\n",
    "\n",
    "        v = v.todense()\n",
    "\n",
    "        v = v - 1\n",
    "        v = torch.Tensor(v)\n",
    "        if torch.cuda.is_available():\n",
    "            v = v.cuda()\n",
    "        \n",
    "        if len(target_recommendations) > 0: # check that target contains recommendations (only needed for aussies)\n",
    "            _, h = rbm.sample_h(v)\n",
    "            recommended, _ = rbm.sample_v(h)\n",
    "\n",
    "            # all recommendations\n",
    "            # multiply recommendations by the games popularity\n",
    "            # print(recommended)\n",
    "            recommended = torch.mul(recommended, pop)\n",
    "            # print(recommended)\n",
    "            _, indices =  torch.topk(recommended[v < 0], k)\n",
    "            # recommendations = torch.tensor(indices, device='cpu').tolist()\n",
    "            recommendations = indices.cpu().tolist()\n",
    "\n",
    "            counter = 0\n",
    "            total = min(len(target_recommendations), k)\n",
    "            for target in target_recommendations:\n",
    "                if target in recommendations:\n",
    "                    counter += 1\n",
    "            # counter = len(recommendations)\n",
    "\n",
    "            recall.append(counter / total)\n",
    "            hitrates.append(min(1, counter))\n",
    "\n",
    "            # nDCG\n",
    "            counter = 0\n",
    "            dcg = 0\n",
    "            for i, r in enumerate(recommendations):\n",
    "                if r in target_recommendations:\n",
    "                    dcg += 1 / np.log2(i+2)\n",
    "\n",
    "            nDCG.append(dcg / idcg) \n",
    "\n",
    "    return hitrates, recall, nDCG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HR / Recall / NDCG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_rbm(rbm):\n",
    "    print(\"Vanilla RBM\")\n",
    "    hr, r, ndcg = compute_hr(train_matrix, test_matrix, rbm)\n",
    "    # print(hr, r, ndcg)\n",
    "    print(\"hr\", np.average(hr))\n",
    "    print(\"recall\", np.average(r))\n",
    "    print(\"ndcg\", np.average(ndcg))\n",
    "\n",
    "    # print(\"popularity incorporated\")\n",
    "    # hr, r, ndcg = compute_hr3(rbm, value_list)\n",
    "    # print(\"hr\", np.average(hr))\n",
    "    # print(\"recall\", np.average(r))\n",
    "    # print(\"ndcg\", np.average(ndcg))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-159ac57b7ec5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mevaluate_rbm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrbm10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'rbm10' is not defined"
     ],
     "ename": "NameError",
     "evalue": "name 'rbm10' is not defined",
     "output_type": "error"
    }
   ],
   "source": [
    "evaluate_rbm(rbm10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "rbm100 = create_rbm(train_matrix, test_matrix, 1024, 10240, 100)\n",
    "evaluate_rbm(rbm100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "rbm10 = create_rbm(train_matrix, test_matrix, 1024, 10240, 10)\n",
    "rbm20 = create_rbm(train_matrix, test_matrix, 1024, 10240, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "print(\"10 epochs\")\n",
    "hr, r, ndcg = compute_hr(train_matrix, test_matrix, rbm10)\n",
    "print(\"hr\", np.average(hr))\n",
    "print(\"recall\", np.average(r))\n",
    "print(\"ndcg\", np.average(ndcg))\n",
    "\n",
    "print(\"20 epochs\")\n",
    "hr, r, ndcg = compute_hr(train_matrix, test_matrix,rbm20)\n",
    "print(\"hr\", np.average(hr))\n",
    "print(\"recall\", np.average(r))\n",
    "print(\"ndcg\", np.average(ndcg))\n",
    "\n",
    "print(\"popularity\")\n",
    "hr,r ,ndcg = compute_hr2(popularity.index)\n",
    "print(\"hr\", np.average(hr))\n",
    "print(\"recall\", np.average(r))\n",
    "print(\"ndcg\", np.average(ndcg))\n",
    "\n",
    "print(\"popularity incorporated\")\n",
    "hr, r, ndcg = compute_hr3(rbm10, value_list)\n",
    "print(\"hr\", np.average(hr))\n",
    "print(\"recall\", np.average(r))\n",
    "print(\"ndcg\", np.average(ndcg))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def recommend(rbm, v, vt, k, p=True):\n",
    "    target_data = vt.data\n",
    "    target_index = vt.indices\n",
    "    target_recommendations = target_index[target_data == 1]\n",
    "    v = v.todense()\n",
    "    # v = v - 1\n",
    "    v = torch.Tensor(v)\n",
    "    if torch.cuda.is_available():\n",
    "        v = v.cuda()\n",
    "    \n",
    "    _, h = rbm.sample_h(v)\n",
    "    recommended, _ = rbm.sample_v(h)\n",
    "\n",
    "    # all recommendations\n",
    "    values, indices =  torch.topk(recommended[v < 1], k)\n",
    "    recommendations = indices.cpu().tolist()\n",
    "\n",
    "    if p:\n",
    "        # print('20', recommended[0][20])\n",
    "        # print('21', recommended[0][21])\n",
    "        print(\"average value\", torch.mean(recommended[0]))\n",
    "\n",
    "    found = True\n",
    "    for r in recommendations:\n",
    "        if r in target_recommendations:\n",
    "            if p:\n",
    "                print(\"HIT\")\n",
    "            found = True\n",
    "            break\n",
    "\n",
    "    if found and p:\n",
    "        print(\"values\", values)\n",
    "        print(\"recommended\", recommendations)\n",
    "        print(\"real\", target_recommendations)\n",
    "        print(\"len real\", len(target_recommendations))\n",
    "\n",
    "    \n",
    "    \n",
    "    return recommendations\n",
    "\n",
    "user = 100\n",
    "# print(\"train\", train_matrix[user])\n",
    "# print(\"test\", test_matrix[user])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "print(\"EPOCHS 10\")\n",
    "recommend(rbm10, train_matrix[user], test_matrix[user], 10)\n",
    "print('---' * 10)\n",
    "print(\"EPOCHS 100\")\n",
    "recommend(rbm100, train_matrix[user], test_matrix[user], 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "rbm2000 = create_rbm(train_matrix, test_matrix, 100, 10000, 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "recommend(rbm2000, train_matrix[user], test_matrix[user], 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "print(\"2000 epochs\")\n",
    "hr, r, ndcg = compute_hr(train_matrix, test_matrix, rbm2000)\n",
    "print(\"hr\", np.average(hr))\n",
    "print(\"recall\", np.average(r))\n",
    "print(\"ndcg\", np.average(ndcg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# hrs = []\n",
    "# rs = []\n",
    "# for i in range(10):\n",
    "#     rbm = create_rbm(user_reviews_df_exploded['item_id_int'].max() + 1, 1024, 10240, i)\n",
    "#     hr, r = compute_hr(rbm)\n",
    "#     hrs.append(np.average(hr))\n",
    "#     rs.append(np.average(r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# plt.clf()\n",
    "# plt.plot(hrs, label='HR')\n",
    "# plt.plot(rs, label='Recall')\n",
    "# plt.xlabel(\"Epochs\")\n",
    "# plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "rbm1 = create_rbm(user_reviews_df_exploded['item_id_int'].max() + 1, 1024, 10240, 50)\n",
    "hr, r, ndcg = compute_hr(rbm1)\n",
    "print(\"hr\", np.average(hr))\n",
    "print(\"recall\", np.average(r))\n",
    "print(\"ndcg\", np.average(r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "rbm50 = create_rbm(user_reviews_df_exploded['item_id_int'].max() + 1, 1024, 10240, 50)\n",
    "hr, r = compute_hr(rbm50)\n",
    "print(\"hr\", np.average(hr))\n",
    "print(\"recall\", np.average(r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "print(\"EPOCHS 50\")\n",
    "recommend(rbm50, train_matrix[user], test_matrix[user], 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "rbm100 = create_rbm(user_reviews_df_exploded['item_id_int'].max() + 1, 1024, 10240, 100)\n",
    "hr, r, ndcg = compute_hr(rbm100)\n",
    "print(\"hr\", np.average(hr))\n",
    "print(\"recall\", np.average(r))\n",
    "print(\"ndcg\", np.average(ndcg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "all_recommendations = set()\n",
    "for u in range(train_matrix.shape[0]):\n",
    "    recommendations = recommend(rbm50, train_matrix[u], test_matrix[u], 10, False)\n",
    "    all_recommendations.update(recommendations)\n",
    "\n",
    "print(len(all_recommendations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "all_recommendations = set()\n",
    "for u in range(train_matrix.shape[0]):\n",
    "    recommendations = recommend(rbm20, train_matrix[u], test_matrix[u], 10, False)\n",
    "    all_recommendations.update(recommendations)\n",
    "\n",
    "print(len(all_recommendations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "all_recommendations = set()\n",
    "for u in range(train_matrix.shape[0]):\n",
    "    recommendations = recommend(rbm10, train_matrix[u], test_matrix[u], 10, False)\n",
    "    all_recommendations.update(recommendations)\n",
    "\n",
    "print(len(all_recommendations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "print(train_matrix.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "rbm500 = create_rbm(user_reviews_df_exploded['item_id_int'].max() + 1, 1024, 10240, 500)\n",
    "hr, r = compute_hr(rbm50)\n",
    "print(\"hr\", np.average(hr))\n",
    "print(\"recall\", np.average(r))\n",
    "\n",
    "all_recommendations = set()\n",
    "for u in range(train_matrix.shape[0]):\n",
    "    recommendations = recommend(rbm500, train_matrix[u], test_matrix[u], 10, False)\n",
    "    all_recommendations.update(recommendations)\n",
    "\n",
    "print(len(all_recommendations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "hr, r = compute_hr(rbm500)\n",
    "print(\"hr\", np.average(hr))\n",
    "print(\"recall\", np.average(r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "rbm2000 = create_rbm(user_reviews_df_exploded['item_id_int'].max() + 1, 1024, 10240, 2000)\n",
    "hr, r, ndcg = compute_hr(rbm2000)\n",
    "print(\"hr\", np.average(hr))\n",
    "print(\"recall\", np.average(r))\n",
    "print(\"ndcg\", np.average(ndcg))\n",
    "\n",
    "all_recommendations = set()\n",
    "for u in range(train_matrix.shape[0]):\n",
    "    recommendations = recommend(rbm2000, train_matrix[u], test_matrix[u], 10, u == train_matrix.shape[0] - 1)\n",
    "    all_recommendations.update(recommendations)\n",
    "\n",
    "print(len(all_recommendations))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparam searching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "epochs = [100]\n",
    "hidden = [100, 1000, 5000, 10000]\n",
    "rbms = []\n",
    "results = {}\n",
    "\n",
    "for epoch in epochs:\n",
    "    for n_hidden in hidden:\n",
    "        rbm = create_rbm(train_matrix, test_matrix, n_hidden, 10240, epoch)\n",
    "        rbms.append(rbm)\n",
    "        hr, r, ndcg = compute_hr(train_matrix, test_matrix, rbm)\n",
    "        results[f\"{epoch}-{n_hidden}\"] = (np.average(hr), np.average(r), np.average(ndcg))\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "for i, rbm in enumerate(rbms):\n",
    "    hr, r, ndcg = compute_hr(train_matrix, test_matrix, rbm)\n",
    "    results[f\"{100}-{hidden[i]}\"] = (np.average(hr), np.average(r), np.average(ndcg))\n",
    "    \n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import pprint\n",
    "pprint.pprint(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# torch.save(rbm.state_dict(), \"./network\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": false,
     "name": "#%% load model\n"
    }
   },
   "outputs": [],
   "source": [
    "# rbm = RBM(n_vis, n_hidden)\n",
    "# rbm.load_state_dict(torch.load(\"./network\"))\n",
    "# rbm.eval()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ac59ebe37160ed0dfa835113d9b8498d9f09ceb179beaac4002f036b9467c963"
  },
  "kernelspec": {
   "display_name": "PyCharm (ai-project)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
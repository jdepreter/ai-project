{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ArPMQU28Yzoj"
   },
   "source": [
    "# Install packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qlMvEkFXMHBD",
    "outputId": "618aaa5d-0a6a-4d87-fc2e-fae1c7f086d6",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Collecting pandas\n  Downloading pandas-1.3.3-cp37-cp37m-win_amd64.whl (10.0 MB)\nRequirement already satisfied: numpy in c:\\users\\quentindh\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (1.21.2)\nCollecting matplotlib\n  Using cached matplotlib-3.4.3-cp37-cp37m-win_amd64.whl (7.2 MB)\nCollecting sklearn\n  Using cached sklearn-0.0.tar.gz (1.1 kB)\nRequirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\quentindh\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from pandas) (2.8.2)\nCollecting pytz>=2017.3\n  Downloading pytz-2021.3-py2.py3-none-any.whl (503 kB)\nCollecting cycler>=0.10\n  Using cached cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\nCollecting pillow>=6.2.0\n  Downloading Pillow-8.4.0-cp37-cp37m-win_amd64.whl (3.2 MB)\nRequirement already satisfied: pyparsing>=2.2.1 in c:\\users\\quentindh\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from matplotlib) (2.4.7)\nCollecting kiwisolver>=1.0.1\n  Downloading kiwisolver-1.3.2-cp37-cp37m-win_amd64.whl (51 kB)\nCollecting scikit-learn\n  Downloading scikit_learn-1.0-cp37-cp37m-win_amd64.whl (7.1 MB)\nRequirement already satisfied: six>=1.5 in c:\\users\\quentindh\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from python-dateutil>=2.7.3->pandas) (1.16.0)\nCollecting threadpoolctl>=2.0.0\n  Downloading threadpoolctl-3.0.0-py3-none-any.whl (14 kB)\nCollecting joblib>=0.11\n  Downloading joblib-1.1.0-py2.py3-none-any.whl (306 kB)\nCollecting scipy>=1.1.0\n  Using cached scipy-1.7.1-cp37-cp37m-win_amd64.whl (33.6 MB)\nUsing legacy setup.py install for sklearn, since package 'wheel' is not installed.\nInstalling collected packages: pytz, pandas, cycler, pillow, kiwisolver, matplotlib, threadpoolctl, joblib, scipy, scikit-learn, sklearn\n    Running setup.py install for sklearn: started\n    Running setup.py install for sklearn: finished with status 'done'\nSuccessfully installed cycler-0.10.0 joblib-1.1.0 kiwisolver-1.3.2 matplotlib-3.4.3 pandas-1.3.3 pillow-8.4.0 pytz-2021.3 scikit-learn-1.0 scipy-1.7.1 sklearn-0.0 threadpoolctl-3.0.0\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": [
      "WARNING: You are using pip version 20.1.1; however, version 21.3 is available.\nYou should consider upgrading via the 'c:\\users\\quentindh\\appdata\\local\\programs\\python\\python37\\python.exe -m pip install --upgrade pip' command.\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# Install your required packages here\n",
    "!pip install pandas numpy matplotlib sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6HgMqLnwYFzN",
    "outputId": "b59b34d4-2cb9-41ee-9555-7da2ddfc37dd",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-100f81653ae7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Mount google drive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/content/drive'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google'"
     ],
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google'",
     "output_type": "error"
    }
   ],
   "source": [
    "# Mount google drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dABS7x_2MHBD",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import gzip\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BK42mwVZcP1m",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "#read file line-by-line and parse json, returns dataframe\n",
    "def parse_json(filename_gzipped_python_json, read_max=-1):\n",
    "  #read gzipped content\n",
    "  f=gzip.open(filename_gzipped_python_json,'r')\n",
    "  \n",
    "  #parse json\n",
    "  parse_data = []\n",
    "  for line in tqdm(f): #tqdm is for showing progress bar, always good when processing large amounts of data\n",
    "    line = line.decode('utf-8')\n",
    "    line = line.replace('true','True') #difference json/python\n",
    "    line = line.replace('false','False')\n",
    "    parsed_result = eval(line) #load python nested datastructure\n",
    "    parse_data.append(parsed_result)\n",
    "    if read_max !=-1 and len(parse_data) > read_max:\n",
    "      print(f'Break reading after {read_max} records')\n",
    "      break\n",
    "  print(f\"Reading {len(parse_data)} rows.\")\n",
    "\n",
    "  #create dataframe\n",
    "  df= pd.DataFrame.from_dict(parse_data)\n",
    "  return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SBkDfgFdYwXs"
   },
   "source": [
    "# Load steam data\n",
    "Note: For steam dataset, json data, is actually coded with Python (so not actually json), such as using values False instead of false and single quotes   instead of double literals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t8-WoBOlMHBE",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "steam_path = '/content/drive/MyDrive/AI Project/datasets/Steam/'\n",
    "metadata_games = 'steam_games.json.gz' \n",
    "user_items = 'australian_users_items.json.gz'\n",
    "user_reviews = 'australian_user_reviews.json.gz'\n",
    "game_bundles = 'bundle_data.json.gz'\n",
    "steam_reviews= 'steam_reviews.json.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "oJivkgXTesdq",
    "outputId": "0e8f837e-56d2-4026-ab08-65b1c54501b4",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "for dataset in [metadata_games, user_items, user_reviews, game_bundles, steam_reviews]:\n",
    "  print(f\"----- {dataset}-----\")\n",
    "  size = os.path.getsize(steam_path + dataset) \n",
    "  print(f'Size of file is {size / 1000000}MB')\n",
    "  df_metadata = parse_json(steam_path + dataset, read_max=1000000)\n",
    "  pd.set_option('display.max_colwidth', None)\n",
    "  display(df_metadata.head(5))\n",
    "  display(df_metadata.describe(include='all'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SlZS3hxS4Ouo"
   },
   "source": [
    "## Example pre-processing / data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "IxKtumfXig_7",
    "outputId": "0ae1d327-4393-4b24-e2fd-1c04a74a9542",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "#cleaner games\n",
    "games = parse_json(steam_path + metadata_games)\n",
    "games = games[['publisher','app_name', 'genres', 'release_date', 'price']]\n",
    "games = games.sort_values(by='release_date', ascending=False)\n",
    "display(games.head(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Pn5SzxT7mokn",
    "outputId": "e61b2444-6f93-420c-eb54-0c73e22bd16c",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "#cleaner interactions\n",
    "user_items_df = parse_json(steam_path + user_items, read_max=100000)\n",
    "user_items_df = user_items_df[['user_id', 'items']]\n",
    "#flatten interactions\n",
    "user_items_all_dct = {'user_id': [], 'item_id': [], 'title': [], 'playtime_forever': []}\n",
    "for idx, row in tqdm(user_items_df.iterrows()):\n",
    "    user_id = row['user_id']\n",
    "    items = row['items']\n",
    "    #rule: if never played, do not add to history\n",
    "    items = [item_dct for item_dct in items if item_dct['playtime_forever'] > 0]  \n",
    "    user_items_all_dct['user_id'].extend([user_id] * len(items))\n",
    "    user_items_all_dct['item_id'].extend([item_dct['item_id'] for item_dct in items])\n",
    "    user_items_all_dct['title'].extend([item_dct['item_name'] for item_dct in items])\n",
    "    user_items_all_dct['playtime_forever'].extend([item_dct['playtime_forever'] for item_dct in items])\n",
    "user_items_df = pd.DataFrame.from_dict(user_items_all_dct)\n",
    "display(user_items_df.head(50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ppGG1mXX4ryj"
   },
   "source": [
    "## Example: Compute popularity and popularity per genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 362
    },
    "id": "mCUrDUq6oZLJ",
    "outputId": "58e61024-6496-4290-d87e-88746325ff5f",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "#Most popular items:\n",
    "popular_items = user_items_df.groupby(by=\"title\")['user_id'].count().reset_index()\n",
    "popular_items = popular_items.rename(columns={\"user_id\": \"user_count\",\"title\": \"app_name\"})\n",
    "popular_items['user_pct'] = popular_items['user_count'] / user_items_df['user_id'].nunique()\n",
    "popular_items = pd.merge(popular_items,games,how='left',on='app_name')\n",
    "popular_items = popular_items.sort_values(by='user_count',ascending=False)\n",
    "display(popular_items.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "DDEf1DQkxbCj",
    "outputId": "63664544-83c3-48ba-fcf8-72aec8746939",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "#Most popular items per genre\n",
    "popular_per_genre_dct = {'genre': [], 'app_name': [], 'user_count':[]}\n",
    "#flatten frame on genre\n",
    "for idx, row in popular_items.iterrows():\n",
    "  genres = row['genres']\n",
    "  app_name = row['app_name']\n",
    "  user_count = row['user_count']\n",
    "  if isinstance(genres,list):\n",
    "    popular_per_genre_dct['genre'].extend(genres)\n",
    "    popular_per_genre_dct['app_name'].extend([app_name] * len(genres))\n",
    "    popular_per_genre_dct['user_count'].extend([user_count] * len(genres))  \n",
    "popular_items_genre = pd.DataFrame.from_dict(popular_per_genre_dct)\n",
    "#compute rank on user_count per genre\n",
    "popular_items_genre = popular_items_genre.sort_values(by=['genre', 'user_count'], ascending=['True', 'False'])\n",
    "popular_items_genre['genre_rank'] = popular_items_genre.groupby(by='genre')['user_count'].rank(ascending=False)\n",
    "#show top-10 popular games per genre\n",
    "popular_items_genre = popular_items_genre[popular_items_genre['genre_rank'] <= 10]\n",
    "display(popular_items_genre.head(50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uruDyk2W5Kks"
   },
   "source": [
    "## Example: Make recommendations content-based"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AnSK0O-85T7G"
   },
   "source": [
    "### Learn user profile consisting of top-3 most liked genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 709
    },
    "id": "ZicFcGZHqEuq",
    "outputId": "3b1fed78-00d8-4a92-e39f-c7d1b0b98247",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "#Example of content-based recommender\n",
    "#1)For each user compute top-3 most liked genres\n",
    "user_profiles_df = pd.merge(user_items_df, games, how='left', left_on='title', right_on='app_name')#merge with games to get genre of items\n",
    "display(user_profiles_df.head(3))\n",
    "user_profiles_df2 = user_profiles_df.groupby(by='user_id')['genres'].apply(list).reset_index() #collect list of genres of items in history\n",
    "user_profiles_df3 = user_profiles_df.groupby(by='user_id')['app_name'].apply(list).reset_index() #collect list of items in history\n",
    "user_profiles_df = pd.merge(user_profiles_df2,user_profiles_df3,on=\"user_id\") #merge both lists\n",
    "display(user_profiles_df.head(3))\n",
    "\n",
    "#i.e. [[Indie, Simulation], [Action], [Action], [Action, Adventure, Indie, RPG],...]\n",
    "def create_profile(genres_list):\n",
    "  cnt = Counter()\n",
    "  for genres in genres_list:\n",
    "    if isinstance(genres, list):\n",
    "      for genre in genres:\n",
    "       cnt[genre]+=1\n",
    "  return cnt.most_common(3)\n",
    "  \n",
    "user_profiles_df['top-3-genres'] = user_profiles_df['genres'].apply(create_profile)\n",
    "user_profiles_df = user_profiles_df[['user_id','app_name','top-3-genres']]\n",
    "display(user_profiles_df.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5g8XT6YT5jkM"
   },
   "source": [
    "### Make recommendations based on most popular games matching top-3 most liked genres in history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "TC6Ivukkvbkr",
    "outputId": "1d1bbf6a-b709-4d76-f786-3c8ac635784f",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "#2)For prediction suggest top-10 most popular games matching genre profile \n",
    "def recommend_popular_in_genre(profile):\n",
    "  genres = profile['top-3-genres']\n",
    "  genres = set([genre for genre, count in genres])\n",
    "  history = set(profile['app_name'])\n",
    "  selection = popular_items_genre[popular_items_genre['genre'].isin(genres)]\n",
    "  selection = popular_items_genre[~popular_items_genre['app_name'].isin(history)]\n",
    "  selection = selection.drop_duplicates(subset='app_name')\n",
    "  selection = selection.sort_values(by='user_count', ascending=False)\n",
    "  return selection.values[0:10]\n",
    "\n",
    "tqdm.pandas() #adds progress_apply to pandas, i.e. apply with progress bar\n",
    "user_profiles_df['recommendation'] = user_profiles_df.progress_apply(recommend_popular_in_genre,axis=1)\n",
    "display(user_profiles_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O1E4YI-zr5Mz"
   },
   "source": [
    "# Load food data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qDbBMbAUNKTs",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "food_path = '/content/drive/MyDrive/AI Project/datasets/Food/'\n",
    "recipes = 'RAW_recipes.csv.zip' \n",
    "interactions = 'RAW_interactions.csv.zip'\n",
    "pp_recipes = 'PP_recipes.csv.zip'\n",
    "pp_users = 'PP_users.csv.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "1RYJ1rlcMHBF",
    "outputId": "3f85eca5-2f94-4b03-e9e9-1687f8b2167d",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "for dataset in [recipes, interactions, pp_recipes, pp_users]:\n",
    "  print(f\"----- {dataset}-----\")\n",
    "  size = os.path.getsize(food_path + dataset) \n",
    "  print(f'Size of file is {size / 1000000}MB')\n",
    "  df = pd.read_csv(food_path + dataset)\n",
    "  pd.set_option('display.max_colwidth', None)\n",
    "  display(df.head(5))\n",
    "  display(df.describe(include='all'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NHB7mgRfiKTY",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "#clean data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TxnlmqofYTU-"
   },
   "source": [
    "# Load Goodreads data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y6O79-jSYqqF",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "goodreads_path = '/content/drive/MyDrive/AI Project/datasets/Goodreads/'\n",
    "books = 'goodreads_books_comics_graphic.json.gz'\n",
    "interactions = 'goodreads_interactions_comics_graphic.json.gz'\n",
    "reviews = 'goodreads_reviews_comics_graphic.json.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "m1HE81puZowr",
    "outputId": "46928298-63ef-4233-f307-903306f4f989",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "for dataset in [books, interactions, reviews]:\n",
    "  print(f\"----- {dataset}-----\")\n",
    "  size = os.path.getsize(goodreads_path + dataset) \n",
    "  print(f'Size of file is {size / 1000000}MB')\n",
    "  #df = pd.read_json(goodreads_path + dataset, lines=True, nrows=1000)\n",
    "  df = parse_json(goodreads_path + dataset, read_max=100000)\n",
    "  pd.set_option('display.max_colwidth', None)\n",
    "  display(df.head(5))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "load_data.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "interpreter": {
   "hash": "bb4b0081ce28d54e315b6de2a107094f9f2d65579be22a25be7116312a3cdb4a"
  },
  "kernelspec": {
   "name": "pycharm-dea5454d",
   "language": "python",
   "display_name": "PyCharm (ai-project)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
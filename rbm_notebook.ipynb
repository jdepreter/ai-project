{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Restricted Boltzmann Machine Defintion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Import PyTorch library\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "device = torch.device('cpu')\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# https://github.com/khanhnamle1994/MetaRec/blob/b5e36cb579a88b32cdfb728f35f645d76b24ad95/Boltzmann-Machines-Experiments/RBM-CF-PyTorch/rbm.py#L23\n",
    "# Create the Restricted Boltzmann Machine architecture\n",
    "class RBM(nn.Module):\n",
    "    def __init__(self, n_vis, n_hid):\n",
    "        \"\"\"\n",
    "        Initialize the parameters (weights and biases) we optimize during the training process\n",
    "        :param n_vis: number of visible units\n",
    "        :param n_hid: number of hidden units\n",
    "        \"\"\"\n",
    "        self.i = 0\n",
    "\n",
    "        # Weights used for the probability of the visible units given the hidden units\n",
    "        super().__init__()\n",
    "        self.W = torch.zeros(n_hid, n_vis, device=device)  # torch.rand: random normal distribution mean = 0, variance = 1\n",
    "\n",
    "        # Bias probability of the visible units is activated, given the value of the hidden units (p_v_given_h)\n",
    "        self.v_bias = torch.zeros(1, n_vis, device=device)  # fake dimension for the batch = 1\n",
    "\n",
    "        # Bias probability of the hidden units is activated, given the value of the visible units (p_h_given_v)\n",
    "        self.h_bias = torch.zeros(1, n_hid, device=device)  # fake dimension for the batch = 1\n",
    "    \n",
    "    def lr(self):\n",
    "        return 0.02\n",
    "\n",
    "    def sample_h(self, x):\n",
    "        \"\"\"\n",
    "        Sample the hidden units\n",
    "        :param x: the dataset\n",
    "        \"\"\"\n",
    "\n",
    "        # Probability h is activated given that the value v is sigmoid(Wx + a)\n",
    "        # torch.mm make the product of 2 tensors\n",
    "        # W.t() take the transpose because W is used for the p_v_given_h\n",
    "        wx = torch.mm(x, self.W.t())\n",
    "        # print(wx.shape)\n",
    "\n",
    "        # Expand the mini-batch\n",
    "        activation = wx + self.h_bias.expand_as(wx)\n",
    "        # print(activation.shape)\n",
    "\n",
    "        # Calculate the probability p_h_given_v\n",
    "        p_h_given_v = torch.sigmoid(activation)\n",
    "\n",
    "        # print(\"h sparse\", p_h_given_v.is_sparse, torch.bernoulli(p_h_given_v).is_sparse)\n",
    "\n",
    "        # Construct a Bernoulli RBM to predict whether an user loves the movie or not (0 or 1)\n",
    "        # This corresponds to whether the n_hid is activated or not activated\n",
    "        return p_h_given_v, torch.bernoulli(p_h_given_v)\n",
    "\n",
    "    def sample_v(self, y):\n",
    "        \"\"\"\n",
    "        Sample the visible units\n",
    "        :param y: the dataset\n",
    "        \"\"\"\n",
    "\n",
    "        # Probability v is activated given that the value h is sigmoid(Wx + a)\n",
    "        wy = torch.mm(y, self.W)\n",
    "\n",
    "        # Expand the mini-batch\n",
    "        activation = wy + self.v_bias.expand_as(wy)\n",
    "\n",
    "        # Calculate the probability p_v_given_h\n",
    "        p_v_given_h = torch.sigmoid(activation)\n",
    "\n",
    "        # print(\"v sparse\", p_v_given_h.is_sparse, torch.bernoulli(p_v_given_h).is_sparse)\n",
    "\n",
    "        # Construct a Bernoulli RBM to predict whether an user loves the movie or not (0 or 1)\n",
    "        # This corresponds to whether the n_vis is activated or not activated\n",
    "        return p_v_given_h, torch.bernoulli(p_v_given_h)\n",
    "\n",
    "    def train_model(self, v0, vk, ph0, phk):\n",
    "        \"\"\"\n",
    "        Perform contrastive divergence algorithm to optimize the weights that minimize the energy\n",
    "        This maximizes the log-likelihood of the model\n",
    "        \"\"\"\n",
    "\n",
    "        w_extra = (torch.mm(v0.t(), ph0) - torch.mm(vk.t(), phk)).t()\n",
    "        v_extra = torch.sum((v0 - vk), 0)\n",
    "        h_extra = torch.sum((ph0 - phk), 0)\n",
    "\n",
    "        # if self.i % 45 == 0:\n",
    "            # print(torch.max(w_extra), torch.max(v_extra), torch.max(h_extra), flush=True)\n",
    "\n",
    "        # Approximate the gradients with the CD algorithm\n",
    "        # TODO learning rate toevoegen\n",
    "        self.W += self.lr() * w_extra\n",
    "\n",
    "        # Add (difference, 0) for the tensor of 2 dimensions\n",
    "        self.v_bias += self.lr() * v_extra\n",
    "        self.h_bias += self.lr() * h_extra\n",
    "        self.i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "cuda = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "import gzip\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "import math\n",
    "tqdm.pandas() #for progres_apply etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "#read file line-by-line and parse json, returns dataframe\n",
    "def parse_json(filename_gzipped_python_json, read_max=-1):\n",
    "  #read gzipped content\n",
    "  f=gzip.open(filename_gzipped_python_json,'r')\n",
    "  \n",
    "  #parse json\n",
    "  parse_data = []\n",
    "  for line in tqdm(f): #tqdm is for showing progress bar, always good when processing large amounts of data\n",
    "    line = line.decode('utf-8')\n",
    "    line = line.replace('true','True') #difference json/python\n",
    "    line = line.replace('false','False')\n",
    "    parsed_result = eval(line) #load python nested datastructure\n",
    "    # print(filename_gzipped_python_json == steam_path + steam_reviews and 'user_id' not in parsed_result)\n",
    "    # break\n",
    "    if filename_gzipped_python_json == steam_path + steam_reviews and 'user_id' not in parsed_result:\n",
    "      continue\n",
    "      \n",
    "    parse_data.append(parsed_result)\n",
    "    if read_max !=-1 and len(parse_data) > read_max:\n",
    "      print(f'Break reading after {read_max} records')\n",
    "      break\n",
    "  print(f\"Reading {len(parse_data)} rows.\")\n",
    "\n",
    "  #create dataframe\n",
    "  df= pd.DataFrame.from_dict(parse_data)\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "steam_path = './data/'\n",
    "metadata_games = 'steam_games.json.gz' \n",
    "user_items = 'australian_users_items.json.gz'\n",
    "user_reviews = 'australian_user_reviews.json.gz'\n",
    "game_bundles = 'bundle_data.json.gz'\n",
    "steam_reviews= 'steam_reviews.json.gz'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Australien Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- australian_user_reviews.json.gz-----\n",
      "Size of file is 6.940139MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25799it [00:01, 19466.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 25799 rows.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# for dataset in [metadata_games, user_items, user_reviews, game_bundles, steam_reviews]:\n",
    "for dataset in [user_reviews]:\n",
    "  print(f\"----- {dataset}-----\")\n",
    "  size = os.path.getsize(steam_path + dataset) \n",
    "  print(f'Size of file is {size / 1000000}MB')\n",
    "  df_metadata = parse_json(steam_path + dataset)\n",
    "  pd.set_option('display.max_colwidth', None)\n",
    "  # display(df_metadata.head(5))\n",
    "#   display(df_metadata.describe(include='all'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25799it [00:01, 19205.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 25799 rows.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "user_reviews_df = parse_json(steam_path + user_reviews)\n",
    "user_reviews_df = user_reviews_df.drop_duplicates(subset='user_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "user_reviews_df_exploded = user_reviews_df.explode('reviews')\n",
    "user_reviews_df_exploded = user_reviews_df_exploded.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def func(x):\n",
    "    return x['recommend'], x[\"item_id\"]\n",
    "\n",
    "user_reviews_df_exploded['recommended'], user_reviews_df_exploded[\"item_id\"] = zip(\n",
    "    *user_reviews_df_exploded['reviews'].map(func)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "user_reviews_df_exploded.reset_index()\n",
    "\n",
    "\n",
    "user_reviews_df_exploded = user_reviews_df_exploded[['user_id', 'item_id', 'recommended']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter users with 1 or no reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24                         [False, True]\n",
       "26       [True, True, True, False, True]\n",
       "36                         [True, False]\n",
       "60             [False, True, True, True]\n",
       "71                         [False, True]\n",
       "                      ...               \n",
       "25758    [True, True, True, False, True]\n",
       "25761                      [False, True]\n",
       "25764                [True, True, False]\n",
       "25768    [True, True, False, True, True]\n",
       "25785                [True, True, False]\n",
       "Length: 3684, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enkeltrue = user_reviews_df[['reviews']].apply(lambda x: [elem['recommend'] for elem in x['reviews']], axis=1)\n",
    "enkeltrue.loc[enkeltrue.map(set).map(len) > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 58430/58430 [00:00<00:00, 1424794.38it/s]\n"
     ]
    }
   ],
   "source": [
    "dct = {}\n",
    "def map_to_consecutive_id(uuid):\n",
    "  if uuid in dct:\n",
    "    return dct[uuid]\n",
    "  else:\n",
    "    id = len(dct)\n",
    "    dct[uuid] = id\n",
    "    return id\n",
    "user_reviews_df_exploded['item_id_int'] = user_reviews_df_exploded['item_id'].progress_apply(map_to_consecutive_id)\n",
    "user_reviews_df_exploded.dtypes\n",
    "f = open(\"item_dct.json\", 'w')\n",
    "json.dump(dct, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 58430/58430 [00:00<00:00, 1327662.29it/s]\n"
     ]
    }
   ],
   "source": [
    "dct = {}\n",
    "user_reviews_df_exploded['user_id_int'] = user_reviews_df_exploded['user_id'].progress_apply(map_to_consecutive_id)\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_df, test_df = train_test_split(user_reviews_df_exploded, test_size=0.2)\n",
    "\n",
    "\n",
    "test_df_grouped = test_df.groupby('user_id_int').agg(list)\n",
    "test_df_grouped = test_df_grouped.reset_index()\n",
    "\n",
    "train_df_grouped = train_df.groupby('user_id_int').agg(list)\n",
    "train_df_grouped = train_df_grouped.reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "#Create scipy csr matrix\n",
    "def get_sparse_matrix(df):\n",
    "    shape = (user_reviews_df_exploded['user_id_int'].max() + 1, user_reviews_df_exploded['item_id_int'].max() + 1)\n",
    "    \n",
    "    user_ids = []\n",
    "    item_ids = []\n",
    "    values = []\n",
    "    for idx, row in df.iterrows():\n",
    "        items = row['item_id_int']\n",
    "        user = row['user_id_int']\n",
    "    \n",
    "        recommended = row['recommended']\n",
    "        user_ids.extend([user] * len(items))\n",
    "        item_ids.extend(items)\n",
    "        values.extend([2 if recommended[i] else 1 for i in range(len(items))])\n",
    "    #create csr matrix\n",
    "    # values = np.ones(len(user_ids))\n",
    "    matrix = scipy.sparse.csr_matrix((values, (user_ids, item_ids)), shape=shape, dtype=np.int32)\n",
    "    return matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Sparse Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<25457x3682 sparse matrix of type '<class 'numpy.intc'>'\n",
       "\twith 46744 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_matrix = get_sparse_matrix(test_df_grouped)\n",
    "\n",
    "train_matrix = get_sparse_matrix(train_df_grouped)\n",
    "train_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x22253415530>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------\n",
      "start training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:34<00:00,  3.47s/it]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def score_model(rbm, batch_size):\n",
    "    test_recon_error = 0  # RMSE reconstruction error initialized to 0 at the beginning of training\n",
    "    s = 0  # a counter (float type) \n",
    "    # for loop - go through every single user\n",
    "    for id_user in range(0, user_reviews_df_exploded['user_id_int'].max() + 1 - batch_size, batch_size):\n",
    "        v = train_matrix[id_user:id_user + batch_size]  # training set inputs are used to activate neurons of my RBM\n",
    "        vt = test_matrix[id_user:id_user + batch_size]  # target\n",
    "        # v = convert_sparse_matrix_to_sparse_tensor(training_sample)\n",
    "        # vt = convert_sparse_matrix_to_sparse_tensor(training_sample2)\n",
    "        v = v.todense()\n",
    "        vt = vt.todense()\n",
    "\n",
    "        # v = v.to_dense()\n",
    "        # vt = vt.to_dense()\n",
    "        v = v - 1\n",
    "        vt = vt - 1\n",
    "        v = torch.Tensor(v)\n",
    "        vt = torch.Tensor(vt)\n",
    "        if torch.cuda.is_available():\n",
    "            v = v.cuda()\n",
    "            vt = vt.cuda()\n",
    "        if len(vt[vt > -1]) > 0:\n",
    "            _, h = rbm.sample_h(v)\n",
    "            _, v = rbm.sample_v(h)\n",
    "\n",
    "            # Update test RMSE reconstruction error\n",
    "            test_recon_error += torch.sqrt(torch.mean((vt[vt > -1] - v[vt > -1])**2)) * len(vt > -1)\n",
    "            s += len(vt > -1) \n",
    "\n",
    "    return test_recon_error / s\n",
    "\n",
    "print('-------')\n",
    "n_vis = user_reviews_df_exploded['item_id_int'].max() + 1\n",
    "n_hidden = 1024\n",
    "batch_size = 1024\n",
    "epochs = 10\n",
    "train_errors = []\n",
    "test_errors = []\n",
    "rbm = RBM(n_vis, n_hidden)\n",
    "\n",
    "# https://stackoverflow.com/questions/40896157/scipy-sparse-csr-matrix-to-tensorflow-sparsetensor-mini-batch-gradient-descent\n",
    "def convert_sparse_matrix_to_sparse_tensor(X):\n",
    "    coo = X.tocoo()\n",
    "\n",
    "    values = coo.data\n",
    "    indices = np.vstack((coo.row, coo.col))\n",
    "\n",
    "    i = torch.LongTensor(indices)\n",
    "    v = torch.FloatTensor(values)\n",
    "    # print(values)\n",
    "    # print(\"values\", v)\n",
    "    shape = coo.shape\n",
    "    tensor = torch.sparse.FloatTensor(i, v, torch.Size(shape)) \n",
    "    if torch.cuda.is_available():\n",
    "        tensor = tensor.cuda()\n",
    "\n",
    "    return tensor \n",
    "\n",
    "print(\"start training\")\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    rbm.train()\n",
    "    train_recon_error = 0  # RMSE reconstruction error initialized to 0 at the beginning of training\n",
    "    s = 0\n",
    "    \n",
    "    for user_id in range(0, user_reviews_df_exploded['user_id_int'].max() + 1 - batch_size, batch_size):\n",
    "        training_sample = train_matrix[user_id : user_id + batch_size]\n",
    "        training_sample2 = train_matrix[user_id : user_id + batch_size]\n",
    "        # print(training_sample)\n",
    "        v0 = convert_sparse_matrix_to_sparse_tensor(training_sample)\n",
    "        # print(v0.coalesce().indices())\n",
    "        vk = convert_sparse_matrix_to_sparse_tensor(training_sample2)\n",
    "\n",
    "        v0 = v0.to_dense()\n",
    "        vk = vk.to_dense()\n",
    "        v0 = v0.sub(1)\n",
    "        vk = vk.sub(1)\n",
    "        \n",
    "        ph0, _ = rbm.sample_h(v0)   \n",
    "\n",
    "        # Third for loop - perform contrastive divergence\n",
    "        # TODO misschien is iets lager proberen?\n",
    "        # TODO start at 1, increase over time\n",
    "        for k in range(10):\n",
    "            _, hk = rbm.sample_h(vk)\n",
    "            _, vk = rbm.sample_v(hk)\n",
    "\n",
    "            # We don't want to learn when there is no rating by the user, and there is no update when rating = -1\n",
    "            # Remove indices from vk vector that are not in the v0 vector => get sparse tensor again\n",
    "            vk[v0 < 0] = v0[v0 < 0]\n",
    "            vksparse = vk.to_sparse()\n",
    "            # print(\"v0\", v0)\n",
    "            # print(\"v0\", v0.add(1).to_sparse())\n",
    "            # print(\"vk\", vk.add(1).to_sparse())\n",
    "            \n",
    "            # print(k)\n",
    "\n",
    "        phk, _ = rbm.sample_h(vk)\n",
    "\n",
    "\n",
    "        rbm.train_model(v0, vk, ph0, phk)\n",
    "        \n",
    "        train_recon_error += torch.sqrt(torch.mean((v0[v0 > -1] - vk[v0 > -1])**2)) * len(v0 > -1)\n",
    "        s += len(v0 > -1)\n",
    "        \n",
    "        # print((torch.mm(v0.t(), ph0) - torch.mm(vk.t(), phk)).t().shape)\n",
    "        # print(torch.sum((-vk + v0), 0).shape)\n",
    "        # print(torch.sum((ph0 - phk), 0).shape)\n",
    "        \n",
    "    train_errors.append(train_recon_error / s)\n",
    "\n",
    "    # print('calculating test scores')\n",
    "    rbm.eval()\n",
    "    test_errors.append(score_model(rbm, batch_size))\n",
    "\n",
    "    # print('finished epoch', epoch)    \n",
    "    \n",
    "import matplotlib.pyplot as plt\n",
    "# Plot the RMSE reconstruction error with respect to increasing number of epochs\n",
    "plt.plot(torch.Tensor(train_errors, device='cpu'), label=\"train\")\n",
    "plt.plot(torch.Tensor(test_errors, device='cpu'), label=\"test\")\n",
    "plt.ylabel('Error')\n",
    "plt.xlabel('Epoch')\n",
    "plt.savefig(f'test0-{batch_size}-{epochs}.jpg')\n",
    "\n",
    "# Evaluate the RBM on test set\n",
    "# test_recon_error = score_model(rbm)\n",
    "# print(\"Final error\", test_recon_error)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jolan\\AppData\\Local\\Temp/ipykernel_6996/1445240602.py:28: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  recommendations = torch.tensor(indices, device='cpu').tolist()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hr 0.1606008793356131\n",
      "recall 0.13985710796287248\n"
     ]
    }
   ],
   "source": [
    "def compute_hr(rbm, k=10, batch_size=100):\n",
    "    s = 0  # a counter (float type) \n",
    "    hitrates = []\n",
    "    recall = []\n",
    "    # for loop - go through every single user\n",
    "    for id_user in range(0, user_reviews_df_exploded['user_id_int'].max() + 1): # - batch_size, batch_size):\n",
    "        v = train_matrix[id_user]  # training set inputs are used to activate neurons of my RBM\n",
    "        vt = test_matrix[id_user]  # target\n",
    "\n",
    "        target_data = vt.data\n",
    "        target_index = vt.indices\n",
    "        target_recommendations = target_index[target_data == 2]\n",
    "        # print(target_test)\n",
    "\n",
    "        v = v.todense()\n",
    "\n",
    "        v = v - 1\n",
    "        v = torch.Tensor(v)\n",
    "        if torch.cuda.is_available():\n",
    "            v = v.cuda()\n",
    "        \n",
    "        if len(target_recommendations) > 0: # check that target contains recommendations (only needed for aussies)\n",
    "            _, h = rbm.sample_h(v)\n",
    "            recommended, _ = rbm.sample_v(h)\n",
    "\n",
    "            # all recommendations\n",
    "            _, indices =  torch.topk(recommended[v < 0], k)\n",
    "            recommendations = torch.tensor(indices, device='cpu').tolist()\n",
    "\n",
    "            counter = 0\n",
    "            total = len(target_recommendations)\n",
    "            for target in target_recommendations:\n",
    "                if target in recommendations:\n",
    "                    counter += 1\n",
    "            # counter = len(recommendations)\n",
    "\n",
    "            recall.append(counter / total)\n",
    "            hitrates.append(min(1, counter))\n",
    "           \n",
    "\n",
    "    return hitrates, recall\n",
    "\n",
    "hr, r = compute_hr(rbm)\n",
    "print(\"hr\", np.average(hr))\n",
    "print(\"recall\", np.average(r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(torch.Tensor(train_errors, device='cpu'), label=\"train\")\n",
    "plt.plot(torch.Tensor(test_errors, device='cpu'), label=\"test\")\n",
    "plt.ylabel('Error')\n",
    "plt.xlabel('Epoch')\n",
    "plt.savefig('errors.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# torch.save(rbm.state_dict(), \"./network\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true,
     "name": "#%% load model\n"
    }
   },
   "outputs": [],
   "source": [
    "rbm = RBM(n_vis, n_hidden)\n",
    "rbm.load_state_dict(torch.load(\"./network\"))\n",
    "rbm.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Full Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7793069it [03:52, 33544.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 3176223 rows.\n"
     ]
    }
   ],
   "source": [
    "steam_reviews_df = parse_json(steam_path + steam_reviews)\n",
    "steam_reviews_df_small = steam_reviews_df[['user_id', 'product_id', 'recommended', 'date']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "steam_reviews_df_cleaned = steam_reviews_df_small.dropna(axis=0, subset=['user_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76561198011965365    1254\n",
       "76561198094803808     900\n",
       "76561197969749884     750\n",
       "76561198094321628     669\n",
       "76561198073092169     549\n",
       "                     ... \n",
       "76561198345086561       1\n",
       "76561198054491833       1\n",
       "76561198095690287       1\n",
       "76561198301658414       1\n",
       "76561198089897928       1\n",
       "Name: user_id, Length: 1485611, dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steam_reviews_df_cleaned.head(5)\n",
    "steam_reviews_df[\"user_id\"].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3176223/3176223 [00:01<00:00, 1672200.46it/s]\n"
     ]
    }
   ],
   "source": [
    "dct = {}\n",
    "def map_to_consecutive_id(uuid):\n",
    "  if uuid in dct:\n",
    "    return dct[uuid]\n",
    "  else:\n",
    "    id = len(dct)\n",
    "    dct[uuid] = id\n",
    "    return id\n",
    "steam_reviews_df_cleaned['product_id_int'] = steam_reviews_df_cleaned['product_id'].progress_apply(map_to_consecutive_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# train_df, test_df = train_test_split(steam_reviews_df_cleaned, test_size=0.2)\n",
    "\n",
    "\n",
    "# test_df_grouped = test_df.groupby('user_id_int').agg(list)\n",
    "# test_df_grouped = test_df_grouped.reset_index()\n",
    "\n",
    "# train_df_grouped = train_df.groupby('user_id_int').agg(list)\n",
    "# train_df_grouped = train_df_grouped.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Date Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id                   object\n",
       "product_id                object\n",
       "recommended                 bool\n",
       "date              datetime64[ns]\n",
       "product_id_int             int64\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>recommended</th>\n",
       "      <th>date</th>\n",
       "      <th>product_id_int</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>76561198007483075</td>\n",
       "      <td>35140</td>\n",
       "      <td>True</td>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>76561197970402776</td>\n",
       "      <td>707610</td>\n",
       "      <td>True</td>\n",
       "      <td>2017-10-16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>76561198060686749</td>\n",
       "      <td>328100</td>\n",
       "      <td>True</td>\n",
       "      <td>2017-06-23</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>76561198023491401</td>\n",
       "      <td>35140</td>\n",
       "      <td>True</td>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>76561198115331805</td>\n",
       "      <td>35140</td>\n",
       "      <td>True</td>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             user_id product_id  recommended       date  product_id_int\n",
       "0  76561198007483075      35140         True 2018-01-04               0\n",
       "1  76561197970402776     707610         True 2017-10-16               1\n",
       "2  76561198060686749     328100         True 2017-06-23               2\n",
       "3  76561198023491401      35140         True 2018-01-03               0\n",
       "4  76561198115331805      35140         True 2018-01-03               0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "steam_reviews_df_cleaned[\"date\"] = pd.to_datetime(steam_reviews_df_cleaned[\"date\"])\n",
    "display(steam_reviews_df_cleaned.dtypes)\n",
    "display(steam_reviews_df_cleaned.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id_int</th>\n",
       "      <th>recommended</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>76561197960265806</th>\n",
       "      <td>[14313]</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[2017-12-20 00:00:00]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76561197960266010</th>\n",
       "      <td>[9722]</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[2017-11-27 00:00:00]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76561197960266146</th>\n",
       "      <td>[597]</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[2017-11-04 00:00:00]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76561197960266225</th>\n",
       "      <td>[1622]</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[2017-06-07 00:00:00]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76561197960266375</th>\n",
       "      <td>[3716]</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[2017-09-13 00:00:00]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  product_id_int recommended                   date\n",
       "user_id                                                            \n",
       "76561197960265806        [14313]      [True]  [2017-12-20 00:00:00]\n",
       "76561197960266010         [9722]      [True]  [2017-11-27 00:00:00]\n",
       "76561197960266146          [597]      [True]  [2017-11-04 00:00:00]\n",
       "76561197960266225         [1622]      [True]  [2017-06-07 00:00:00]\n",
       "76561197960266375         [3716]      [True]  [2017-09-13 00:00:00]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id_int</th>\n",
       "      <th>recommended</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>76561197960266546</th>\n",
       "      <td>[2678, 2678]</td>\n",
       "      <td>[True, True]</td>\n",
       "      <td>[2016-11-25 00:00:00, 2016-11-25 00:00:00]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76561197960266564</th>\n",
       "      <td>[7259, 7259]</td>\n",
       "      <td>[True, True]</td>\n",
       "      <td>[2016-08-14 00:00:00, 2016-08-14 00:00:00]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76561197960267022</th>\n",
       "      <td>[7779, 13382]</td>\n",
       "      <td>[True, True]</td>\n",
       "      <td>[2015-09-29 00:00:00, 2015-04-16 00:00:00]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76561197960267615</th>\n",
       "      <td>[1428, 2098, 2545, 2643, 2633, 3052, 3150, 3979, 3979, 5255, 5797, 5747, 5884, 6832, 6500, 6956, 7122, 7102, 7352, 7469, 7931, 9757, 9911, 10291, 11006, 11309, 11432, 11736, 12754, 12703, 12755, 13323, 13215, 13544, 14085, 14055]</td>\n",
       "      <td>[True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True]</td>\n",
       "      <td>[2012-11-06 00:00:00, 2011-11-30 00:00:00, 2011-07-16 00:00:00, 2011-11-30 00:00:00, 2012-04-04 00:00:00, 2011-07-06 00:00:00, 2011-11-30 00:00:00, 2010-12-10 00:00:00, 2010-12-10 00:00:00, 2011-11-30 00:00:00, 2010-12-10 00:00:00, 2011-11-30 00:00:00, 2013-01-09 00:00:00, 2011-11-30 00:00:00, 2013-10-30 00:00:00, 2011-11-30 00:00:00, 2011-11-30 00:00:00, 2011-11-30 00:00:00, 2011-11-30 00:00:00, 2011-11-30 00:00:00, 2011-11-30 00:00:00, 2010-12-10 00:00:00, 2011-09-13 00:00:00, 2010-12-10 00:00:00, 2011-11-30 00:00:00, 2012-11-05 00:00:00, 2011-11-30 00:00:00, 2011-07-20 00:00:00, 2012-12-14 00:00:00, 2011-11-30 00:00:00, 2011-11-30 00:00:00, 2010-12-10 00:00:00, 2011-11-30 00:00:00, 2012-07-14 00:00:00, 2011-07-30 00:00:00, 2011-11-30 00:00:00]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76561197960268226</th>\n",
       "      <td>[9485, 13462]</td>\n",
       "      <td>[True, True]</td>\n",
       "      <td>[2015-06-01 00:00:00, 2016-11-28 00:00:00]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                          product_id_int  \\\n",
       "user_id                                                                                                                                                                                                                                                    \n",
       "76561197960266546                                                                                                                                                                                                                           [2678, 2678]   \n",
       "76561197960266564                                                                                                                                                                                                                           [7259, 7259]   \n",
       "76561197960267022                                                                                                                                                                                                                          [7779, 13382]   \n",
       "76561197960267615  [1428, 2098, 2545, 2643, 2633, 3052, 3150, 3979, 3979, 5255, 5797, 5747, 5884, 6832, 6500, 6956, 7122, 7102, 7352, 7469, 7931, 9757, 9911, 10291, 11006, 11309, 11432, 11736, 12754, 12703, 12755, 13323, 13215, 13544, 14085, 14055]   \n",
       "76561197960268226                                                                                                                                                                                                                          [9485, 13462]   \n",
       "\n",
       "                                                                                                                                                                                                                                recommended  \\\n",
       "user_id                                                                                                                                                                                                                                       \n",
       "76561197960266546                                                                                                                                                                                                              [True, True]   \n",
       "76561197960266564                                                                                                                                                                                                              [True, True]   \n",
       "76561197960267022                                                                                                                                                                                                              [True, True]   \n",
       "76561197960267615  [True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True]   \n",
       "76561197960268226                                                                                                                                                                                                              [True, True]   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   date  \n",
       "user_id                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "76561197960266546                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            [2016-11-25 00:00:00, 2016-11-25 00:00:00]  \n",
       "76561197960266564                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            [2016-08-14 00:00:00, 2016-08-14 00:00:00]  \n",
       "76561197960267022                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            [2015-09-29 00:00:00, 2015-04-16 00:00:00]  \n",
       "76561197960267615  [2012-11-06 00:00:00, 2011-11-30 00:00:00, 2011-07-16 00:00:00, 2011-11-30 00:00:00, 2012-04-04 00:00:00, 2011-07-06 00:00:00, 2011-11-30 00:00:00, 2010-12-10 00:00:00, 2010-12-10 00:00:00, 2011-11-30 00:00:00, 2010-12-10 00:00:00, 2011-11-30 00:00:00, 2013-01-09 00:00:00, 2011-11-30 00:00:00, 2013-10-30 00:00:00, 2011-11-30 00:00:00, 2011-11-30 00:00:00, 2011-11-30 00:00:00, 2011-11-30 00:00:00, 2011-11-30 00:00:00, 2011-11-30 00:00:00, 2010-12-10 00:00:00, 2011-09-13 00:00:00, 2010-12-10 00:00:00, 2011-11-30 00:00:00, 2012-11-05 00:00:00, 2011-11-30 00:00:00, 2011-07-20 00:00:00, 2012-12-14 00:00:00, 2011-11-30 00:00:00, 2011-11-30 00:00:00, 2010-12-10 00:00:00, 2011-11-30 00:00:00, 2012-07-14 00:00:00, 2011-07-30 00:00:00, 2011-11-30 00:00:00]  \n",
       "76561197960268226                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            [2015-06-01 00:00:00, 2016-11-28 00:00:00]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "steam_reviews_df_grouped = steam_reviews_df_cleaned.groupby(\"user_id\")[[\"product_id_int\", \"recommended\", \"date\"]].agg(list)\n",
    "display(steam_reviews_df_grouped.head(5))\n",
    "\n",
    "steam_reviews_df_grouped_smaller = steam_reviews_df_grouped[steam_reviews_df_grouped[\"recommended\"].map(len) > 1]\n",
    "display(steam_reviews_df_grouped_smaller.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 581343/581343 [00:00<00:00, 1167091.91it/s]\n"
     ]
    }
   ],
   "source": [
    "dct.clear()\n",
    "steam_reviews_df_grouped_smaller = steam_reviews_df_grouped_smaller.reset_index()\n",
    "steam_reviews_df_grouped_smaller[\"user_id_int\"] = steam_reviews_df_grouped_smaller[\"user_id\"].progress_apply(map_to_consecutive_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(581343, 5)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(1485611, 3)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "904268\n"
     ]
    }
   ],
   "source": [
    "display(steam_reviews_df_grouped_smaller.shape)\n",
    "display(steam_reviews_df_grouped.shape)\n",
    "print(steam_reviews_df_grouped.shape[0] - steam_reviews_df_grouped_smaller.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 581343/581343 [00:00<00:00, 1126379.15it/s]\n",
      "100%|██████████| 581343/581343 [00:00<00:00, 1132967.87it/s]\n",
      "100%|██████████| 581343/581343 [00:01<00:00, 365661.56it/s]\n",
      "100%|██████████| 581343/581343 [00:00<00:00, 1149768.63it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>product_id_int</th>\n",
       "      <th>recommended</th>\n",
       "      <th>date</th>\n",
       "      <th>user_id_int</th>\n",
       "      <th>product_history</th>\n",
       "      <th>product_future</th>\n",
       "      <th>recommended_history</th>\n",
       "      <th>recommended_future</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>76561197960266546</td>\n",
       "      <td>[2678, 2678]</td>\n",
       "      <td>[True, True]</td>\n",
       "      <td>[2016-11-25 00:00:00, 2016-11-25 00:00:00]</td>\n",
       "      <td>0</td>\n",
       "      <td>[2678]</td>\n",
       "      <td>[2678]</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>76561197960266564</td>\n",
       "      <td>[7259, 7259]</td>\n",
       "      <td>[True, True]</td>\n",
       "      <td>[2016-08-14 00:00:00, 2016-08-14 00:00:00]</td>\n",
       "      <td>1</td>\n",
       "      <td>[7259]</td>\n",
       "      <td>[7259]</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>76561197960267022</td>\n",
       "      <td>[7779, 13382]</td>\n",
       "      <td>[True, True]</td>\n",
       "      <td>[2015-09-29 00:00:00, 2015-04-16 00:00:00]</td>\n",
       "      <td>2</td>\n",
       "      <td>[7779]</td>\n",
       "      <td>[13382]</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>76561197960267615</td>\n",
       "      <td>[1428, 2098, 2545, 2643, 2633, 3052, 3150, 3979, 3979, 5255, 5797, 5747, 5884, 6832, 6500, 6956, 7122, 7102, 7352, 7469, 7931, 9757, 9911, 10291, 11006, 11309, 11432, 11736, 12754, 12703, 12755, 13323, 13215, 13544, 14085, 14055]</td>\n",
       "      <td>[True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True]</td>\n",
       "      <td>[2012-11-06 00:00:00, 2011-11-30 00:00:00, 2011-07-16 00:00:00, 2011-11-30 00:00:00, 2012-04-04 00:00:00, 2011-07-06 00:00:00, 2011-11-30 00:00:00, 2010-12-10 00:00:00, 2010-12-10 00:00:00, 2011-11-30 00:00:00, 2010-12-10 00:00:00, 2011-11-30 00:00:00, 2013-01-09 00:00:00, 2011-11-30 00:00:00, 2013-10-30 00:00:00, 2011-11-30 00:00:00, 2011-11-30 00:00:00, 2011-11-30 00:00:00, 2011-11-30 00:00:00, 2011-11-30 00:00:00, 2011-11-30 00:00:00, 2010-12-10 00:00:00, 2011-09-13 00:00:00, 2010-12-10 00:00:00, 2011-11-30 00:00:00, 2012-11-05 00:00:00, 2011-11-30 00:00:00, 2011-07-20 00:00:00, 2012-12-14 00:00:00, 2011-11-30 00:00:00, 2011-11-30 00:00:00, 2010-12-10 00:00:00, 2011-11-30 00:00:00, 2012-07-14 00:00:00, 2011-07-30 00:00:00, 2011-11-30 00:00:00]</td>\n",
       "      <td>3</td>\n",
       "      <td>[1428, 2098, 2545, 2643, 2633, 3052, 3150, 3979, 3979, 5255, 5797, 5747, 5884, 6832, 6500, 6956, 7122, 7102, 7352, 7469, 7931, 9757, 9911, 10291, 11006, 11309, 11432, 11736]</td>\n",
       "      <td>[12754, 12703, 12755, 13323, 13215, 13544, 14085, 14055]</td>\n",
       "      <td>[True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True]</td>\n",
       "      <td>[True, True, True, True, True, True, True, True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>76561197960268226</td>\n",
       "      <td>[9485, 13462]</td>\n",
       "      <td>[True, True]</td>\n",
       "      <td>[2015-06-01 00:00:00, 2016-11-28 00:00:00]</td>\n",
       "      <td>4</td>\n",
       "      <td>[9485]</td>\n",
       "      <td>[13462]</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[True]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             user_id  \\\n",
       "0  76561197960266546   \n",
       "1  76561197960266564   \n",
       "2  76561197960267022   \n",
       "3  76561197960267615   \n",
       "4  76561197960268226   \n",
       "\n",
       "                                                                                                                                                                                                                          product_id_int  \\\n",
       "0                                                                                                                                                                                                                           [2678, 2678]   \n",
       "1                                                                                                                                                                                                                           [7259, 7259]   \n",
       "2                                                                                                                                                                                                                          [7779, 13382]   \n",
       "3  [1428, 2098, 2545, 2643, 2633, 3052, 3150, 3979, 3979, 5255, 5797, 5747, 5884, 6832, 6500, 6956, 7122, 7102, 7352, 7469, 7931, 9757, 9911, 10291, 11006, 11309, 11432, 11736, 12754, 12703, 12755, 13323, 13215, 13544, 14085, 14055]   \n",
       "4                                                                                                                                                                                                                          [9485, 13462]   \n",
       "\n",
       "                                                                                                                                                                                                                recommended  \\\n",
       "0                                                                                                                                                                                                              [True, True]   \n",
       "1                                                                                                                                                                                                              [True, True]   \n",
       "2                                                                                                                                                                                                              [True, True]   \n",
       "3  [True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True]   \n",
       "4                                                                                                                                                                                                              [True, True]   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   date  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            [2016-11-25 00:00:00, 2016-11-25 00:00:00]   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            [2016-08-14 00:00:00, 2016-08-14 00:00:00]   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            [2015-09-29 00:00:00, 2015-04-16 00:00:00]   \n",
       "3  [2012-11-06 00:00:00, 2011-11-30 00:00:00, 2011-07-16 00:00:00, 2011-11-30 00:00:00, 2012-04-04 00:00:00, 2011-07-06 00:00:00, 2011-11-30 00:00:00, 2010-12-10 00:00:00, 2010-12-10 00:00:00, 2011-11-30 00:00:00, 2010-12-10 00:00:00, 2011-11-30 00:00:00, 2013-01-09 00:00:00, 2011-11-30 00:00:00, 2013-10-30 00:00:00, 2011-11-30 00:00:00, 2011-11-30 00:00:00, 2011-11-30 00:00:00, 2011-11-30 00:00:00, 2011-11-30 00:00:00, 2011-11-30 00:00:00, 2010-12-10 00:00:00, 2011-09-13 00:00:00, 2010-12-10 00:00:00, 2011-11-30 00:00:00, 2012-11-05 00:00:00, 2011-11-30 00:00:00, 2011-07-20 00:00:00, 2012-12-14 00:00:00, 2011-11-30 00:00:00, 2011-11-30 00:00:00, 2010-12-10 00:00:00, 2011-11-30 00:00:00, 2012-07-14 00:00:00, 2011-07-30 00:00:00, 2011-11-30 00:00:00]   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            [2015-06-01 00:00:00, 2016-11-28 00:00:00]   \n",
       "\n",
       "   user_id_int  \\\n",
       "0            0   \n",
       "1            1   \n",
       "2            2   \n",
       "3            3   \n",
       "4            4   \n",
       "\n",
       "                                                                                                                                                                 product_history  \\\n",
       "0                                                                                                                                                                         [2678]   \n",
       "1                                                                                                                                                                         [7259]   \n",
       "2                                                                                                                                                                         [7779]   \n",
       "3  [1428, 2098, 2545, 2643, 2633, 3052, 3150, 3979, 3979, 5255, 5797, 5747, 5884, 6832, 6500, 6956, 7122, 7102, 7352, 7469, 7931, 9757, 9911, 10291, 11006, 11309, 11432, 11736]   \n",
       "4                                                                                                                                                                         [9485]   \n",
       "\n",
       "                                             product_future  \\\n",
       "0                                                    [2678]   \n",
       "1                                                    [7259]   \n",
       "2                                                   [13382]   \n",
       "3  [12754, 12703, 12755, 13323, 13215, 13544, 14085, 14055]   \n",
       "4                                                   [13462]   \n",
       "\n",
       "                                                                                                                                                        recommended_history  \\\n",
       "0                                                                                                                                                                    [True]   \n",
       "1                                                                                                                                                                    [True]   \n",
       "2                                                                                                                                                                    [True]   \n",
       "3  [True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True]   \n",
       "4                                                                                                                                                                    [True]   \n",
       "\n",
       "                                 recommended_future  \n",
       "0                                            [True]  \n",
       "1                                            [True]  \n",
       "2                                            [True]  \n",
       "3  [True, True, True, True, True, True, True, True]  \n",
       "4                                            [True]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "def split(items, train_percentage):\n",
    "    train_count = math.floor(len(items) * train_percentage)\n",
    "    return items[0:train_count], items[train_count:]\n",
    "\n",
    "train_percentage = 0.8\n",
    "steam_reviews_df_grouped_smaller[\"product_history\"] = steam_reviews_df_grouped_smaller[\"product_id_int\"].progress_apply(lambda items: split(items, train_percentage)[0])\n",
    "steam_reviews_df_grouped_smaller[\"product_future\"] = steam_reviews_df_grouped_smaller[\"product_id_int\"].progress_apply(lambda items: split(items, train_percentage)[1])\n",
    "steam_reviews_df_grouped_smaller[\"recommended_history\"] = steam_reviews_df_grouped_smaller[\"recommended\"].progress_apply(lambda items: split(items, train_percentage)[0])\n",
    "steam_reviews_df_grouped_smaller[\"recommended_future\"] = steam_reviews_df_grouped_smaller[\"recommended\"].progress_apply(lambda items: split(items, train_percentage)[1])\n",
    "display(steam_reviews_df_grouped_smaller.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2271955"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steam_reviews_df_grouped_smaller[\"recommended\"].map(len).describe()\n",
    "steam_reviews_df_grouped_smaller[\"recommended\"].map(len).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#Create scipy csr matrix\n",
    "def get_sparse_matrix(df, shape, recommended_col=\"recommended_history\", product_col=\"product_history\"):\n",
    "    user_ids = []\n",
    "    product_ids = []\n",
    "    values = []\n",
    "    for _, row in df.iterrows():\n",
    "        products = row[product_col]\n",
    "        user = row['user_id_int']\n",
    "    \n",
    "        recommended = row[recommended_col]\n",
    "        user_ids.extend([user] * len(products))\n",
    "        product_ids.extend(products)\n",
    "        values.extend([2 if recommended[i] else 1 for i in range(len(products))])\n",
    "    #create csr matrix\n",
    "    # values = np.ones(len(user_ids))\n",
    "    matrix = scipy.sparse.csr_matrix((values, (user_ids, product_ids)), shape=shape, dtype=np.int32)\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "steam_reviews_set = steam_reviews_df_grouped_smaller#.head(100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<581343x14513 sparse matrix of type '<class 'numpy.intc'>'\n",
       "\twith 1404885 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape = (steam_reviews_set.shape[0], steam_reviews_df_cleaned['product_id_int'].max() + 1)\n",
    "\n",
    "steam_reviews_set = steam_reviews_set.reset_index()\n",
    "train_matrix = get_sparse_matrix(steam_reviews_set, shape)\n",
    "test_matrix = get_sparse_matrix(steam_reviews_set, shape, recommended_col=\"recommended_future\", product_col=\"product_future\")\n",
    "train_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<581343x14513 sparse matrix of type '<class 'numpy.intc'>'\n",
       "\twith 708285 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model RBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------\n",
      "start training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [24:20<00:00, 146.01s/it]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def score_model(rbm, batch_size):\n",
    "    test_recon_error = 0  # RMSE reconstruction error initialized to 0 at the beginning of training\n",
    "    s = 0  # a counter (float type) \n",
    "    # for loop - go through every single user\n",
    "    for id_user in range(0, user_reviews_df_exploded['user_id_int'].max() + 1 - batch_size, batch_size):\n",
    "        v = train_matrix[id_user:id_user + batch_size]  # training set inputs are used to activate neurons of my RBM\n",
    "        vt = test_matrix[id_user:id_user + batch_size]  # target\n",
    "        # v = convert_sparse_matrix_to_sparse_tensor(training_sample)\n",
    "        # vt = convert_sparse_matrix_to_sparse_tensor(training_sample2)\n",
    "        v = v.todense()\n",
    "        vt = vt.todense()\n",
    "\n",
    "        # v = v.to_dense()\n",
    "        # vt = vt.to_dense()\n",
    "        v = v - 1\n",
    "        vt = vt - 1\n",
    "        v = torch.Tensor(v)\n",
    "        vt = torch.Tensor(vt)\n",
    "        if torch.cuda.is_available():\n",
    "            v = v.cuda()\n",
    "            vt = vt.cuda()\n",
    "        if len(vt[vt > -1]) > 0:\n",
    "            _, h = rbm.sample_h(v)\n",
    "            v, _ = rbm.sample_v(h)\n",
    "\n",
    "            # Update test RMSE reconstruction error\n",
    "            test_recon_error += torch.sqrt(torch.mean((vt[vt > -1] - v[vt > -1])**2)) * len(vt > -1)\n",
    "            s += len(vt > -1) \n",
    "\n",
    "    return test_recon_error / s\n",
    "\n",
    "print('-------')\n",
    "n_vis = shape[1]\n",
    "n_hidden = 2000\n",
    "batch_size = 2048 \n",
    "epochs = 10\n",
    "train_errors = []\n",
    "test_errors = []\n",
    "rbm = RBM(n_vis, n_hidden)\n",
    "\n",
    "# https://stackoverflow.com/questions/40896157/scipy-sparse-csr-matrix-to-tensorflow-sparsetensor-mini-batch-gradient-descent\n",
    "def convert_sparse_matrix_to_sparse_tensor(X):\n",
    "    coo = X.tocoo()\n",
    "\n",
    "    values = coo.data\n",
    "    indices = np.vstack((coo.row, coo.col))\n",
    "\n",
    "    i = torch.LongTensor(indices)\n",
    "    v = torch.FloatTensor(values)\n",
    "    if torch.cuda.is_available():\n",
    "        i = i.cuda()\n",
    "        v = v.cuda()\n",
    "    # print(values)\n",
    "    # print(\"values\", v)\n",
    "    shape = coo.shape\n",
    "    tensor = torch.sparse.FloatTensor(i, v, torch.Size(shape)) \n",
    "    if torch.cuda.is_available():\n",
    "        tensor = tensor.cuda()\n",
    "\n",
    "    return tensor \n",
    "\n",
    "print(\"start training\")\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    rbm.train()\n",
    "    train_recon_error = 0  # RMSE reconstruction error initialized to 0 at the beginning of training\n",
    "    s = 0\n",
    "    \n",
    "    for user_id in range(0, shape[0] - batch_size, batch_size):\n",
    "        training_sample = train_matrix[user_id : user_id + batch_size]\n",
    "        training_sample2 = train_matrix[user_id : user_id + batch_size]\n",
    "        # print(training_sample)\n",
    "        v0 = convert_sparse_matrix_to_sparse_tensor(training_sample)\n",
    "        # print(v0.coalesce().indices())\n",
    "        vk = convert_sparse_matrix_to_sparse_tensor(training_sample2)\n",
    "\n",
    "        v0 = v0.to_dense()\n",
    "        vk = vk.to_dense()\n",
    "        v0 = v0.sub(1)\n",
    "        vk = vk.sub(1)\n",
    "        \n",
    "        ph0, _ = rbm.sample_h(v0)   \n",
    "\n",
    "        # Third for loop - perform contrastive divergence\n",
    "        for k in range(5):\n",
    "            _, hk = rbm.sample_h(vk)\n",
    "            _, vk = rbm.sample_v(hk)\n",
    "\n",
    "            # We don't want to learn when there is no rating by the user, and there is no update when rating = -1\n",
    "            # Remove indices from vk vector that are not in the v0 vector => get sparse tensor again\n",
    "            vk[v0 < 0] = v0[v0 < 0]\n",
    "\n",
    "        phk, _ = rbm.sample_h(vk)\n",
    "        rbm.train_model(v0, vk, ph0, phk)\n",
    "\n",
    "        vk_train, _ = rbm.sample_v(hk)\n",
    "        train_recon_error += torch.sqrt(torch.mean((v0[v0 > -1] - vk_train[v0 > -1])**2)) * len(v0 > -1)\n",
    "        s += len(v0 > -1) \n",
    "        \n",
    "    train_errors.append(train_recon_error / s)\n",
    "\n",
    "    # print('calculating test scores')\n",
    "    # rbm.eval()\n",
    "    # test_errors.append(score_model(rbm)) \n",
    "    rbm.eval()\n",
    "    test_errors.append(score_model(rbm, batch_size))\n",
    "\n",
    "    # print('finished epoch', epoch)    \n",
    "    \n",
    "import matplotlib.pyplot as plt\n",
    "# Plot the RMSE reconstruction error with respect to increasing number of epochs\n",
    "plt.plot(torch.Tensor(train_errors, device='cpu'), label=\"train\")\n",
    "plt.plot(torch.Tensor(test_errors, device='cpu'), label=\"test\")\n",
    "plt.ylabel('Error')\n",
    "plt.xlabel('Epoch')\n",
    "plt.savefig(f'datasubset-{n_hidden}-{batch_size}-{epochs}-test.jpg')\n",
    "\n",
    "# Evaluate the RBM on test set\n",
    "# test_recon_error = score_model(rbm)\n",
    "# print(\"Final error\", test_recon_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jolan\\AppData\\Local\\Temp/ipykernel_6996/1445240602.py:28: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  recommendations = torch.tensor(indices, device='cpu').tolist()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hr 0.0006022403340426386\n",
      "recall 0.0006022403340426386\n"
     ]
    }
   ],
   "source": [
    "hr, r = compute_hr(rbm)\n",
    "print('hr', np.average(hr))\n",
    "print(\"recall\", np.average(r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(0.7204, device='cuda:0'),\n",
       " tensor(0.6915, device='cuda:0'),\n",
       " tensor(0.6858, device='cuda:0'),\n",
       " tensor(0.6830, device='cuda:0'),\n",
       " tensor(0.6813, device='cuda:0'),\n",
       " tensor(0.6801, device='cuda:0'),\n",
       " tensor(0.6792, device='cuda:0'),\n",
       " tensor(0.6786, device='cuda:0'),\n",
       " tensor(0.6781, device='cuda:0'),\n",
       " tensor(0.6777, device='cuda:0'),\n",
       " tensor(0.6773, device='cuda:0'),\n",
       " tensor(0.6770, device='cuda:0'),\n",
       " tensor(0.6768, device='cuda:0'),\n",
       " tensor(0.6765, device='cuda:0'),\n",
       " tensor(0.6764, device='cuda:0'),\n",
       " tensor(0.6762, device='cuda:0'),\n",
       " tensor(0.6760, device='cuda:0'),\n",
       " tensor(0.6759, device='cuda:0'),\n",
       " tensor(0.6758, device='cuda:0'),\n",
       " tensor(0.6757, device='cuda:0'),\n",
       " tensor(0.6756, device='cuda:0'),\n",
       " tensor(0.6755, device='cuda:0'),\n",
       " tensor(0.6754, device='cuda:0'),\n",
       " tensor(0.6753, device='cuda:0'),\n",
       " tensor(0.6753, device='cuda:0'),\n",
       " tensor(0.6752, device='cuda:0'),\n",
       " tensor(0.6751, device='cuda:0'),\n",
       " tensor(0.6751, device='cuda:0'),\n",
       " tensor(0.6750, device='cuda:0'),\n",
       " tensor(0.6750, device='cuda:0'),\n",
       " tensor(0.6749, device='cuda:0'),\n",
       " tensor(0.6749, device='cuda:0'),\n",
       " tensor(0.6748, device='cuda:0'),\n",
       " tensor(0.6748, device='cuda:0'),\n",
       " tensor(0.6748, device='cuda:0'),\n",
       " tensor(0.6747, device='cuda:0'),\n",
       " tensor(0.6747, device='cuda:0'),\n",
       " tensor(0.6747, device='cuda:0'),\n",
       " tensor(0.6746, device='cuda:0'),\n",
       " tensor(0.6746, device='cuda:0'),\n",
       " tensor(0.6746, device='cuda:0'),\n",
       " tensor(0.6746, device='cuda:0'),\n",
       " tensor(0.6745, device='cuda:0'),\n",
       " tensor(0.6745, device='cuda:0'),\n",
       " tensor(0.6745, device='cuda:0'),\n",
       " tensor(0.6745, device='cuda:0'),\n",
       " tensor(0.6745, device='cuda:0'),\n",
       " tensor(0.6744, device='cuda:0'),\n",
       " tensor(0.6744, device='cuda:0'),\n",
       " tensor(0.6744, device='cuda:0')]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[tensor(0.4664, device='cuda:0'),\n",
       " tensor(0.4493, device='cuda:0'),\n",
       " tensor(0.4414, device='cuda:0'),\n",
       " tensor(0.4365, device='cuda:0'),\n",
       " tensor(0.4331, device='cuda:0'),\n",
       " tensor(0.4305, device='cuda:0'),\n",
       " tensor(0.4285, device='cuda:0'),\n",
       " tensor(0.4268, device='cuda:0'),\n",
       " tensor(0.4255, device='cuda:0'),\n",
       " tensor(0.4243, device='cuda:0'),\n",
       " tensor(0.4234, device='cuda:0'),\n",
       " tensor(0.4225, device='cuda:0'),\n",
       " tensor(0.4218, device='cuda:0'),\n",
       " tensor(0.4211, device='cuda:0'),\n",
       " tensor(0.4205, device='cuda:0'),\n",
       " tensor(0.4200, device='cuda:0'),\n",
       " tensor(0.4195, device='cuda:0'),\n",
       " tensor(0.4190, device='cuda:0'),\n",
       " tensor(0.4186, device='cuda:0'),\n",
       " tensor(0.4182, device='cuda:0'),\n",
       " tensor(0.4179, device='cuda:0'),\n",
       " tensor(0.4176, device='cuda:0'),\n",
       " tensor(0.4173, device='cuda:0'),\n",
       " tensor(0.4170, device='cuda:0'),\n",
       " tensor(0.4168, device='cuda:0'),\n",
       " tensor(0.4165, device='cuda:0'),\n",
       " tensor(0.4163, device='cuda:0'),\n",
       " tensor(0.4161, device='cuda:0'),\n",
       " tensor(0.4159, device='cuda:0'),\n",
       " tensor(0.4157, device='cuda:0'),\n",
       " tensor(0.4155, device='cuda:0'),\n",
       " tensor(0.4154, device='cuda:0'),\n",
       " tensor(0.4152, device='cuda:0'),\n",
       " tensor(0.4150, device='cuda:0'),\n",
       " tensor(0.4149, device='cuda:0'),\n",
       " tensor(0.4148, device='cuda:0'),\n",
       " tensor(0.4146, device='cuda:0'),\n",
       " tensor(0.4145, device='cuda:0'),\n",
       " tensor(0.4144, device='cuda:0'),\n",
       " tensor(0.4143, device='cuda:0'),\n",
       " tensor(0.4142, device='cuda:0'),\n",
       " tensor(0.4141, device='cuda:0'),\n",
       " tensor(0.4140, device='cuda:0'),\n",
       " tensor(0.4139, device='cuda:0'),\n",
       " tensor(0.4138, device='cuda:0'),\n",
       " tensor(0.4137, device='cuda:0'),\n",
       " tensor(0.4136, device='cuda:0'),\n",
       " tensor(0.4135, device='cuda:0'),\n",
       " tensor(0.4135, device='cuda:0'),\n",
       " tensor(0.4134, device='cuda:0')]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(train_errors)\n",
    "display(test_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76561198037833890    1\n",
       "76561197992194309    1\n",
       "76561198043292775    1\n",
       "76561198030442121    1\n",
       "76561197963870074    1\n",
       "                    ..\n",
       "76561198345086561    1\n",
       "76561198054491833    1\n",
       "76561198095690287    1\n",
       "76561198301658414    1\n",
       "76561198089897928    1\n",
       "Name: user_id, Length: 904268, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "76561198011965365    1254\n",
       "76561198094803808     900\n",
       "76561197969749884     750\n",
       "76561198094321628     669\n",
       "76561198073092169     549\n",
       "                     ... \n",
       "76561198098554655       2\n",
       "76561198044342349       2\n",
       "76561198122784122       2\n",
       "76561198076341138       2\n",
       "76561198102545130       2\n",
       "Name: user_id, Length: 581343, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "76561198011965365    1254\n",
       "76561198094803808     900\n",
       "76561197969749884     750\n",
       "76561198094321628     669\n",
       "76561198073092169     549\n",
       "                     ... \n",
       "76561198345086561       1\n",
       "76561198054491833       1\n",
       "76561198095690287       1\n",
       "76561198301658414       1\n",
       "76561198089897928       1\n",
       "Name: user_id, Length: 1485611, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "s = steam_reviews_df_small[\"user_id\"].value_counts(dropna=False)\n",
    "display(s.loc[s < 2])\n",
    "display(s.loc[s >= 2])\n",
    "display(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(0.4664, device='cuda:0'),\n",
       " tensor(0.4493, device='cuda:0'),\n",
       " tensor(0.4414, device='cuda:0'),\n",
       " tensor(0.4365, device='cuda:0'),\n",
       " tensor(0.4331, device='cuda:0'),\n",
       " tensor(0.4305, device='cuda:0'),\n",
       " tensor(0.4285, device='cuda:0'),\n",
       " tensor(0.4268, device='cuda:0'),\n",
       " tensor(0.4255, device='cuda:0'),\n",
       " tensor(0.4243, device='cuda:0'),\n",
       " tensor(0.4234, device='cuda:0'),\n",
       " tensor(0.4225, device='cuda:0'),\n",
       " tensor(0.4218, device='cuda:0'),\n",
       " tensor(0.4211, device='cuda:0'),\n",
       " tensor(0.4205, device='cuda:0'),\n",
       " tensor(0.4200, device='cuda:0'),\n",
       " tensor(0.4195, device='cuda:0'),\n",
       " tensor(0.4190, device='cuda:0'),\n",
       " tensor(0.4186, device='cuda:0'),\n",
       " tensor(0.4182, device='cuda:0'),\n",
       " tensor(0.4179, device='cuda:0'),\n",
       " tensor(0.4176, device='cuda:0'),\n",
       " tensor(0.4173, device='cuda:0'),\n",
       " tensor(0.4170, device='cuda:0'),\n",
       " tensor(0.4168, device='cuda:0'),\n",
       " tensor(0.4165, device='cuda:0'),\n",
       " tensor(0.4163, device='cuda:0'),\n",
       " tensor(0.4161, device='cuda:0'),\n",
       " tensor(0.4159, device='cuda:0'),\n",
       " tensor(0.4157, device='cuda:0'),\n",
       " tensor(0.4155, device='cuda:0'),\n",
       " tensor(0.4154, device='cuda:0'),\n",
       " tensor(0.4152, device='cuda:0'),\n",
       " tensor(0.4150, device='cuda:0'),\n",
       " tensor(0.4149, device='cuda:0'),\n",
       " tensor(0.4148, device='cuda:0'),\n",
       " tensor(0.4146, device='cuda:0'),\n",
       " tensor(0.4145, device='cuda:0'),\n",
       " tensor(0.4144, device='cuda:0'),\n",
       " tensor(0.4143, device='cuda:0'),\n",
       " tensor(0.4142, device='cuda:0'),\n",
       " tensor(0.4141, device='cuda:0'),\n",
       " tensor(0.4140, device='cuda:0'),\n",
       " tensor(0.4139, device='cuda:0'),\n",
       " tensor(0.4138, device='cuda:0'),\n",
       " tensor(0.4137, device='cuda:0'),\n",
       " tensor(0.4136, device='cuda:0'),\n",
       " tensor(0.4135, device='cuda:0'),\n",
       " tensor(0.4135, device='cuda:0'),\n",
       " tensor(0.4134, device='cuda:0')]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ac59ebe37160ed0dfa835113d9b8498d9f09ceb179beaac4002f036b9467c963"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

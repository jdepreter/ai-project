{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Restricted Boltzmann Machine Defintion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Import PyTorch library\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "device = torch.device('cpu')\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# https://github.com/khanhnamle1994/MetaRec/blob/b5e36cb579a88b32cdfb728f35f645d76b24ad95/Boltzmann-Machines-Experiments/RBM-CF-PyTorch/rbm.py#L23\n",
    "# Create the Restricted Boltzmann Machine architecture\n",
    "class RBM(nn.Module):\n",
    "    def __init__(self, n_vis, n_hid):\n",
    "        \"\"\"\n",
    "        Initialize the parameters (weights and biases) we optimize during the training process\n",
    "        :param n_vis: number of visible units\n",
    "        :param n_hid: number of hidden units\n",
    "        \"\"\"\n",
    "        self.i = 0\n",
    "\n",
    "        # Weights used for the probability of the visible units given the hidden units\n",
    "        super().__init__()\n",
    "        self.W = torch.randn(n_hid, n_vis, device=device)  # torch.rand: random normal distribution mean = 0, variance = 1\n",
    "\n",
    "        # Bias probability of the visible units is activated, given the value of the hidden units (p_v_given_h)\n",
    "        self.v_bias = torch.randn(1, n_vis, device=device)  # fake dimension for the batch = 1\n",
    "\n",
    "        # Bias probability of the hidden units is activated, given the value of the visible units (p_h_given_v)\n",
    "        self.h_bias = torch.randn(1, n_hid, device=device)  # fake dimension for the batch = 1\n",
    "    \n",
    "    def lr():\n",
    "        return 0.02\n",
    "\n",
    "    def sample_h(self, x):\n",
    "        \"\"\"\n",
    "        Sample the hidden units\n",
    "        :param x: the dataset\n",
    "        \"\"\"\n",
    "\n",
    "        # Probability h is activated given that the value v is sigmoid(Wx + a)\n",
    "        # torch.mm make the product of 2 tensors\n",
    "        # W.t() take the transpose because W is used for the p_v_given_h\n",
    "        wx = torch.mm(x, self.W.t())\n",
    "        # print(wx.shape)\n",
    "\n",
    "        # Expand the mini-batch\n",
    "        activation = wx + self.h_bias.expand_as(wx)\n",
    "        # print(activation.shape)\n",
    "\n",
    "        # Calculate the probability p_h_given_v\n",
    "        p_h_given_v = torch.sigmoid(activation)\n",
    "\n",
    "        # print(\"h sparse\", p_h_given_v.is_sparse, torch.bernoulli(p_h_given_v).is_sparse)\n",
    "\n",
    "        # Construct a Bernoulli RBM to predict whether an user loves the movie or not (0 or 1)\n",
    "        # This corresponds to whether the n_hid is activated or not activated\n",
    "        return p_h_given_v, torch.bernoulli(p_h_given_v)\n",
    "\n",
    "    def sample_v(self, y):\n",
    "        \"\"\"\n",
    "        Sample the visible units\n",
    "        :param y: the dataset\n",
    "        \"\"\"\n",
    "\n",
    "        # Probability v is activated given that the value h is sigmoid(Wx + a)\n",
    "        wy = torch.mm(y, self.W)\n",
    "\n",
    "        # Expand the mini-batch\n",
    "        activation = wy + self.v_bias.expand_as(wy)\n",
    "\n",
    "        # Calculate the probability p_v_given_h\n",
    "        p_v_given_h = torch.sigmoid(activation)\n",
    "\n",
    "        # print(\"v sparse\", p_v_given_h.is_sparse, torch.bernoulli(p_v_given_h).is_sparse)\n",
    "\n",
    "        # Construct a Bernoulli RBM to predict whether an user loves the movie or not (0 or 1)\n",
    "        # This corresponds to whether the n_vis is activated or not activated\n",
    "        return p_v_given_h, torch.bernoulli(p_v_given_h)\n",
    "\n",
    "    def train_model(self, v0, vk, ph0, phk):\n",
    "        \"\"\"\n",
    "        Perform contrastive divergence algorithm to optimize the weights that minimize the energy\n",
    "        This maximizes the log-likelihood of the model\n",
    "        \"\"\"\n",
    "\n",
    "        w_extra = (torch.mm(v0.t(), ph0) - torch.mm(vk.t(), phk)).t()\n",
    "        v_extra = torch.sum((v0 - vk), 0)\n",
    "        h_extra = torch.sum((ph0 - phk), 0)\n",
    "\n",
    "        if self.i % 45 == 0:\n",
    "            print(torch.max(w_extra), torch.max(v_extra), torch.max(h_extra), flush=True)\n",
    "\n",
    "        # Approximate the gradients with the CD algorithm\n",
    "        # TODO learning rate toevoegen\n",
    "        self.W += w_extra\n",
    "\n",
    "        # Add (difference, 0) for the tensor of 2 dimensions\n",
    "        self.v_bias += v_extra\n",
    "        self.h_bias += h_extra\n",
    "        self.i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "cuda = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "import gzip\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "import math\n",
    "tqdm.pandas() #for progres_apply etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "#read file line-by-line and parse json, returns dataframe\n",
    "def parse_json(filename_gzipped_python_json, read_max=-1):\n",
    "  #read gzipped content\n",
    "  f=gzip.open(filename_gzipped_python_json,'r')\n",
    "  \n",
    "  #parse json\n",
    "  parse_data = []\n",
    "  for line in tqdm(f): #tqdm is for showing progress bar, always good when processing large amounts of data\n",
    "    line = line.decode('utf-8')\n",
    "    line = line.replace('true','True') #difference json/python\n",
    "    line = line.replace('false','False')\n",
    "    parsed_result = eval(line) #load python nested datastructure\n",
    "    # print(filename_gzipped_python_json == steam_path + steam_reviews and 'user_id' not in parsed_result)\n",
    "    # break\n",
    "    if filename_gzipped_python_json == steam_path + steam_reviews and 'user_id' not in parsed_result:\n",
    "      continue\n",
    "      \n",
    "    parse_data.append(parsed_result)\n",
    "    if read_max !=-1 and len(parse_data) > read_max:\n",
    "      print(f'Break reading after {read_max} records')\n",
    "      break\n",
    "  print(f\"Reading {len(parse_data)} rows.\")\n",
    "\n",
    "  #create dataframe\n",
    "  df= pd.DataFrame.from_dict(parse_data)\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "steam_path = './data/'\n",
    "metadata_games = 'steam_games.json.gz' \n",
    "user_items = 'australian_users_items.json.gz'\n",
    "user_reviews = 'australian_user_reviews.json.gz'\n",
    "game_bundles = 'bundle_data.json.gz'\n",
    "steam_reviews= 'steam_reviews.json.gz'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Australien Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r0it [00:00, ?it/s]\n",
      "\r615it [00:00, 6105.65it/s]\n",
      "\r1324it [00:00, 6358.48it/s]\n",
      "\r1723it [00:00, 5381.36it/s]\n",
      "\r2542it [00:00, 5988.90it/s]\n",
      "\r3152it [00:00, 6008.81it/s]\n",
      "\r3702it [00:00, 5832.94it/s]\n",
      "\r4286it [00:00, 5822.32it/s]\n",
      "\r5087it [00:00, 6330.96it/s]\n",
      "\r5953it [00:00, 6874.62it/s]\n",
      "\r6646it [00:01, 6639.58it/s]\n",
      "\r7454it [00:01, 7001.43it/s]\n",
      "\r8365it [00:01, 7510.28it/s]\n",
      "\r9194it [00:01, 7712.56it/s]\n",
      "\r9979it [00:01, 7107.76it/s]\n",
      "\r10770it [00:01, 7315.96it/s]\n",
      "\r11756it [00:01, 7915.76it/s]\n",
      "\r12697it [00:01, 8295.71it/s]\n",
      "\r13549it [00:01, 7608.10it/s]\n",
      "\r14337it [00:01, 7561.16it/s]\n",
      "\r15112it [00:02, 7042.42it/s]\n",
      "\r15837it [00:02, 6733.59it/s]\n",
      "\r16640it [00:02, 7062.71it/s]\n",
      "\r17504it [00:02, 7457.80it/s]\n",
      "\r18267it [00:02, 6793.85it/s]\n",
      "\r19103it [00:02, 7147.69it/s]\n",
      "\r20118it [00:02, 7830.86it/s]\n",
      "\r21159it [00:02, 8444.60it/s]\n",
      "\r22383it [00:02, 9294.55it/s]\n",
      "\r23621it [00:03, 10027.82it/s]\n",
      "\r24839it [00:03, 10569.06it/s]\n",
      "\r25799it [00:03, 7876.90it/s] \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- australian_user_reviews.json.gz-----\n",
      "Size of file is 6.940139MB\n",
      "Reading 25799 rows.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# for dataset in [metadata_games, user_items, user_reviews, game_bundles, steam_reviews]:\n",
    "for dataset in [user_reviews]:\n",
    "  print(f\"----- {dataset}-----\")\n",
    "  size = os.path.getsize(steam_path + dataset) \n",
    "  print(f'Size of file is {size / 1000000}MB')\n",
    "  df_metadata = parse_json(steam_path + dataset)\n",
    "  pd.set_option('display.max_colwidth', None)\n",
    "  # display(df_metadata.head(5))\n",
    "#   display(df_metadata.describe(include='all'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r0it [00:00, ?it/s]\n",
      "\r641it [00:00, 6361.37it/s]\n",
      "\r1341it [00:00, 6527.56it/s]\n",
      "\r2091it [00:00, 6778.35it/s]\n",
      "\r2895it [00:00, 7099.46it/s]\n",
      "\r3710it [00:00, 7370.40it/s]\n",
      "\r4348it [00:00, 6225.48it/s]\n",
      "\r4932it [00:00, 5783.85it/s]\n",
      "\r5767it [00:00, 6360.52it/s]\n",
      "\r6503it [00:00, 6617.68it/s]\n",
      "\r7170it [00:01, 5704.32it/s]\n",
      "\r8036it [00:01, 6344.58it/s]\n",
      "\r8711it [00:01, 5235.69it/s]\n",
      "\r9296it [00:01, 4696.19it/s]\n",
      "\r9819it [00:01, 4713.91it/s]\n",
      "\r10334it [00:01, 4826.82it/s]\n",
      "\r11040it [00:01, 5324.10it/s]\n",
      "\r11786it [00:01, 5814.43it/s]\n",
      "\r12405it [00:02, 4153.61it/s]\n",
      "\r13195it [00:02, 4836.08it/s]\n",
      "\r13957it [00:02, 5411.37it/s]\n",
      "\r14682it [00:02, 5846.63it/s]\n",
      "\r15345it [00:02, 5904.29it/s]\n",
      "\r16215it [00:02, 6523.48it/s]\n",
      "\r17208it [00:02, 7260.20it/s]\n",
      "\r18303it [00:02, 8063.67it/s]\n",
      "\r19529it [00:03, 8971.36it/s]\n",
      "\r20596it [00:03, 9403.90it/s]\n",
      "\r21602it [00:03, 9517.39it/s]\n",
      "\r22615it [00:03, 9672.95it/s]\n",
      "\r23802it [00:03, 10222.17it/s]\n",
      "\r24856it [00:03, 9725.23it/s] \n",
      "\r25799it [00:03, 7025.12it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 25799 rows.\n"
     ]
    }
   ],
   "source": [
    "user_reviews_df = parse_json(steam_path + user_reviews)\n",
    "user_reviews_df = user_reviews_df.drop_duplicates(subset='user_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "user_reviews_df_exploded = user_reviews_df.explode('reviews')\n",
    "user_reviews_df_exploded = user_reviews_df_exploded.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def func(x):\n",
    "    return x['recommend'], x[\"item_id\"]\n",
    "\n",
    "user_reviews_df_exploded['recommended'], user_reviews_df_exploded[\"item_id\"] = zip(\n",
    "    *user_reviews_df_exploded['reviews'].map(func)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "user_reviews_df_exploded.reset_index()\n",
    "\n",
    "\n",
    "user_reviews_df_exploded = user_reviews_df_exploded[['user_id', 'item_id', 'recommended']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24                         [False, True]\n",
       "26       [True, True, True, False, True]\n",
       "36                         [True, False]\n",
       "60             [False, True, True, True]\n",
       "71                         [False, True]\n",
       "                      ...               \n",
       "25758    [True, True, True, False, True]\n",
       "25761                      [False, True]\n",
       "25764                [True, True, False]\n",
       "25768    [True, True, False, True, True]\n",
       "25785                [True, True, False]\n",
       "Length: 3684, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enkeltrue = user_reviews_df[['reviews']].apply(lambda x: [elem['recommend'] for elem in x['reviews']], axis=1)\n",
    "enkeltrue.loc[enkeltrue.map(set).map(len) > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  0%|          | 0/58430 [00:00<?, ?it/s]\n",
      "\r 58%|█████▊    | 34063/58430 [00:00<00:00, 338152.81it/s]\n",
      "\r100%|██████████| 58430/58430 [00:00<00:00, 255838.88it/s]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dct = {}\n",
    "def map_to_consecutive_id(uuid):\n",
    "  if uuid in dct:\n",
    "    return dct[uuid]\n",
    "  else:\n",
    "    id = len(dct)\n",
    "    dct[uuid] = id\n",
    "    return id\n",
    "user_reviews_df_exploded['item_id_int'] = user_reviews_df_exploded['item_id'].progress_apply(map_to_consecutive_id)\n",
    "user_reviews_df_exploded.dtypes\n",
    "f = open(\"item_dct.json\", 'w')\n",
    "json.dump(dct, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  0%|          | 0/58430 [00:00<?, ?it/s]\n",
      "\r 63%|██████▎   | 36540/58430 [00:00<00:00, 362305.34it/s]\n",
      "\r100%|██████████| 58430/58430 [00:00<00:00, 325228.73it/s]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dct = {}\n",
    "user_reviews_df_exploded['user_id_int'] = user_reviews_df_exploded['user_id'].progress_apply(map_to_consecutive_id)\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_df, test_df = train_test_split(user_reviews_df_exploded, test_size=0.2)\n",
    "\n",
    "\n",
    "test_df_grouped = test_df.groupby('user_id_int').agg(list)\n",
    "test_df_grouped = test_df_grouped.reset_index()\n",
    "\n",
    "train_df_grouped = train_df.groupby('user_id_int').agg(list)\n",
    "train_df_grouped = train_df_grouped.reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "#Create scipy csr matrix\n",
    "def get_sparse_matrix(df):\n",
    "    shape = (user_reviews_df_exploded['user_id_int'].max() + 1, user_reviews_df_exploded['item_id_int'].max() + 1)\n",
    "    \n",
    "    user_ids = []\n",
    "    item_ids = []\n",
    "    values = []\n",
    "    for idx, row in df.iterrows():\n",
    "        items = row['item_id_int']\n",
    "        user = row['user_id_int']\n",
    "    \n",
    "        recommended = row['recommended']\n",
    "        user_ids.extend([user] * len(items))\n",
    "        item_ids.extend(items)\n",
    "        values.extend([2 if recommended[i] else 1 for i in range(len(items))])\n",
    "    #create csr matrix\n",
    "    # values = np.ones(len(user_ids))\n",
    "    matrix = scipy.sparse.csr_matrix((values, (user_ids, item_ids)), shape=shape, dtype=np.int32)\n",
    "    return matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<25457x3682 sparse matrix of type '<class 'numpy.intc'>'\n",
       "\twith 46744 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_matrix = get_sparse_matrix(test_df_grouped)\n",
    "\n",
    "train_matrix = get_sparse_matrix(train_df_grouped)\n",
    "train_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'user_reviews_df_exploded' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2604/989217197.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'-------'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m \u001b[0mn_vis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0muser_reviews_df_exploded\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'item_id_int'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m \u001b[0mn_hidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1024\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m128\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'user_reviews_df_exploded' is not defined"
     ]
    }
   ],
   "source": [
    "def score_model(rbm):\n",
    "    test_recon_error = 0  # RMSE reconstruction error initialized to 0 at the beginning of training\n",
    "    s = 0  # a counter (float type) \n",
    "    # for loop - go through every single user\n",
    "    for id_user in range(user_reviews_df_exploded['user_id_int'].max() + 1):\n",
    "        v = train_matrix[id_user:id_user + 1]  # training set inputs are used to activate neurons of my RBM\n",
    "        vt = test_matrix[id_user:id_user + 1]  # target\n",
    "        # v = convert_sparse_matrix_to_sparse_tensor(training_sample)\n",
    "        # vt = convert_sparse_matrix_to_sparse_tensor(training_sample2)\n",
    "        v = v.todense()\n",
    "        vt = vt.todense()\n",
    "\n",
    "        # v = v.to_dense()\n",
    "        # vt = vt.to_dense()\n",
    "        v = v - 1\n",
    "        vt = vt - 1\n",
    "        v = torch.Tensor(v)\n",
    "        vt = torch.Tensor(vt)\n",
    "        if torch.cuda.is_available():\n",
    "            v = v.cuda()\n",
    "            vt = vt.cuda()\n",
    "        if len(vt[vt > -1]) > 0:\n",
    "            _, h = rbm.sample_h(v)\n",
    "            _, v = rbm.sample_v(h)\n",
    "\n",
    "            # Update test RMSE reconstruction error\n",
    "            test_recon_error += torch.sqrt(torch.mean((vt[vt > -1] - v[vt > -1])**2))\n",
    "            s += 1\n",
    "\n",
    "    return test_recon_error / s\n",
    "\n",
    "print('-------')\n",
    "n_vis = user_reviews_df_exploded['item_id_int'].max() + 1\n",
    "n_hidden = 1024\n",
    "batch_size = 128\n",
    "train_errors = []\n",
    "test_errors = []\n",
    "rbm = RBM(n_vis, n_hidden)\n",
    "\n",
    "# https://stackoverflow.com/questions/40896157/scipy-sparse-csr-matrix-to-tensorflow-sparsetensor-mini-batch-gradient-descent\n",
    "def convert_sparse_matrix_to_sparse_tensor(X):\n",
    "    coo = X.tocoo()\n",
    "\n",
    "    values = coo.data\n",
    "    indices = np.vstack((coo.row, coo.col))\n",
    "\n",
    "    i = torch.LongTensor(indices)\n",
    "    v = torch.FloatTensor(values)\n",
    "    # print(values)\n",
    "    # print(\"values\", v)\n",
    "    shape = coo.shape\n",
    "    tensor = torch.sparse.FloatTensor(i, v, torch.Size(shape)) \n",
    "    if torch.cuda.is_available():\n",
    "        tensor = tensor.cuda()\n",
    "\n",
    "    return tensor \n",
    "\n",
    "print(\"start training\")\n",
    "for epoch in range(2):\n",
    "    rbm.train()\n",
    "    train_recon_error = 0  # RMSE reconstruction error initialized to 0 at the beginning of training\n",
    "    s = 0\n",
    "    \n",
    "    for user_id in range(0, user_reviews_df_exploded['user_id_int'].max() + 1 - batch_size, batch_size):\n",
    "        training_sample = train_matrix[user_id : user_id + batch_size]\n",
    "        training_sample2 = train_matrix[user_id : user_id + batch_size]\n",
    "        # print(training_sample)\n",
    "        v0 = convert_sparse_matrix_to_sparse_tensor(training_sample)\n",
    "        # print(v0.coalesce().indices())\n",
    "        vk = convert_sparse_matrix_to_sparse_tensor(training_sample2)\n",
    "\n",
    "        v0 = v0.to_dense()\n",
    "        vk = vk.to_dense()\n",
    "        v0 = v0.sub(1)\n",
    "        vk = vk.sub(1)\n",
    "        \n",
    "        ph0, _ = rbm.sample_h(v0)   \n",
    "\n",
    "        # Third for loop - perform contrastive divergence\n",
    "        # TODO misschien is iets lager proberen?\n",
    "        for k in range(10):\n",
    "            _, hk = rbm.sample_h(vk)\n",
    "            _, vk = rbm.sample_v(hk)\n",
    "\n",
    "            # We don't want to learn when there is no rating by the user, and there is no update when rating = -1\n",
    "            # Remove indices from vk vector that are not in the v0 vector => get sparse tensor again\n",
    "            vk[v0 < 0] = v0[v0 < 0]\n",
    "            vksparse = vk.to_sparse()\n",
    "            # print(\"v0\", v0)\n",
    "            # print(\"v0\", v0.add(1).to_sparse())\n",
    "            # print(\"vk\", vk.add(1).to_sparse())\n",
    "            \n",
    "            # print(k)\n",
    "\n",
    "        phk, _ = rbm.sample_h(vk)\n",
    "\n",
    "\n",
    "        rbm.train_model(v0, vk, ph0, phk)\n",
    "        \n",
    "        train_recon_error += torch.sqrt(torch.mean((v0[v0 > 0] - vk[v0 > 0])**2))\n",
    "        s += 1\n",
    "        \n",
    "        # print((torch.mm(v0.t(), ph0) - torch.mm(vk.t(), phk)).t().shape)\n",
    "        # print(torch.sum((-vk + v0), 0).shape)\n",
    "        # print(torch.sum((ph0 - phk), 0).shape)\n",
    "        \n",
    "    train_errors.append(train_recon_error / s)\n",
    "\n",
    "    print('calculating test scores')\n",
    "    rbm.eval()\n",
    "    test_errors.append(score_model(rbm))\n",
    "\n",
    "    print('finished epoch', epoch)    \n",
    "    \n",
    "import matplotlib.pyplot as plt\n",
    "# Plot the RMSE reconstruction error with respect to increasing number of epochs\n",
    "plt.plot(torch.Tensor(train_errors, device='cpu'), label=\"train\")\n",
    "plt.plot(torch.Tensor(test_errors, device='cpu'), label=\"test\")\n",
    "plt.ylabel('Error')\n",
    "plt.xlabel('Epoch')\n",
    "plt.savefig('errors.jpg')\n",
    "\n",
    "# Evaluate the RBM on test set\n",
    "# test_recon_error = score_model(rbm)\n",
    "# print(\"Final error\", test_recon_error)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(torch.Tensor(train_errors, device='cpu'), label=\"train\")\n",
    "plt.plot(torch.Tensor(test_errors, device='cpu'), label=\"test\")\n",
    "plt.ylabel('Error')\n",
    "plt.xlabel('Epoch')\n",
    "plt.savefig('errors.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# torch.save(rbm.state_dict(), \"./network\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true,
     "name": "#%% load model\n"
    }
   },
   "outputs": [],
   "source": [
    "rbm = RBM(n_vis, n_hidden)\n",
    "rbm.load_state_dict(torch.load(\"./network\"))\n",
    "rbm.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Full Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7793069it [03:51, 33627.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 3176223 rows.\n"
     ]
    }
   ],
   "source": [
    "steam_reviews_df = parse_json(steam_path + steam_reviews)\n",
    "steam_reviews_df_small = steam_reviews_df[['user_id', 'product_id', 'recommended', 'date']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "steam_reviews_df_cleaned = steam_reviews_df_small.dropna(axis=0, subset=['user_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76561198011965365    1254\n",
       "76561198094803808     900\n",
       "76561197969749884     750\n",
       "76561198094321628     669\n",
       "76561198073092169     549\n",
       "                     ... \n",
       "76561198345086561       1\n",
       "76561198054491833       1\n",
       "76561198095690287       1\n",
       "76561198301658414       1\n",
       "76561198089897928       1\n",
       "Name: user_id, Length: 1485611, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steam_reviews_df_cleaned.head(5)\n",
    "steam_reviews_df[\"user_id\"].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3176223/3176223 [00:01<00:00, 1689802.73it/s]\n"
     ]
    }
   ],
   "source": [
    "dct = {}\n",
    "def map_to_consecutive_id(uuid):\n",
    "  if uuid in dct:\n",
    "    return dct[uuid]\n",
    "  else:\n",
    "    id = len(dct)\n",
    "    dct[uuid] = id\n",
    "    return id\n",
    "steam_reviews_df_cleaned['product_id_int'] = steam_reviews_df_cleaned['product_id'].progress_apply(map_to_consecutive_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# train_df, test_df = train_test_split(steam_reviews_df_cleaned, test_size=0.2)\n",
    "\n",
    "\n",
    "# test_df_grouped = test_df.groupby('user_id_int').agg(list)\n",
    "# test_df_grouped = test_df_grouped.reset_index()\n",
    "\n",
    "# train_df_grouped = train_df.groupby('user_id_int').agg(list)\n",
    "# train_df_grouped = train_df_grouped.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Date Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id                   object\n",
       "product_id                object\n",
       "recommended                 bool\n",
       "date              datetime64[ns]\n",
       "product_id_int             int64\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>recommended</th>\n",
       "      <th>date</th>\n",
       "      <th>product_id_int</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>76561198007483075</td>\n",
       "      <td>35140</td>\n",
       "      <td>True</td>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>76561197970402776</td>\n",
       "      <td>707610</td>\n",
       "      <td>True</td>\n",
       "      <td>2017-10-16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>76561198060686749</td>\n",
       "      <td>328100</td>\n",
       "      <td>True</td>\n",
       "      <td>2017-06-23</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>76561198023491401</td>\n",
       "      <td>35140</td>\n",
       "      <td>True</td>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>76561198115331805</td>\n",
       "      <td>35140</td>\n",
       "      <td>True</td>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             user_id product_id  recommended       date  product_id_int\n",
       "0  76561198007483075      35140         True 2018-01-04               0\n",
       "1  76561197970402776     707610         True 2017-10-16               1\n",
       "2  76561198060686749     328100         True 2017-06-23               2\n",
       "3  76561198023491401      35140         True 2018-01-03               0\n",
       "4  76561198115331805      35140         True 2018-01-03               0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "steam_reviews_df_cleaned[\"date\"] = pd.to_datetime(steam_reviews_df_cleaned[\"date\"])\n",
    "display(steam_reviews_df_cleaned.dtypes)\n",
    "display(steam_reviews_df_cleaned.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id_int</th>\n",
       "      <th>recommended</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>76561197960265806</th>\n",
       "      <td>[14313]</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[2017-12-20 00:00:00]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76561197960266010</th>\n",
       "      <td>[9722]</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[2017-11-27 00:00:00]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76561197960266146</th>\n",
       "      <td>[597]</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[2017-11-04 00:00:00]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76561197960266225</th>\n",
       "      <td>[1622]</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[2017-06-07 00:00:00]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76561197960266375</th>\n",
       "      <td>[3716]</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[2017-09-13 00:00:00]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  product_id_int recommended                   date\n",
       "user_id                                                            \n",
       "76561197960265806        [14313]      [True]  [2017-12-20 00:00:00]\n",
       "76561197960266010         [9722]      [True]  [2017-11-27 00:00:00]\n",
       "76561197960266146          [597]      [True]  [2017-11-04 00:00:00]\n",
       "76561197960266225         [1622]      [True]  [2017-06-07 00:00:00]\n",
       "76561197960266375         [3716]      [True]  [2017-09-13 00:00:00]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id_int</th>\n",
       "      <th>recommended</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>76561197960266546</th>\n",
       "      <td>[2678, 2678]</td>\n",
       "      <td>[True, True]</td>\n",
       "      <td>[2016-11-25 00:00:00, 2016-11-25 00:00:00]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76561197960266564</th>\n",
       "      <td>[7259, 7259]</td>\n",
       "      <td>[True, True]</td>\n",
       "      <td>[2016-08-14 00:00:00, 2016-08-14 00:00:00]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76561197960267022</th>\n",
       "      <td>[7779, 13382]</td>\n",
       "      <td>[True, True]</td>\n",
       "      <td>[2015-09-29 00:00:00, 2015-04-16 00:00:00]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76561197960267615</th>\n",
       "      <td>[1428, 2098, 2545, 2643, 2633, 3052, 3150, 397...</td>\n",
       "      <td>[True, True, True, True, True, True, True, Tru...</td>\n",
       "      <td>[2012-11-06 00:00:00, 2011-11-30 00:00:00, 201...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76561197960268226</th>\n",
       "      <td>[9485, 13462]</td>\n",
       "      <td>[True, True]</td>\n",
       "      <td>[2015-06-01 00:00:00, 2016-11-28 00:00:00]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      product_id_int  \\\n",
       "user_id                                                                \n",
       "76561197960266546                                       [2678, 2678]   \n",
       "76561197960266564                                       [7259, 7259]   \n",
       "76561197960267022                                      [7779, 13382]   \n",
       "76561197960267615  [1428, 2098, 2545, 2643, 2633, 3052, 3150, 397...   \n",
       "76561197960268226                                      [9485, 13462]   \n",
       "\n",
       "                                                         recommended  \\\n",
       "user_id                                                                \n",
       "76561197960266546                                       [True, True]   \n",
       "76561197960266564                                       [True, True]   \n",
       "76561197960267022                                       [True, True]   \n",
       "76561197960267615  [True, True, True, True, True, True, True, Tru...   \n",
       "76561197960268226                                       [True, True]   \n",
       "\n",
       "                                                                date  \n",
       "user_id                                                               \n",
       "76561197960266546         [2016-11-25 00:00:00, 2016-11-25 00:00:00]  \n",
       "76561197960266564         [2016-08-14 00:00:00, 2016-08-14 00:00:00]  \n",
       "76561197960267022         [2015-09-29 00:00:00, 2015-04-16 00:00:00]  \n",
       "76561197960267615  [2012-11-06 00:00:00, 2011-11-30 00:00:00, 201...  \n",
       "76561197960268226         [2015-06-01 00:00:00, 2016-11-28 00:00:00]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "steam_reviews_df_grouped = steam_reviews_df_cleaned.groupby(\"user_id\")[[\"product_id_int\", \"recommended\", \"date\"]].agg(list)\n",
    "display(steam_reviews_df_grouped.head(5))\n",
    "\n",
    "steam_reviews_df_grouped_smaller = steam_reviews_df_grouped[steam_reviews_df_grouped[\"recommended\"].map(len) > 1]\n",
    "display(steam_reviews_df_grouped_smaller.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 581343/581343 [00:00<00:00, 1124202.15it/s]\n"
     ]
    }
   ],
   "source": [
    "dct.clear()\n",
    "steam_reviews_df_grouped_smaller = steam_reviews_df_grouped_smaller.reset_index()\n",
    "steam_reviews_df_grouped_smaller[\"user_id_int\"] = steam_reviews_df_grouped_smaller[\"user_id\"].progress_apply(map_to_consecutive_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(581343, 5)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(1485611, 3)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "904268\n"
     ]
    }
   ],
   "source": [
    "display(steam_reviews_df_grouped_smaller.shape)\n",
    "display(steam_reviews_df_grouped.shape)\n",
    "print(steam_reviews_df_grouped.shape[0] - steam_reviews_df_grouped_smaller.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 581343/581343 [00:00<00:00, 1087340.38it/s]\n",
      "100%|██████████| 581343/581343 [00:01<00:00, 371979.49it/s]\n",
      "100%|██████████| 581343/581343 [00:00<00:00, 1128567.21it/s]\n",
      "100%|██████████| 581343/581343 [00:00<00:00, 1151927.76it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>product_id_int</th>\n",
       "      <th>recommended</th>\n",
       "      <th>date</th>\n",
       "      <th>user_id_int</th>\n",
       "      <th>product_history</th>\n",
       "      <th>product_future</th>\n",
       "      <th>recommended_history</th>\n",
       "      <th>recommended_future</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>76561197960266546</td>\n",
       "      <td>[2678, 2678]</td>\n",
       "      <td>[True, True]</td>\n",
       "      <td>[2016-11-25 00:00:00, 2016-11-25 00:00:00]</td>\n",
       "      <td>0</td>\n",
       "      <td>[2678]</td>\n",
       "      <td>[2678]</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>76561197960266564</td>\n",
       "      <td>[7259, 7259]</td>\n",
       "      <td>[True, True]</td>\n",
       "      <td>[2016-08-14 00:00:00, 2016-08-14 00:00:00]</td>\n",
       "      <td>1</td>\n",
       "      <td>[7259]</td>\n",
       "      <td>[7259]</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>76561197960267022</td>\n",
       "      <td>[7779, 13382]</td>\n",
       "      <td>[True, True]</td>\n",
       "      <td>[2015-09-29 00:00:00, 2015-04-16 00:00:00]</td>\n",
       "      <td>2</td>\n",
       "      <td>[7779]</td>\n",
       "      <td>[13382]</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>76561197960267615</td>\n",
       "      <td>[1428, 2098, 2545, 2643, 2633, 3052, 3150, 397...</td>\n",
       "      <td>[True, True, True, True, True, True, True, Tru...</td>\n",
       "      <td>[2012-11-06 00:00:00, 2011-11-30 00:00:00, 201...</td>\n",
       "      <td>3</td>\n",
       "      <td>[1428, 2098, 2545, 2643, 2633, 3052, 3150, 397...</td>\n",
       "      <td>[12754, 12703, 12755, 13323, 13215, 13544, 140...</td>\n",
       "      <td>[True, True, True, True, True, True, True, Tru...</td>\n",
       "      <td>[True, True, True, True, True, True, True, True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>76561197960268226</td>\n",
       "      <td>[9485, 13462]</td>\n",
       "      <td>[True, True]</td>\n",
       "      <td>[2015-06-01 00:00:00, 2016-11-28 00:00:00]</td>\n",
       "      <td>4</td>\n",
       "      <td>[9485]</td>\n",
       "      <td>[13462]</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[True]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             user_id                                     product_id_int  \\\n",
       "0  76561197960266546                                       [2678, 2678]   \n",
       "1  76561197960266564                                       [7259, 7259]   \n",
       "2  76561197960267022                                      [7779, 13382]   \n",
       "3  76561197960267615  [1428, 2098, 2545, 2643, 2633, 3052, 3150, 397...   \n",
       "4  76561197960268226                                      [9485, 13462]   \n",
       "\n",
       "                                         recommended  \\\n",
       "0                                       [True, True]   \n",
       "1                                       [True, True]   \n",
       "2                                       [True, True]   \n",
       "3  [True, True, True, True, True, True, True, Tru...   \n",
       "4                                       [True, True]   \n",
       "\n",
       "                                                date  user_id_int  \\\n",
       "0         [2016-11-25 00:00:00, 2016-11-25 00:00:00]            0   \n",
       "1         [2016-08-14 00:00:00, 2016-08-14 00:00:00]            1   \n",
       "2         [2015-09-29 00:00:00, 2015-04-16 00:00:00]            2   \n",
       "3  [2012-11-06 00:00:00, 2011-11-30 00:00:00, 201...            3   \n",
       "4         [2015-06-01 00:00:00, 2016-11-28 00:00:00]            4   \n",
       "\n",
       "                                     product_history  \\\n",
       "0                                             [2678]   \n",
       "1                                             [7259]   \n",
       "2                                             [7779]   \n",
       "3  [1428, 2098, 2545, 2643, 2633, 3052, 3150, 397...   \n",
       "4                                             [9485]   \n",
       "\n",
       "                                      product_future  \\\n",
       "0                                             [2678]   \n",
       "1                                             [7259]   \n",
       "2                                            [13382]   \n",
       "3  [12754, 12703, 12755, 13323, 13215, 13544, 140...   \n",
       "4                                            [13462]   \n",
       "\n",
       "                                 recommended_history  \\\n",
       "0                                             [True]   \n",
       "1                                             [True]   \n",
       "2                                             [True]   \n",
       "3  [True, True, True, True, True, True, True, Tru...   \n",
       "4                                             [True]   \n",
       "\n",
       "                                 recommended_future  \n",
       "0                                            [True]  \n",
       "1                                            [True]  \n",
       "2                                            [True]  \n",
       "3  [True, True, True, True, True, True, True, True]  \n",
       "4                                            [True]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "def split(items, train_percentage):\n",
    "    train_count = math.floor(len(items) * train_percentage)\n",
    "    return items[0:train_count], items[train_count:]\n",
    "\n",
    "train_percentage = 0.8\n",
    "steam_reviews_df_grouped_smaller[\"product_history\"] = steam_reviews_df_grouped_smaller[\"product_id_int\"].progress_apply(lambda items: split(items, train_percentage)[0])\n",
    "steam_reviews_df_grouped_smaller[\"product_future\"] = steam_reviews_df_grouped_smaller[\"product_id_int\"].progress_apply(lambda items: split(items, train_percentage)[1])\n",
    "steam_reviews_df_grouped_smaller[\"recommended_history\"] = steam_reviews_df_grouped_smaller[\"recommended\"].progress_apply(lambda items: split(items, train_percentage)[0])\n",
    "steam_reviews_df_grouped_smaller[\"recommended_future\"] = steam_reviews_df_grouped_smaller[\"recommended\"].progress_apply(lambda items: split(items, train_percentage)[1])\n",
    "display(steam_reviews_df_grouped_smaller.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2271955"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steam_reviews_df_grouped_smaller[\"recommended\"].map(len).describe()\n",
    "steam_reviews_df_grouped_smaller[\"recommended\"].map(len).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#Create scipy csr matrix\n",
    "def get_sparse_matrix(df, shape, recommended_col=\"recommended_history\", product_col=\"product_history\"):\n",
    "    user_ids = []\n",
    "    product_ids = []\n",
    "    values = []\n",
    "    for _, row in df.iterrows():\n",
    "        products = row[product_col]\n",
    "        user = row['user_id_int']\n",
    "    \n",
    "        recommended = row[recommended_col]\n",
    "        user_ids.extend([user] * len(products))\n",
    "        product_ids.extend(products)\n",
    "        values.extend([2 if recommended[i] else 1 for i in range(len(products))])\n",
    "    #create csr matrix\n",
    "    # values = np.ones(len(user_ids))\n",
    "    matrix = scipy.sparse.csr_matrix((values, (user_ids, product_ids)), shape=shape, dtype=np.int32)\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "steam_reviews_set = steam_reviews_df_grouped_smaller.head(100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<100000x14513 sparse matrix of type '<class 'numpy.intc'>'\n",
       "\twith 293925 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape = (steam_reviews_set.shape[0], steam_reviews_df_cleaned['product_id_int'].max() + 1)\n",
    "\n",
    "steam_reviews_set = steam_reviews_set.reset_index()\n",
    "train_matrix = get_sparse_matrix(steam_reviews_set, shape)\n",
    "test_matrix = get_sparse_matrix(steam_reviews_set, shape, recommended_col=\"recommended_future\", product_col=\"product_future\")\n",
    "train_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<100000x14513 sparse matrix of type '<class 'numpy.intc'>'\n",
       "\twith 132628 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------\n",
      "start training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/48 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(184.0986, device='cuda:0') tensor(89., device='cuda:0') tensor(124.2468, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 45/48 [02:50<00:11,  4.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(70., device='cuda:0') tensor(70., device='cuda:0') tensor(94.6787, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [03:03<00:00,  3.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 42/48 [02:39<00:23,  3.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(52., device='cuda:0') tensor(52., device='cuda:0') tensor(54.7365, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [03:01<00:00,  3.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████▏ | 39/48 [02:27<00:34,  3.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(34., device='cuda:0') tensor(34., device='cuda:0') tensor(27.0023, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [03:01<00:00,  3.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 36/48 [02:17<00:45,  3.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(60., device='cuda:0') tensor(60., device='cuda:0') tensor(47.4170, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [03:02<00:00,  3.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 33/48 [02:04<00:56,  3.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(46., device='cuda:0') tensor(46., device='cuda:0') tensor(28.0000, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [03:01<00:00,  3.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▎   | 30/48 [01:53<01:08,  3.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(58., device='cuda:0') tensor(58., device='cuda:0') tensor(5.1017, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [03:01<00:00,  3.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▋    | 27/48 [01:41<01:19,  3.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(53.2723, device='cuda:0') tensor(44., device='cuda:0') tensor(51.9757, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [03:00<00:00,  3.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 24/48 [01:30<01:29,  3.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(78.5193, device='cuda:0') tensor(78., device='cuda:0') tensor(57., device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [03:00<00:00,  3.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 21/48 [01:19<01:41,  3.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(52.8823, device='cuda:0') tensor(42., device='cuda:0') tensor(59., device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [03:00<00:00,  3.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 18/48 [01:07<01:52,  3.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(64.9976, device='cuda:0') tensor(48., device='cuda:0') tensor(9.1758, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [03:00<00:00,  3.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███▏      | 15/48 [00:56<02:04,  3.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(52.8977, device='cuda:0') tensor(52., device='cuda:0') tensor(64., device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [03:01<00:00,  3.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 12/48 [00:45<02:15,  3.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(54.3374, device='cuda:0') tensor(46., device='cuda:0') tensor(47.9983, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [03:00<00:00,  3.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished epoch 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 9/48 [00:33<02:27,  3.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(108., device='cuda:0') tensor(80., device='cuda:0') tensor(68., device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [03:01<00:00,  3.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished epoch 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 6/48 [00:22<02:38,  3.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(52., device='cuda:0') tensor(52., device='cuda:0') tensor(42., device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [03:00<00:00,  3.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished epoch 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 3/48 [00:11<02:49,  3.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(40., device='cuda:0') tensor(40., device='cuda:0') tensor(19.5636, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [03:01<00:00,  3.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished epoch 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/48 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(51., device='cuda:0') tensor(36., device='cuda:0') tensor(65., device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 45/48 [02:49<00:11,  3.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(78.9972, device='cuda:0') tensor(70., device='cuda:0') tensor(85., device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [03:00<00:00,  3.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished epoch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 42/48 [02:39<00:22,  3.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(52., device='cuda:0') tensor(52., device='cuda:0') tensor(50.5363, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [03:01<00:00,  3.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished epoch 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████▏ | 39/48 [02:34<00:35,  3.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(43., device='cuda:0') tensor(34., device='cuda:0') tensor(34., device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [03:09<00:00,  3.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished epoch 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 36/48 [02:23<00:48,  4.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(60., device='cuda:0') tensor(60., device='cuda:0') tensor(3.0383e-06, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [03:11<00:00,  3.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished epoch 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 33/48 [02:11<00:59,  4.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(60.9760, device='cuda:0') tensor(46., device='cuda:0') tensor(58., device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [03:11<00:00,  3.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished epoch 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def score_model(rbm):\n",
    "    test_recon_error = 0  # RMSE reconstruction error initialized to 0 at the beginning of training\n",
    "    s = 0  # a counter (float type) \n",
    "    # for loop - go through every single user\n",
    "    for id_user in tqdm(range(shape[0])):\n",
    "        v = train_matrix[id_user:id_user + 1]  # training set inputs are used to activate neurons of my RBM\n",
    "        vt = test_matrix[id_user:id_user + 1]  # target\n",
    "        # v = convert_sparse_matrix_to_sparse_tensor(training_sample)\n",
    "        # vt = convert_sparse_matrix_to_sparse_tensor(training_sample2)\n",
    "        v = v.todense()\n",
    "        vt = vt.todense()\n",
    "\n",
    "        # v = v.to_dense()\n",
    "        # vt = vt.to_dense()\n",
    "        v = v - 1\n",
    "        vt = vt - 1\n",
    "        v = torch.Tensor(v)\n",
    "        vt = torch.Tensor(vt)\n",
    "        if torch.cuda.is_available():\n",
    "            v = v.cuda()\n",
    "            vt = vt.cuda()\n",
    "        if len(vt[vt > -1]) > 0:\n",
    "            _, h = rbm.sample_h(v)\n",
    "            _, v = rbm.sample_v(h)\n",
    "\n",
    "            # Update test RMSE reconstruction error\n",
    "            test_recon_error += torch.sqrt(torch.mean((vt[vt > -1] - v[vt > -1])**2))\n",
    "            s += 1\n",
    "\n",
    "    return test_recon_error / s\n",
    "\n",
    "print('-------')\n",
    "n_vis = shape[1]\n",
    "n_hidden = 10000\n",
    "batch_size = 2048 \n",
    "train_errors = []\n",
    "test_errors = []\n",
    "rbm = RBM(n_vis, n_hidden)\n",
    "\n",
    "# https://stackoverflow.com/questions/40896157/scipy-sparse-csr-matrix-to-tensorflow-sparsetensor-mini-batch-gradient-descent\n",
    "def convert_sparse_matrix_to_sparse_tensor(X):\n",
    "    coo = X.tocoo()\n",
    "\n",
    "    values = coo.data\n",
    "    indices = np.vstack((coo.row, coo.col))\n",
    "\n",
    "    i = torch.LongTensor(indices)\n",
    "    v = torch.FloatTensor(values)\n",
    "    if torch.cuda.is_available():\n",
    "        i = i.cuda()\n",
    "        v = v.cuda()\n",
    "    # print(values)\n",
    "    # print(\"values\", v)\n",
    "    shape = coo.shape\n",
    "    tensor = torch.sparse.FloatTensor(i, v, torch.Size(shape)) \n",
    "    if torch.cuda.is_available():\n",
    "        tensor = tensor.cuda()\n",
    "\n",
    "    return tensor \n",
    "\n",
    "print(\"start training\")\n",
    "for epoch in range(20):\n",
    "    rbm.train()\n",
    "    train_recon_error = 0  # RMSE reconstruction error initialized to 0 at the beginning of training\n",
    "    s = 0\n",
    "    \n",
    "    for user_id in tqdm(range(0, shape[0] - batch_size, batch_size)):\n",
    "        training_sample = train_matrix[user_id : user_id + batch_size]\n",
    "        training_sample2 = train_matrix[user_id : user_id + batch_size]\n",
    "        # print(training_sample)\n",
    "        v0 = convert_sparse_matrix_to_sparse_tensor(training_sample)\n",
    "        # print(v0.coalesce().indices())\n",
    "        vk = convert_sparse_matrix_to_sparse_tensor(training_sample2)\n",
    "\n",
    "        v0 = v0.to_dense()\n",
    "        vk = vk.to_dense()\n",
    "        v0 = v0.sub(1)\n",
    "        vk = vk.sub(1)\n",
    "        \n",
    "        ph0, _ = rbm.sample_h(v0)   \n",
    "\n",
    "        # Third for loop - perform contrastive divergence\n",
    "        for k in range(10):\n",
    "            _, hk = rbm.sample_h(vk)\n",
    "            _, vk = rbm.sample_v(hk)\n",
    "\n",
    "            # We don't want to learn when there is no rating by the user, and there is no update when rating = -1\n",
    "            # Remove indices from vk vector that are not in the v0 vector => get sparse tensor again\n",
    "            vk[v0 < 0] = v0[v0 < 0]\n",
    "            vksparse = vk.to_sparse()\n",
    "            # print(\"v0\", v0)\n",
    "            # print(\"v0\", v0.add(1).to_sparse())\n",
    "            # print(\"vk\", vk.add(1).to_sparse())\n",
    "            \n",
    "            # print(k)\n",
    "\n",
    "        phk, _ = rbm.sample_h(vk)\n",
    "\n",
    "\n",
    "        rbm.train_model(v0, vk, ph0, phk)\n",
    "        \n",
    "        train_recon_error += torch.sqrt(torch.mean((v0[v0 > 0] - vk[v0 > 0])**2))\n",
    "        s += 1\n",
    "        \n",
    "        # print((torch.mm(v0.t(), ph0) - torch.mm(vk.t(), phk)).t().shape)\n",
    "        # print(torch.sum((-vk + v0), 0).shape)\n",
    "        # print(torch.sum((ph0 - phk), 0).shape)\n",
    "        \n",
    "    train_errors.append(train_recon_error / s)\n",
    "\n",
    "    # print('calculating test scores')\n",
    "    # rbm.eval()\n",
    "    # test_errors.append(score_model(rbm))\n",
    "\n",
    "    print('finished epoch', epoch)    \n",
    "    \n",
    "import matplotlib.pyplot as plt\n",
    "# Plot the RMSE reconstruction error with respect to increasing number of epochs\n",
    "plt.plot(torch.Tensor(train_errors, device='cpu'), label=\"train\")\n",
    "plt.plot(torch.Tensor(test_errors, device='cpu'), label=\"test\")\n",
    "plt.ylabel('Error')\n",
    "plt.xlabel('Epoch')\n",
    "plt.savefig('big.jpg')\n",
    "\n",
    "# Evaluate the RBM on test set\n",
    "# test_recon_error = score_model(rbm)\n",
    "# print(\"Final error\", test_recon_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "display(train_errors)\n",
    "display(test_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "s = steam_reviews_df_small[\"user_id\"].value_counts(dropna=False)\n",
    "display(s.loc[s < 2])\n",
    "display(s.loc[s >= 2])\n",
    "display(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "test_errors"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ac59ebe37160ed0dfa835113d9b8498d9f09ceb179beaac4002f036b9467c963"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Restricted Boltzmann Machine Defintion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import PyTorch library\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "device = torch.device('cpu')\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# https://github.com/khanhnamle1994/MetaRec/blob/b5e36cb579a88b32cdfb728f35f645d76b24ad95/Boltzmann-Machines-Experiments/RBM-CF-PyTorch/rbm.py#L23\n",
    "# Create the Restricted Boltzmann Machine architecture\n",
    "class RBM(nn.Module):\n",
    "    def __init__(self, n_vis, n_hid):\n",
    "        \"\"\"\n",
    "        Initialize the parameters (weights and biases) we optimize during the training process\n",
    "        :param n_vis: number of visible units\n",
    "        :param n_hid: number of hidden units\n",
    "        \"\"\"\n",
    "\n",
    "        # Weights used for the probability of the visible units given the hidden units\n",
    "        super().__init__()\n",
    "        self.W = torch.randn(n_hid, n_vis, device=device)  # torch.rand: random normal distribution mean = 0, variance = 1\n",
    "\n",
    "        # Bias probability of the visible units is activated, given the value of the hidden units (p_v_given_h)\n",
    "        self.v_bias = torch.randn(1, n_vis, device=device)  # fake dimension for the batch = 1\n",
    "\n",
    "        # Bias probability of the hidden units is activated, given the value of the visible units (p_h_given_v)\n",
    "        self.h_bias = torch.randn(1, n_hid, device=device)  # fake dimension for the batch = 1\n",
    "\n",
    "    def sample_h(self, x):\n",
    "        \"\"\"\n",
    "        Sample the hidden units\n",
    "        :param x: the dataset\n",
    "        \"\"\"\n",
    "\n",
    "        # Probability h is activated given that the value v is sigmoid(Wx + a)\n",
    "        # torch.mm make the product of 2 tensors\n",
    "        # W.t() take the transpose because W is used for the p_v_given_h\n",
    "        wx = torch.mm(x, self.W.t())\n",
    "        # print(wx.shape)\n",
    "\n",
    "        # Expand the mini-batch\n",
    "        activation = wx + self.h_bias.expand_as(wx)\n",
    "        # print(activation.shape)\n",
    "\n",
    "        # Calculate the probability p_h_given_v\n",
    "        p_h_given_v = torch.sigmoid(activation)\n",
    "\n",
    "        # print(\"h sparse\", p_h_given_v.is_sparse, torch.bernoulli(p_h_given_v).is_sparse)\n",
    "\n",
    "        # Construct a Bernoulli RBM to predict whether an user loves the movie or not (0 or 1)\n",
    "        # This corresponds to whether the n_hid is activated or not activated\n",
    "        return p_h_given_v, torch.bernoulli(p_h_given_v)\n",
    "\n",
    "    def sample_v(self, y):\n",
    "        \"\"\"\n",
    "        Sample the visible units\n",
    "        :param y: the dataset\n",
    "        \"\"\"\n",
    "\n",
    "        # Probability v is activated given that the value h is sigmoid(Wx + a)\n",
    "        wy = torch.mm(y, self.W)\n",
    "\n",
    "        # Expand the mini-batch\n",
    "        activation = wy + self.v_bias.expand_as(wy)\n",
    "\n",
    "        # Calculate the probability p_v_given_h\n",
    "        p_v_given_h = torch.sigmoid(activation)\n",
    "\n",
    "        # print(\"v sparse\", p_v_given_h.is_sparse, torch.bernoulli(p_v_given_h).is_sparse)\n",
    "\n",
    "        # Construct a Bernoulli RBM to predict whether an user loves the movie or not (0 or 1)\n",
    "        # This corresponds to whether the n_vis is activated or not activated\n",
    "        return p_v_given_h, torch.bernoulli(p_v_given_h)\n",
    "\n",
    "    def train_model(self, v0, vk, ph0, phk):\n",
    "        \"\"\"\n",
    "        Perform contrastive divergence algorithm to optimize the weights that minimize the energy\n",
    "        This maximizes the log-likelihood of the model\n",
    "        \"\"\"\n",
    "\n",
    "        # Approximate the gradients with the CD algorithm\n",
    "        self.W += (torch.mm(v0.t(), ph0) - torch.mm(vk.t(), phk)).t()\n",
    "\n",
    "        # Add (difference, 0) for the tensor of 2 dimensions\n",
    "        self.v_bias += torch.sum((v0 - vk), 0)\n",
    "        self.h_bias += torch.sum((ph0 - phk), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "import gzip\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "import math\n",
    "tqdm.pandas() #for progres_apply etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "#read file line-by-line and parse json, returns dataframe\n",
    "def parse_json(filename_gzipped_python_json, read_max=-1):\n",
    "  #read gzipped content\n",
    "  f=gzip.open(filename_gzipped_python_json,'r')\n",
    "  \n",
    "  #parse json\n",
    "  parse_data = []\n",
    "  for line in tqdm(f): #tqdm is for showing progress bar, always good when processing large amounts of data\n",
    "    line = line.decode('utf-8')\n",
    "    line = line.replace('true','True') #difference json/python\n",
    "    line = line.replace('false','False')\n",
    "    parsed_result = eval(line) #load python nested datastructure\n",
    "    # print(filename_gzipped_python_json == steam_path + steam_reviews and 'user_id' not in parsed_result)\n",
    "    # break\n",
    "    if filename_gzipped_python_json == steam_path + steam_reviews and 'user_id' not in parsed_result:\n",
    "      continue\n",
    "      \n",
    "    parse_data.append(parsed_result)\n",
    "    if read_max !=-1 and len(parse_data) > read_max:\n",
    "      print(f'Break reading after {read_max} records')\n",
    "      break\n",
    "  print(f\"Reading {len(parse_data)} rows.\")\n",
    "\n",
    "  #create dataframe\n",
    "  df= pd.DataFrame.from_dict(parse_data)\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "steam_path = './data/'\n",
    "metadata_games = 'steam_games.json.gz' \n",
    "user_items = 'australian_users_items.json.gz'\n",
    "user_reviews = 'australian_user_reviews.json.gz'\n",
    "game_bundles = 'bundle_data.json.gz'\n",
    "steam_reviews= 'steam_reviews.json.gz'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Australien Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# for dataset in [metadata_games, user_items, user_reviews, game_bundles, steam_reviews]:\n",
    "for dataset in [user_reviews]:\n",
    "  print(f\"----- {dataset}-----\")\n",
    "  size = os.path.getsize(steam_path + dataset) \n",
    "  print(f'Size of file is {size / 1000000}MB')\n",
    "  df_metadata = parse_json(steam_path + dataset)\n",
    "  pd.set_option('display.max_colwidth', None)\n",
    "  # display(df_metadata.head(5))\n",
    "#   display(df_metadata.describe(include='all'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "user_reviews_df = parse_json(steam_path + user_reviews)\n",
    "user_reviews_df = user_reviews_df.drop_duplicates(subset='user_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "user_reviews_df_exploded = user_reviews_df.explode('reviews')\n",
    "user_reviews_df_exploded = user_reviews_df_exploded.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def func(x):\n",
    "    return x['recommend'], x[\"item_id\"]\n",
    "\n",
    "user_reviews_df_exploded['recommended'], user_reviews_df_exploded[\"item_id\"] = zip(\n",
    "    *user_reviews_df_exploded['reviews'].map(func)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "user_reviews_df_exploded.reset_index()\n",
    "\n",
    "\n",
    "user_reviews_df_exploded = user_reviews_df_exploded[['user_id', 'item_id', 'recommended']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "enkeltrue = user_reviews_df[['reviews']].apply(lambda x: [elem['recommend'] for elem in x['reviews']], axis=1)\n",
    "enkeltrue.loc[enkeltrue.map(set).map(len) > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "dct = {}\n",
    "def map_to_consecutive_id(uuid):\n",
    "  if uuid in dct:\n",
    "    return dct[uuid]\n",
    "  else:\n",
    "    id = len(dct)\n",
    "    dct[uuid] = id\n",
    "    return id\n",
    "user_reviews_df_exploded['item_id_int'] = user_reviews_df_exploded['item_id'].progress_apply(map_to_consecutive_id)\n",
    "user_reviews_df_exploded.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "dct = {}\n",
    "user_reviews_df_exploded['user_id_int'] = user_reviews_df_exploded['user_id'].progress_apply(map_to_consecutive_id)\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_df, test_df = train_test_split(user_reviews_df_exploded, test_size=0.2)\n",
    "\n",
    "\n",
    "test_df_grouped = test_df.groupby('user_id_int').agg(list)\n",
    "test_df_grouped = test_df_grouped.reset_index()\n",
    "\n",
    "train_df_grouped = train_df.groupby('user_id_int').agg(list)\n",
    "train_df_grouped = train_df_grouped.reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "#Create scipy csr matrix\n",
    "def get_sparse_matrix(df):\n",
    "    shape = (user_reviews_df_exploded['user_id_int'].max() + 1, user_reviews_df_exploded['item_id_int'].max() + 1)\n",
    "    \n",
    "    user_ids = []\n",
    "    item_ids = []\n",
    "    values = []\n",
    "    for idx, row in df.iterrows():\n",
    "        items = row['item_id_int']\n",
    "        user = row['user_id_int']\n",
    "    \n",
    "        recommended = row['recommended']\n",
    "        user_ids.extend([user] * len(items))\n",
    "        item_ids.extend(items)\n",
    "        values.extend([2 if recommended[i] else 1 for i in range(len(items))])\n",
    "    #create csr matrix\n",
    "    # values = np.ones(len(user_ids))\n",
    "    matrix = scipy.sparse.csr_matrix((values, (user_ids, item_ids)), shape=shape, dtype=np.int32)\n",
    "    return matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "test_matrix = get_sparse_matrix(test_df_grouped)\n",
    "\n",
    "train_matrix = get_sparse_matrix(train_df_grouped)\n",
    "train_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def score_model(rbm):\n",
    "    test_recon_error = 0  # RMSE reconstruction error initialized to 0 at the beginning of training\n",
    "    s = 0  # a counter (float type) \n",
    "    # for loop - go through every single user\n",
    "    for id_user in range(user_reviews_df_exploded['user_id_int'].max() + 1):\n",
    "        v = train_matrix[id_user:id_user + 1]  # training set inputs are used to activate neurons of my RBM\n",
    "        vt = test_matrix[id_user:id_user + 1]  # target\n",
    "        # v = convert_sparse_matrix_to_sparse_tensor(training_sample)\n",
    "        # vt = convert_sparse_matrix_to_sparse_tensor(training_sample2)\n",
    "        v = v.todense()\n",
    "        vt = vt.todense()\n",
    "\n",
    "        # v = v.to_dense()\n",
    "        # vt = vt.to_dense()\n",
    "        v = v - 1\n",
    "        vt = vt - 1\n",
    "        v = torch.Tensor(v)\n",
    "        vt = torch.Tensor(vt)\n",
    "        if torch.cuda.is_available():\n",
    "            v = v.cuda()\n",
    "            vt = vt.cuda()\n",
    "        if len(vt[vt > -1]) > 0:\n",
    "            _, h = rbm.sample_h(v)\n",
    "            _, v = rbm.sample_v(h)\n",
    "\n",
    "            # Update test RMSE reconstruction error\n",
    "            test_recon_error += torch.sqrt(torch.mean((vt[vt > -1] - v[vt > -1])**2))\n",
    "            s += 1\n",
    "\n",
    "    return test_recon_error / s\n",
    "\n",
    "print('-------')\n",
    "n_vis = user_reviews_df_exploded['item_id_int'].max() + 1\n",
    "n_hidden = 1024\n",
    "batch_size = 128\n",
    "train_errors = []\n",
    "test_errors = []\n",
    "rbm = RBM(n_vis, n_hidden)\n",
    "\n",
    "# https://stackoverflow.com/questions/40896157/scipy-sparse-csr-matrix-to-tensorflow-sparsetensor-mini-batch-gradient-descent\n",
    "def convert_sparse_matrix_to_sparse_tensor(X):\n",
    "    coo = X.tocoo()\n",
    "\n",
    "    values = coo.data\n",
    "    indices = np.vstack((coo.row, coo.col))\n",
    "\n",
    "    i = torch.LongTensor(indices)\n",
    "    v = torch.FloatTensor(values)\n",
    "    # print(values)\n",
    "    # print(\"values\", v)\n",
    "    shape = coo.shape\n",
    "    tensor = torch.sparse.FloatTensor(i, v, torch.Size(shape)) \n",
    "    if torch.cuda.is_available():\n",
    "        tensor = tensor.cuda()\n",
    "\n",
    "    return tensor \n",
    "\n",
    "print(\"start training\")\n",
    "for epoch in range(20):\n",
    "    rbm.train()\n",
    "    train_recon_error = 0  # RMSE reconstruction error initialized to 0 at the beginning of training\n",
    "    s = 0\n",
    "    \n",
    "    for user_id in range(0, user_reviews_df_exploded['user_id_int'].max() + 1 - batch_size, batch_size):\n",
    "        training_sample = train_matrix[user_id : user_id + batch_size]\n",
    "        training_sample2 = train_matrix[user_id : user_id + batch_size]\n",
    "        # print(training_sample)\n",
    "        v0 = convert_sparse_matrix_to_sparse_tensor(training_sample)\n",
    "        # print(v0.coalesce().indices())\n",
    "        vk = convert_sparse_matrix_to_sparse_tensor(training_sample2)\n",
    "\n",
    "        v0 = v0.to_dense()\n",
    "        vk = vk.to_dense()\n",
    "        v0 = v0.sub(1)\n",
    "        vk = vk.sub(1)\n",
    "        \n",
    "        ph0, _ = rbm.sample_h(v0)   \n",
    "\n",
    "        # Third for loop - perform contrastive divergence\n",
    "        for k in range(10):\n",
    "            _, hk = rbm.sample_h(vk)\n",
    "            _, vk = rbm.sample_v(hk)\n",
    "\n",
    "            # We don't want to learn when there is no rating by the user, and there is no update when rating = -1\n",
    "            # Remove indices from vk vector that are not in the v0 vector => get sparse tensor again\n",
    "            vk[v0 < 0] = v0[v0 < 0]\n",
    "            vksparse = vk.to_sparse()\n",
    "            # print(\"v0\", v0)\n",
    "            # print(\"v0\", v0.add(1).to_sparse())\n",
    "            # print(\"vk\", vk.add(1).to_sparse())\n",
    "            \n",
    "            # print(k)\n",
    "\n",
    "        phk, _ = rbm.sample_h(vk)\n",
    "\n",
    "\n",
    "        rbm.train_model(v0, vk, ph0, phk)\n",
    "        \n",
    "        train_recon_error += torch.sqrt(torch.mean((v0[v0 > 0] - vk[v0 > 0])**2))\n",
    "        s += 1\n",
    "        \n",
    "        # print((torch.mm(v0.t(), ph0) - torch.mm(vk.t(), phk)).t().shape)\n",
    "        # print(torch.sum((-vk + v0), 0).shape)\n",
    "        # print(torch.sum((ph0 - phk), 0).shape)\n",
    "        \n",
    "    train_errors.append(train_recon_error / s)\n",
    "\n",
    "    print('calculating test scores')\n",
    "    rbm.eval()\n",
    "    test_errors.append(score_model(rbm))\n",
    "\n",
    "    print('finished epoch', epoch)    \n",
    "    \n",
    "import matplotlib.pyplot as plt\n",
    "# Plot the RMSE reconstruction error with respect to increasing number of epochs\n",
    "plt.plot(torch.Tensor(train_errors, device='cpu'), label=\"train\")\n",
    "plt.plot(torch.Tensor(test_errors, device='cpu'), label=\"test\")\n",
    "plt.ylabel('Error')\n",
    "plt.xlabel('Epoch')\n",
    "plt.savefig('errors.jpg')\n",
    "\n",
    "# Evaluate the RBM on test set\n",
    "# test_recon_error = score_model(rbm)\n",
    "# print(\"Final error\", test_recon_error)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(torch.Tensor(train_errors, device='cpu'), label=\"train\")\n",
    "plt.plot(torch.Tensor(test_errors, device='cpu'), label=\"test\")\n",
    "plt.ylabel('Error')\n",
    "plt.xlabel('Epoch')\n",
    "plt.savefig('errors.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# torch.save(rbm.state_dict(), \"./network\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": false,
     "name": "#%% load model\n"
    }
   },
   "outputs": [],
   "source": [
    "rbm = RBM(n_vis, n_hidden)\n",
    "rbm.load_state_dict(torch.load(\"./network\"))\n",
    "rbm.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Full Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7793069it [03:49, 33921.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 3176223 rows.\n"
     ]
    }
   ],
   "source": [
    "steam_reviews_df = parse_json(steam_path + steam_reviews)\n",
    "steam_reviews_df_small = steam_reviews_df[['user_id', 'product_id', 'recommended', 'date']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "steam_reviews_df_cleaned = steam_reviews_df_small.dropna(axis=0, subset=['user_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76561198011965365    1254\n",
       "76561198094803808     900\n",
       "76561197969749884     750\n",
       "76561198094321628     669\n",
       "76561198073092169     549\n",
       "                     ... \n",
       "76561198345086561       1\n",
       "76561198054491833       1\n",
       "76561198095690287       1\n",
       "76561198301658414       1\n",
       "76561198089897928       1\n",
       "Name: user_id, Length: 1485611, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steam_reviews_df_cleaned.head(5)\n",
    "steam_reviews_df[\"user_id\"].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3176223/3176223 [00:01<00:00, 1632652.75it/s]\n"
     ]
    }
   ],
   "source": [
    "dct = {}\n",
    "def map_to_consecutive_id(uuid):\n",
    "  if uuid in dct:\n",
    "    return dct[uuid]\n",
    "  else:\n",
    "    id = len(dct)\n",
    "    dct[uuid] = id\n",
    "    return id\n",
    "steam_reviews_df_cleaned['product_id_int'] = steam_reviews_df_cleaned['product_id'].progress_apply(map_to_consecutive_id)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# train_df, test_df = train_test_split(steam_reviews_df_cleaned, test_size=0.2)\n",
    "\n",
    "\n",
    "# test_df_grouped = test_df.groupby('user_id_int').agg(list)\n",
    "# test_df_grouped = test_df_grouped.reset_index()\n",
    "\n",
    "# train_df_grouped = train_df.groupby('user_id_int').agg(list)\n",
    "# train_df_grouped = train_df_grouped.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Date Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id                   object\n",
       "product_id                object\n",
       "recommended                 bool\n",
       "date              datetime64[ns]\n",
       "product_id_int             int64\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>recommended</th>\n",
       "      <th>date</th>\n",
       "      <th>product_id_int</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>76561198007483075</td>\n",
       "      <td>35140</td>\n",
       "      <td>True</td>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>76561197970402776</td>\n",
       "      <td>707610</td>\n",
       "      <td>True</td>\n",
       "      <td>2017-10-16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>76561198060686749</td>\n",
       "      <td>328100</td>\n",
       "      <td>True</td>\n",
       "      <td>2017-06-23</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>76561198023491401</td>\n",
       "      <td>35140</td>\n",
       "      <td>True</td>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>76561198115331805</td>\n",
       "      <td>35140</td>\n",
       "      <td>True</td>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             user_id product_id  recommended       date  product_id_int\n",
       "0  76561198007483075      35140         True 2018-01-04               0\n",
       "1  76561197970402776     707610         True 2017-10-16               1\n",
       "2  76561198060686749     328100         True 2017-06-23               2\n",
       "3  76561198023491401      35140         True 2018-01-03               0\n",
       "4  76561198115331805      35140         True 2018-01-03               0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "steam_reviews_df_cleaned[\"date\"] = pd.to_datetime(steam_reviews_df_cleaned[\"date\"])\n",
    "display(steam_reviews_df_cleaned.dtypes)\n",
    "display(steam_reviews_df_cleaned.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id_int</th>\n",
       "      <th>recommended</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>76561197960265806</th>\n",
       "      <td>[14313]</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[2017-12-20 00:00:00]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76561197960266010</th>\n",
       "      <td>[9722]</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[2017-11-27 00:00:00]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76561197960266146</th>\n",
       "      <td>[597]</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[2017-11-04 00:00:00]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76561197960266225</th>\n",
       "      <td>[1622]</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[2017-06-07 00:00:00]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76561197960266375</th>\n",
       "      <td>[3716]</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[2017-09-13 00:00:00]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  product_id_int recommended                   date\n",
       "user_id                                                            \n",
       "76561197960265806        [14313]      [True]  [2017-12-20 00:00:00]\n",
       "76561197960266010         [9722]      [True]  [2017-11-27 00:00:00]\n",
       "76561197960266146          [597]      [True]  [2017-11-04 00:00:00]\n",
       "76561197960266225         [1622]      [True]  [2017-06-07 00:00:00]\n",
       "76561197960266375         [3716]      [True]  [2017-09-13 00:00:00]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id_int</th>\n",
       "      <th>recommended</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>76561197960266546</th>\n",
       "      <td>[2678, 2678]</td>\n",
       "      <td>[True, True]</td>\n",
       "      <td>[2016-11-25 00:00:00, 2016-11-25 00:00:00]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76561197960266564</th>\n",
       "      <td>[7259, 7259]</td>\n",
       "      <td>[True, True]</td>\n",
       "      <td>[2016-08-14 00:00:00, 2016-08-14 00:00:00]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76561197960267022</th>\n",
       "      <td>[7779, 13382]</td>\n",
       "      <td>[True, True]</td>\n",
       "      <td>[2015-09-29 00:00:00, 2015-04-16 00:00:00]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76561197960267615</th>\n",
       "      <td>[1428, 2098, 2545, 2643, 2633, 3052, 3150, 3979, 3979, 5255, 5797, 5747, 5884, 6832, 6500, 6956, 7122, 7102, 7352, 7469, 7931, 9757, 9911, 10291, 11006, 11309, 11432, 11736, 12754, 12703, 12755, 13323, 13215, 13544, 14085, 14055]</td>\n",
       "      <td>[True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True]</td>\n",
       "      <td>[2012-11-06 00:00:00, 2011-11-30 00:00:00, 2011-07-16 00:00:00, 2011-11-30 00:00:00, 2012-04-04 00:00:00, 2011-07-06 00:00:00, 2011-11-30 00:00:00, 2010-12-10 00:00:00, 2010-12-10 00:00:00, 2011-11-30 00:00:00, 2010-12-10 00:00:00, 2011-11-30 00:00:00, 2013-01-09 00:00:00, 2011-11-30 00:00:00, 2013-10-30 00:00:00, 2011-11-30 00:00:00, 2011-11-30 00:00:00, 2011-11-30 00:00:00, 2011-11-30 00:00:00, 2011-11-30 00:00:00, 2011-11-30 00:00:00, 2010-12-10 00:00:00, 2011-09-13 00:00:00, 2010-12-10 00:00:00, 2011-11-30 00:00:00, 2012-11-05 00:00:00, 2011-11-30 00:00:00, 2011-07-20 00:00:00, 2012-12-14 00:00:00, 2011-11-30 00:00:00, 2011-11-30 00:00:00, 2010-12-10 00:00:00, 2011-11-30 00:00:00, 2012-07-14 00:00:00, 2011-07-30 00:00:00, 2011-11-30 00:00:00]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76561197960268226</th>\n",
       "      <td>[9485, 13462]</td>\n",
       "      <td>[True, True]</td>\n",
       "      <td>[2015-06-01 00:00:00, 2016-11-28 00:00:00]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                          product_id_int  \\\n",
       "user_id                                                                                                                                                                                                                                                    \n",
       "76561197960266546                                                                                                                                                                                                                           [2678, 2678]   \n",
       "76561197960266564                                                                                                                                                                                                                           [7259, 7259]   \n",
       "76561197960267022                                                                                                                                                                                                                          [7779, 13382]   \n",
       "76561197960267615  [1428, 2098, 2545, 2643, 2633, 3052, 3150, 3979, 3979, 5255, 5797, 5747, 5884, 6832, 6500, 6956, 7122, 7102, 7352, 7469, 7931, 9757, 9911, 10291, 11006, 11309, 11432, 11736, 12754, 12703, 12755, 13323, 13215, 13544, 14085, 14055]   \n",
       "76561197960268226                                                                                                                                                                                                                          [9485, 13462]   \n",
       "\n",
       "                                                                                                                                                                                                                                recommended  \\\n",
       "user_id                                                                                                                                                                                                                                       \n",
       "76561197960266546                                                                                                                                                                                                              [True, True]   \n",
       "76561197960266564                                                                                                                                                                                                              [True, True]   \n",
       "76561197960267022                                                                                                                                                                                                              [True, True]   \n",
       "76561197960267615  [True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True]   \n",
       "76561197960268226                                                                                                                                                                                                              [True, True]   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   date  \n",
       "user_id                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "76561197960266546                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            [2016-11-25 00:00:00, 2016-11-25 00:00:00]  \n",
       "76561197960266564                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            [2016-08-14 00:00:00, 2016-08-14 00:00:00]  \n",
       "76561197960267022                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            [2015-09-29 00:00:00, 2015-04-16 00:00:00]  \n",
       "76561197960267615  [2012-11-06 00:00:00, 2011-11-30 00:00:00, 2011-07-16 00:00:00, 2011-11-30 00:00:00, 2012-04-04 00:00:00, 2011-07-06 00:00:00, 2011-11-30 00:00:00, 2010-12-10 00:00:00, 2010-12-10 00:00:00, 2011-11-30 00:00:00, 2010-12-10 00:00:00, 2011-11-30 00:00:00, 2013-01-09 00:00:00, 2011-11-30 00:00:00, 2013-10-30 00:00:00, 2011-11-30 00:00:00, 2011-11-30 00:00:00, 2011-11-30 00:00:00, 2011-11-30 00:00:00, 2011-11-30 00:00:00, 2011-11-30 00:00:00, 2010-12-10 00:00:00, 2011-09-13 00:00:00, 2010-12-10 00:00:00, 2011-11-30 00:00:00, 2012-11-05 00:00:00, 2011-11-30 00:00:00, 2011-07-20 00:00:00, 2012-12-14 00:00:00, 2011-11-30 00:00:00, 2011-11-30 00:00:00, 2010-12-10 00:00:00, 2011-11-30 00:00:00, 2012-07-14 00:00:00, 2011-07-30 00:00:00, 2011-11-30 00:00:00]  \n",
       "76561197960268226                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            [2015-06-01 00:00:00, 2016-11-28 00:00:00]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "steam_reviews_df_grouped = steam_reviews_df_cleaned.groupby(\"user_id\")[[\"product_id_int\", \"recommended\", \"date\"]].agg(list)\n",
    "display(steam_reviews_df_grouped.head(5))\n",
    "\n",
    "steam_reviews_df_grouped_smaller = steam_reviews_df_grouped[steam_reviews_df_grouped[\"recommended\"].map(len) > 1]\n",
    "display(steam_reviews_df_grouped_smaller.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 581343/581343 [00:00<00:00, 1090456.43it/s]\n"
     ]
    }
   ],
   "source": [
    "dct.clear()\n",
    "steam_reviews_df_grouped_smaller = steam_reviews_df_grouped_smaller.reset_index()\n",
    "steam_reviews_df_grouped_smaller[\"user_id_int\"] = steam_reviews_df_grouped_smaller[\"user_id\"].progress_apply(map_to_consecutive_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(581343, 5)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(1485611, 3)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "904268\n"
     ]
    }
   ],
   "source": [
    "display(steam_reviews_df_grouped_smaller.shape)\n",
    "display(steam_reviews_df_grouped.shape)\n",
    "print(steam_reviews_df_grouped.shape[0] - steam_reviews_df_grouped_smaller.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 581343/581343 [00:00<00:00, 1122032.52it/s]\n",
      "100%|██████████| 581343/581343 [00:00<00:00, 1130762.74it/s]\n",
      "100%|██████████| 581343/581343 [00:01<00:00, 380125.94it/s]\n",
      "100%|██████████| 581343/581343 [00:00<00:00, 1141871.90it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>product_id_int</th>\n",
       "      <th>recommended</th>\n",
       "      <th>date</th>\n",
       "      <th>user_id_int</th>\n",
       "      <th>product_history</th>\n",
       "      <th>product_future</th>\n",
       "      <th>recommended_history</th>\n",
       "      <th>recommended_future</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>76561197960266546</td>\n",
       "      <td>[2678, 2678]</td>\n",
       "      <td>[True, True]</td>\n",
       "      <td>[2016-11-25 00:00:00, 2016-11-25 00:00:00]</td>\n",
       "      <td>0</td>\n",
       "      <td>[2678]</td>\n",
       "      <td>[2678]</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>76561197960266564</td>\n",
       "      <td>[7259, 7259]</td>\n",
       "      <td>[True, True]</td>\n",
       "      <td>[2016-08-14 00:00:00, 2016-08-14 00:00:00]</td>\n",
       "      <td>1</td>\n",
       "      <td>[7259]</td>\n",
       "      <td>[7259]</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>76561197960267022</td>\n",
       "      <td>[7779, 13382]</td>\n",
       "      <td>[True, True]</td>\n",
       "      <td>[2015-09-29 00:00:00, 2015-04-16 00:00:00]</td>\n",
       "      <td>2</td>\n",
       "      <td>[7779]</td>\n",
       "      <td>[13382]</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>76561197960267615</td>\n",
       "      <td>[1428, 2098, 2545, 2643, 2633, 3052, 3150, 3979, 3979, 5255, 5797, 5747, 5884, 6832, 6500, 6956, 7122, 7102, 7352, 7469, 7931, 9757, 9911, 10291, 11006, 11309, 11432, 11736, 12754, 12703, 12755, 13323, 13215, 13544, 14085, 14055]</td>\n",
       "      <td>[True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True]</td>\n",
       "      <td>[2012-11-06 00:00:00, 2011-11-30 00:00:00, 2011-07-16 00:00:00, 2011-11-30 00:00:00, 2012-04-04 00:00:00, 2011-07-06 00:00:00, 2011-11-30 00:00:00, 2010-12-10 00:00:00, 2010-12-10 00:00:00, 2011-11-30 00:00:00, 2010-12-10 00:00:00, 2011-11-30 00:00:00, 2013-01-09 00:00:00, 2011-11-30 00:00:00, 2013-10-30 00:00:00, 2011-11-30 00:00:00, 2011-11-30 00:00:00, 2011-11-30 00:00:00, 2011-11-30 00:00:00, 2011-11-30 00:00:00, 2011-11-30 00:00:00, 2010-12-10 00:00:00, 2011-09-13 00:00:00, 2010-12-10 00:00:00, 2011-11-30 00:00:00, 2012-11-05 00:00:00, 2011-11-30 00:00:00, 2011-07-20 00:00:00, 2012-12-14 00:00:00, 2011-11-30 00:00:00, 2011-11-30 00:00:00, 2010-12-10 00:00:00, 2011-11-30 00:00:00, 2012-07-14 00:00:00, 2011-07-30 00:00:00, 2011-11-30 00:00:00]</td>\n",
       "      <td>3</td>\n",
       "      <td>[1428, 2098, 2545, 2643, 2633, 3052, 3150, 3979, 3979, 5255, 5797, 5747, 5884, 6832, 6500, 6956, 7122, 7102, 7352, 7469, 7931, 9757, 9911, 10291, 11006, 11309, 11432, 11736]</td>\n",
       "      <td>[12754, 12703, 12755, 13323, 13215, 13544, 14085, 14055]</td>\n",
       "      <td>[True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True]</td>\n",
       "      <td>[True, True, True, True, True, True, True, True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>76561197960268226</td>\n",
       "      <td>[9485, 13462]</td>\n",
       "      <td>[True, True]</td>\n",
       "      <td>[2015-06-01 00:00:00, 2016-11-28 00:00:00]</td>\n",
       "      <td>4</td>\n",
       "      <td>[9485]</td>\n",
       "      <td>[13462]</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[True]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             user_id  \\\n",
       "0  76561197960266546   \n",
       "1  76561197960266564   \n",
       "2  76561197960267022   \n",
       "3  76561197960267615   \n",
       "4  76561197960268226   \n",
       "\n",
       "                                                                                                                                                                                                                          product_id_int  \\\n",
       "0                                                                                                                                                                                                                           [2678, 2678]   \n",
       "1                                                                                                                                                                                                                           [7259, 7259]   \n",
       "2                                                                                                                                                                                                                          [7779, 13382]   \n",
       "3  [1428, 2098, 2545, 2643, 2633, 3052, 3150, 3979, 3979, 5255, 5797, 5747, 5884, 6832, 6500, 6956, 7122, 7102, 7352, 7469, 7931, 9757, 9911, 10291, 11006, 11309, 11432, 11736, 12754, 12703, 12755, 13323, 13215, 13544, 14085, 14055]   \n",
       "4                                                                                                                                                                                                                          [9485, 13462]   \n",
       "\n",
       "                                                                                                                                                                                                                recommended  \\\n",
       "0                                                                                                                                                                                                              [True, True]   \n",
       "1                                                                                                                                                                                                              [True, True]   \n",
       "2                                                                                                                                                                                                              [True, True]   \n",
       "3  [True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True]   \n",
       "4                                                                                                                                                                                                              [True, True]   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   date  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            [2016-11-25 00:00:00, 2016-11-25 00:00:00]   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            [2016-08-14 00:00:00, 2016-08-14 00:00:00]   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            [2015-09-29 00:00:00, 2015-04-16 00:00:00]   \n",
       "3  [2012-11-06 00:00:00, 2011-11-30 00:00:00, 2011-07-16 00:00:00, 2011-11-30 00:00:00, 2012-04-04 00:00:00, 2011-07-06 00:00:00, 2011-11-30 00:00:00, 2010-12-10 00:00:00, 2010-12-10 00:00:00, 2011-11-30 00:00:00, 2010-12-10 00:00:00, 2011-11-30 00:00:00, 2013-01-09 00:00:00, 2011-11-30 00:00:00, 2013-10-30 00:00:00, 2011-11-30 00:00:00, 2011-11-30 00:00:00, 2011-11-30 00:00:00, 2011-11-30 00:00:00, 2011-11-30 00:00:00, 2011-11-30 00:00:00, 2010-12-10 00:00:00, 2011-09-13 00:00:00, 2010-12-10 00:00:00, 2011-11-30 00:00:00, 2012-11-05 00:00:00, 2011-11-30 00:00:00, 2011-07-20 00:00:00, 2012-12-14 00:00:00, 2011-11-30 00:00:00, 2011-11-30 00:00:00, 2010-12-10 00:00:00, 2011-11-30 00:00:00, 2012-07-14 00:00:00, 2011-07-30 00:00:00, 2011-11-30 00:00:00]   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            [2015-06-01 00:00:00, 2016-11-28 00:00:00]   \n",
       "\n",
       "   user_id_int  \\\n",
       "0            0   \n",
       "1            1   \n",
       "2            2   \n",
       "3            3   \n",
       "4            4   \n",
       "\n",
       "                                                                                                                                                                 product_history  \\\n",
       "0                                                                                                                                                                         [2678]   \n",
       "1                                                                                                                                                                         [7259]   \n",
       "2                                                                                                                                                                         [7779]   \n",
       "3  [1428, 2098, 2545, 2643, 2633, 3052, 3150, 3979, 3979, 5255, 5797, 5747, 5884, 6832, 6500, 6956, 7122, 7102, 7352, 7469, 7931, 9757, 9911, 10291, 11006, 11309, 11432, 11736]   \n",
       "4                                                                                                                                                                         [9485]   \n",
       "\n",
       "                                             product_future  \\\n",
       "0                                                    [2678]   \n",
       "1                                                    [7259]   \n",
       "2                                                   [13382]   \n",
       "3  [12754, 12703, 12755, 13323, 13215, 13544, 14085, 14055]   \n",
       "4                                                   [13462]   \n",
       "\n",
       "                                                                                                                                                        recommended_history  \\\n",
       "0                                                                                                                                                                    [True]   \n",
       "1                                                                                                                                                                    [True]   \n",
       "2                                                                                                                                                                    [True]   \n",
       "3  [True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True]   \n",
       "4                                                                                                                                                                    [True]   \n",
       "\n",
       "                                 recommended_future  \n",
       "0                                            [True]  \n",
       "1                                            [True]  \n",
       "2                                            [True]  \n",
       "3  [True, True, True, True, True, True, True, True]  \n",
       "4                                            [True]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "def split(items, train_percentage):\n",
    "    train_count = math.floor(len(items) * train_percentage)\n",
    "    return items[0:train_count], items[train_count:]\n",
    "\n",
    "train_percentage = 0.8\n",
    "steam_reviews_df_grouped_smaller[\"product_history\"] = steam_reviews_df_grouped_smaller[\"product_id_int\"].progress_apply(lambda items: split(items, train_percentage)[0])\n",
    "steam_reviews_df_grouped_smaller[\"product_future\"] = steam_reviews_df_grouped_smaller[\"product_id_int\"].progress_apply(lambda items: split(items, train_percentage)[1])\n",
    "steam_reviews_df_grouped_smaller[\"recommended_history\"] = steam_reviews_df_grouped_smaller[\"recommended\"].progress_apply(lambda items: split(items, train_percentage)[0])\n",
    "steam_reviews_df_grouped_smaller[\"recommended_future\"] = steam_reviews_df_grouped_smaller[\"recommended\"].progress_apply(lambda items: split(items, train_percentage)[1])\n",
    "display(steam_reviews_df_grouped_smaller.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    581343.000000\n",
       "mean          3.908114\n",
       "std           5.950826\n",
       "min           2.000000\n",
       "25%           2.000000\n",
       "50%           2.000000\n",
       "75%           4.000000\n",
       "max        1254.000000\n",
       "Name: recommended, dtype: float64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steam_reviews_df_grouped_smaller[\"recommended\"].map(len).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create scipy csr matrix\n",
    "def get_sparse_matrix(df, shape, recommended_col=\"recommended_history\", product_col=\"product_history\"):\n",
    "    user_ids = []\n",
    "    product_ids = []\n",
    "    values = []\n",
    "    for _, row in df.iterrows():\n",
    "        products = row[product_col]\n",
    "        user = row['user_id_int']\n",
    "    \n",
    "        recommended = row[recommended_col]\n",
    "        user_ids.extend([user] * len(products))\n",
    "        product_ids.extend(products)\n",
    "        values.extend([2 if recommended[i] else 1 for i in range(len(products))])\n",
    "    #create csr matrix\n",
    "    # values = np.ones(len(user_ids))\n",
    "    matrix = scipy.sparse.csr_matrix((values, (user_ids, product_ids)), shape=shape, dtype=np.int32)\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "steam_reviews_set = steam_reviews_df_grouped_smaller.head(100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<100000x14513 sparse matrix of type '<class 'numpy.intc'>'\n",
       "\twith 293925 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape = (steam_reviews_set.shape[0], steam_reviews_df_cleaned['product_id_int'].max() + 1)\n",
    "\n",
    "steam_reviews_set = steam_reviews_set.reset_index()\n",
    "train_matrix = get_sparse_matrix(steam_reviews_set, shape)\n",
    "test_matrix = get_sparse_matrix(steam_reviews_set, shape, recommended_col=\"recommended_future\", product_col=\"product_future\")\n",
    "train_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<100000x14513 sparse matrix of type '<class 'numpy.intc'>'\n",
       "\twith 132628 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------\n",
      "start training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 97/97 [00:27<00:00,  3.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating test scores\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [01:15<00:00, 1318.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 97/97 [00:26<00:00,  3.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating test scores\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [01:18<00:00, 1266.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished epoch 1\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def score_model(rbm):\n",
    "    test_recon_error = 0  # RMSE reconstruction error initialized to 0 at the beginning of training\n",
    "    s = 0  # a counter (float type) \n",
    "    # for loop - go through every single user\n",
    "    for id_user in tqdm(range(shape[0])):\n",
    "        v = train_matrix[id_user:id_user + 1]  # training set inputs are used to activate neurons of my RBM\n",
    "        vt = test_matrix[id_user:id_user + 1]  # target\n",
    "        # v = convert_sparse_matrix_to_sparse_tensor(training_sample)\n",
    "        # vt = convert_sparse_matrix_to_sparse_tensor(training_sample2)\n",
    "        v = v.todense()\n",
    "        vt = vt.todense()\n",
    "\n",
    "        # v = v.to_dense()\n",
    "        # vt = vt.to_dense()\n",
    "        v = v - 1\n",
    "        vt = vt - 1\n",
    "        v = torch.Tensor(v)\n",
    "        vt = torch.Tensor(vt)\n",
    "        if torch.cuda.is_available():\n",
    "            v = v.cuda()\n",
    "            vt = vt.cuda()\n",
    "        if len(vt[vt > -1]) > 0:\n",
    "            _, h = rbm.sample_h(v)\n",
    "            _, v = rbm.sample_v(h)\n",
    "\n",
    "            # Update test RMSE reconstruction error\n",
    "            test_recon_error += torch.sqrt(torch.mean((vt[vt > -1] - v[vt > -1])**2))\n",
    "            s += 1\n",
    "\n",
    "    return test_recon_error / s\n",
    "\n",
    "print('-------')\n",
    "n_vis = shape[1]\n",
    "n_hidden = 12\n",
    "batch_size = 1024 \n",
    "train_errors = []\n",
    "test_errors = []\n",
    "rbm = RBM(n_vis, n_hidden)\n",
    "\n",
    "# https://stackoverflow.com/questions/40896157/scipy-sparse-csr-matrix-to-tensorflow-sparsetensor-mini-batch-gradient-descent\n",
    "def convert_sparse_matrix_to_sparse_tensor(X):\n",
    "    coo = X.tocoo()\n",
    "\n",
    "    values = coo.data\n",
    "    indices = np.vstack((coo.row, coo.col))\n",
    "\n",
    "    i = torch.LongTensor(indices)\n",
    "    v = torch.FloatTensor(values)\n",
    "    if torch.cuda.is_available():\n",
    "        i = i.cuda()\n",
    "        v = v.cuda()\n",
    "    # print(values)\n",
    "    # print(\"values\", v)\n",
    "    shape = coo.shape\n",
    "    tensor = torch.sparse.FloatTensor(i, v, torch.Size(shape)) \n",
    "    if torch.cuda.is_available():\n",
    "        tensor = tensor.cuda()\n",
    "\n",
    "    return tensor \n",
    "\n",
    "print(\"start training\")\n",
    "for epoch in range(200):\n",
    "    rbm.train()\n",
    "    train_recon_error = 0  # RMSE reconstruction error initialized to 0 at the beginning of training\n",
    "    s = 0\n",
    "    \n",
    "    for user_id in tqdm(range(0, shape[0] - batch_size, batch_size)):\n",
    "        training_sample = train_matrix[user_id : user_id + batch_size]\n",
    "        training_sample2 = train_matrix[user_id : user_id + batch_size]\n",
    "        # print(training_sample)\n",
    "        v0 = convert_sparse_matrix_to_sparse_tensor(training_sample)\n",
    "        # print(v0.coalesce().indices())\n",
    "        vk = convert_sparse_matrix_to_sparse_tensor(training_sample2)\n",
    "\n",
    "        v0 = v0.to_dense()\n",
    "        vk = vk.to_dense()\n",
    "        v0 = v0.sub(1)\n",
    "        vk = vk.sub(1)\n",
    "        \n",
    "        ph0, _ = rbm.sample_h(v0)   \n",
    "\n",
    "        # Third for loop - perform contrastive divergence\n",
    "        for k in range(10):\n",
    "            _, hk = rbm.sample_h(vk)\n",
    "            _, vk = rbm.sample_v(hk)\n",
    "\n",
    "            # We don't want to learn when there is no rating by the user, and there is no update when rating = -1\n",
    "            # Remove indices from vk vector that are not in the v0 vector => get sparse tensor again\n",
    "            vk[v0 < 0] = v0[v0 < 0]\n",
    "            vksparse = vk.to_sparse()\n",
    "            # print(\"v0\", v0)\n",
    "            # print(\"v0\", v0.add(1).to_sparse())\n",
    "            # print(\"vk\", vk.add(1).to_sparse())\n",
    "            \n",
    "            # print(k)\n",
    "\n",
    "        phk, _ = rbm.sample_h(vk)\n",
    "\n",
    "\n",
    "        rbm.train_model(v0, vk, ph0, phk)\n",
    "        \n",
    "        train_recon_error += torch.sqrt(torch.mean((v0[v0 > 0] - vk[v0 > 0])**2))\n",
    "        s += 1\n",
    "        \n",
    "        # print((torch.mm(v0.t(), ph0) - torch.mm(vk.t(), phk)).t().shape)\n",
    "        # print(torch.sum((-vk + v0), 0).shape)\n",
    "        # print(torch.sum((ph0 - phk), 0).shape)\n",
    "        \n",
    "    train_errors.append(train_recon_error / s)\n",
    "\n",
    "    # print('calculating test scores')\n",
    "    # rbm.eval()\n",
    "    # test_errors.append(score_model(rbm))\n",
    "\n",
    "    print('finished epoch', epoch)    \n",
    "    \n",
    "import matplotlib.pyplot as plt\n",
    "# Plot the RMSE reconstruction error with respect to increasing number of epochs\n",
    "plt.plot(torch.Tensor(train_errors, device='cpu'), label=\"train\")\n",
    "plt.plot(torch.Tensor(test_errors, device='cpu'), label=\"test\")\n",
    "plt.ylabel('Error')\n",
    "plt.xlabel('Epoch')\n",
    "plt.savefig('big.jpg')\n",
    "\n",
    "# Evaluate the RBM on test set\n",
    "# test_recon_error = score_model(rbm)\n",
    "# print(\"Final error\", test_recon_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(train_errors)\n",
    "display(test_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = steam_reviews_df_small[\"user_id\"].value_counts(dropna=False)\n",
    "display(s.loc[s < 2])\n",
    "display(s.loc[s >= 2])\n",
    "display(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_errors"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ac59ebe37160ed0dfa835113d9b8498d9f09ceb179beaac4002f036b9467c963"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Restricted Boltzmann Machine Defintion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Import PyTorch library\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "device = torch.device('cpu')\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# https://github.com/khanhnamle1994/MetaRec/blob/b5e36cb579a88b32cdfb728f35f645d76b24ad95/Boltzmann-Machines-Experiments/RBM-CF-PyTorch/rbm.py#L23\n",
    "# Create the Restricted Boltzmann Machine architecture\n",
    "class RBM(nn.Module):\n",
    "    def __init__(self, n_vis, n_hid):\n",
    "        \"\"\"\n",
    "        Initialize the parameters (weights and biases) we optimize during the training process\n",
    "        :param n_vis: number of visible units\n",
    "        :param n_hid: number of hidden units\n",
    "        \"\"\"\n",
    "        self.i = 0\n",
    "\n",
    "        # Weights used for the probability of the visible units given the hidden units\n",
    "        super().__init__()\n",
    "        self.W = torch.zeros(n_hid, n_vis, device=device)  # torch.rand: random normal distribution mean = 0, variance = 1\n",
    "\n",
    "        # Bias probability of the visible units is activated, given the value of the hidden units (p_v_given_h)\n",
    "        self.v_bias = torch.zeros(1, n_vis, device=device)  # fake dimension for the batch = 1\n",
    "\n",
    "        # Bias probability of the hidden units is activated, given the value of the visible units (p_h_given_v)\n",
    "        self.h_bias = torch.zeros(1, n_hid, device=device)  # fake dimension for the batch = 1\n",
    "    \n",
    "    def lr(self):\n",
    "        return 0.02\n",
    "\n",
    "    def sample_h(self, x):\n",
    "        \"\"\"\n",
    "        Sample the hidden units\n",
    "        :param x: the dataset\n",
    "        \"\"\"\n",
    "\n",
    "        # Probability h is activated given that the value v is sigmoid(Wx + a)\n",
    "        # torch.mm make the product of 2 tensors\n",
    "        # W.t() take the transpose because W is used for the p_v_given_h\n",
    "        wx = torch.mm(x, self.W.t())\n",
    "        # print(wx.shape)\n",
    "\n",
    "        # Expand the mini-batch\n",
    "        activation = wx + self.h_bias.expand_as(wx)\n",
    "        # print(activation.shape)\n",
    "\n",
    "        # Calculate the probability p_h_given_v\n",
    "        p_h_given_v = torch.sigmoid(activation)\n",
    "\n",
    "        # print(\"h sparse\", p_h_given_v.is_sparse, torch.bernoulli(p_h_given_v).is_sparse)\n",
    "\n",
    "        # Construct a Bernoulli RBM to predict whether an user loves the movie or not (0 or 1)\n",
    "        # This corresponds to whether the n_hid is activated or not activated\n",
    "        return p_h_given_v, torch.bernoulli(p_h_given_v)\n",
    "\n",
    "    def sample_v(self, y):\n",
    "        \"\"\"\n",
    "        Sample the visible units\n",
    "        :param y: the dataset\n",
    "        \"\"\"\n",
    "\n",
    "        # Probability v is activated given that the value h is sigmoid(Wx + a)\n",
    "        wy = torch.mm(y, self.W)\n",
    "\n",
    "        # Expand the mini-batch\n",
    "        activation = wy + self.v_bias.expand_as(wy)\n",
    "\n",
    "        # Calculate the probability p_v_given_h\n",
    "        p_v_given_h = torch.sigmoid(activation)\n",
    "\n",
    "        # print(\"v sparse\", p_v_given_h.is_sparse, torch.bernoulli(p_v_given_h).is_sparse)\n",
    "\n",
    "        # Construct a Bernoulli RBM to predict whether an user loves the movie or not (0 or 1)\n",
    "        # This corresponds to whether the n_vis is activated or not activated\n",
    "        return p_v_given_h, torch.bernoulli(p_v_given_h)\n",
    "\n",
    "    def train_model(self, v0, vk, ph0, phk):\n",
    "        \"\"\"\n",
    "        Perform contrastive divergence algorithm to optimize the weights that minimize the energy\n",
    "        This maximizes the log-likelihood of the model\n",
    "        \"\"\"\n",
    "\n",
    "        w_extra = (torch.mm(v0.t(), ph0) - torch.mm(vk.t(), phk)).t()\n",
    "        v_extra = torch.sum((v0 - vk), 0)\n",
    "        h_extra = torch.sum((ph0 - phk), 0)\n",
    "\n",
    "        # if self.i % 45 == 0:\n",
    "            # print(torch.max(w_extra), torch.max(v_extra), torch.max(h_extra), flush=True)\n",
    "\n",
    "        # Approximate the gradients with the CD algorithm\n",
    "        # TODO learning rate toevoegen\n",
    "        self.W += self.lr() * w_extra\n",
    "\n",
    "        # Add (difference, 0) for the tensor of 2 dimensions\n",
    "        self.v_bias += self.lr() * v_extra\n",
    "        self.h_bias += self.lr() * h_extra\n",
    "        self.i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "cuda = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "import gzip\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "import math\n",
    "tqdm.pandas() #for progres_apply etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "#read file line-by-line and parse json, returns dataframe\n",
    "def parse_json(filename_gzipped_python_json, read_max=-1):\n",
    "  #read gzipped content\n",
    "  f=gzip.open(filename_gzipped_python_json,'r')\n",
    "  \n",
    "  #parse json\n",
    "  parse_data = []\n",
    "  for line in tqdm(f): #tqdm is for showing progress bar, always good when processing large amounts of data\n",
    "    line = line.decode('utf-8')\n",
    "    line = line.replace('true','True') #difference json/python\n",
    "    line = line.replace('false','False')\n",
    "    parsed_result = eval(line) #load python nested datastructure\n",
    "    # print(filename_gzipped_python_json == steam_path + steam_reviews and 'user_id' not in parsed_result)\n",
    "    # break\n",
    "    if filename_gzipped_python_json == steam_path + steam_reviews and 'user_id' not in parsed_result:\n",
    "      continue\n",
    "      \n",
    "    parse_data.append(parsed_result)\n",
    "    if read_max !=-1 and len(parse_data) > read_max:\n",
    "      print(f'Break reading after {read_max} records')\n",
    "      break\n",
    "  print(f\"Reading {len(parse_data)} rows.\")\n",
    "\n",
    "  #create dataframe\n",
    "  df= pd.DataFrame.from_dict(parse_data)\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "steam_path = './data/'\n",
    "metadata_games = 'steam_games.json.gz' \n",
    "user_items = 'australian_users_items.json.gz'\n",
    "user_reviews = 'australian_user_reviews.json.gz'\n",
    "game_bundles = 'bundle_data.json.gz'\n",
    "steam_reviews= 'steam_reviews.json.gz'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Australien Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- australian_user_reviews.json.gz-----\n",
      "Size of file is 6.940139MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25799it [00:01, 19842.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 25799 rows.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# for dataset in [metadata_games, user_items, user_reviews, game_bundles, steam_reviews]:\n",
    "for dataset in [user_reviews]:\n",
    "  print(f\"----- {dataset}-----\")\n",
    "  size = os.path.getsize(steam_path + dataset) \n",
    "  print(f'Size of file is {size / 1000000}MB')\n",
    "  df_metadata = parse_json(steam_path + dataset)\n",
    "  pd.set_option('display.max_colwidth', None)\n",
    "  # display(df_metadata.head(5))\n",
    "#   display(df_metadata.describe(include='all'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25799it [00:01, 20071.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 25799 rows.\n"
     ]
    }
   ],
   "source": [
    "user_reviews_df = parse_json(steam_path + user_reviews)\n",
    "user_reviews_df = user_reviews_df.drop_duplicates(subset='user_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "user_reviews_df_exploded = user_reviews_df.explode('reviews')\n",
    "user_reviews_df_exploded = user_reviews_df_exploded.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def func(x):\n",
    "    return x['recommend'], x[\"item_id\"]\n",
    "\n",
    "user_reviews_df_exploded['recommended'], user_reviews_df_exploded[\"item_id\"] = zip(\n",
    "    *user_reviews_df_exploded['reviews'].map(func)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "user_reviews_df_exploded.reset_index()\n",
    "\n",
    "\n",
    "user_reviews_df_exploded = user_reviews_df_exploded[['user_id', 'item_id', 'recommended']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24                         [False, True]\n",
       "26       [True, True, True, False, True]\n",
       "36                         [True, False]\n",
       "60             [False, True, True, True]\n",
       "71                         [False, True]\n",
       "                      ...               \n",
       "25758    [True, True, True, False, True]\n",
       "25761                      [False, True]\n",
       "25764                [True, True, False]\n",
       "25768    [True, True, False, True, True]\n",
       "25785                [True, True, False]\n",
       "Length: 3684, dtype: object"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enkeltrue = user_reviews_df[['reviews']].apply(lambda x: [elem['recommend'] for elem in x['reviews']], axis=1)\n",
    "enkeltrue.loc[enkeltrue.map(set).map(len) > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 58430/58430 [00:00<00:00, 1327655.10it/s]\n"
     ]
    }
   ],
   "source": [
    "dct = {}\n",
    "def map_to_consecutive_id(uuid):\n",
    "  if uuid in dct:\n",
    "    return dct[uuid]\n",
    "  else:\n",
    "    id = len(dct)\n",
    "    dct[uuid] = id\n",
    "    return id\n",
    "user_reviews_df_exploded['item_id_int'] = user_reviews_df_exploded['item_id'].progress_apply(map_to_consecutive_id)\n",
    "user_reviews_df_exploded.dtypes\n",
    "f = open(\"item_dct.json\", 'w')\n",
    "json.dump(dct, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 58430/58430 [00:00<00:00, 1269960.58it/s]\n"
     ]
    }
   ],
   "source": [
    "dct = {}\n",
    "user_reviews_df_exploded['user_id_int'] = user_reviews_df_exploded['user_id'].progress_apply(map_to_consecutive_id)\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_df, test_df = train_test_split(user_reviews_df_exploded, test_size=0.2)\n",
    "\n",
    "\n",
    "test_df_grouped = test_df.groupby('user_id_int').agg(list)\n",
    "test_df_grouped = test_df_grouped.reset_index()\n",
    "\n",
    "train_df_grouped = train_df.groupby('user_id_int').agg(list)\n",
    "train_df_grouped = train_df_grouped.reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "#Create scipy csr matrix\n",
    "def get_sparse_matrix(df):\n",
    "    shape = (user_reviews_df_exploded['user_id_int'].max() + 1, user_reviews_df_exploded['item_id_int'].max() + 1)\n",
    "    \n",
    "    user_ids = []\n",
    "    item_ids = []\n",
    "    values = []\n",
    "    for idx, row in df.iterrows():\n",
    "        items = row['item_id_int']\n",
    "        user = row['user_id_int']\n",
    "    \n",
    "        recommended = row['recommended']\n",
    "        user_ids.extend([user] * len(items))\n",
    "        item_ids.extend(items)\n",
    "        values.extend([2 if recommended[i] else 1 for i in range(len(items))])\n",
    "    #create csr matrix\n",
    "    # values = np.ones(len(user_ids))\n",
    "    matrix = scipy.sparse.csr_matrix((values, (user_ids, item_ids)), shape=shape, dtype=np.int32)\n",
    "    return matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<25457x3682 sparse matrix of type '<class 'numpy.intc'>'\n",
       "\twith 46744 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_matrix = get_sparse_matrix(test_df_grouped)\n",
    "\n",
    "train_matrix = get_sparse_matrix(train_df_grouped)\n",
    "train_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x180818d3bd0>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------\n",
      "start training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [05:36<00:00,  3.36s/it]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def score_model(rbm, batch_size):\n",
    "    test_recon_error = 0  # RMSE reconstruction error initialized to 0 at the beginning of training\n",
    "    s = 0  # a counter (float type) \n",
    "    # for loop - go through every single user\n",
    "    for id_user in range(0, user_reviews_df_exploded['user_id_int'].max() + 1 - batch_size, batch_size):\n",
    "        v = train_matrix[id_user:id_user + batch_size]  # training set inputs are used to activate neurons of my RBM\n",
    "        vt = test_matrix[id_user:id_user + batch_size]  # target\n",
    "        # v = convert_sparse_matrix_to_sparse_tensor(training_sample)\n",
    "        # vt = convert_sparse_matrix_to_sparse_tensor(training_sample2)\n",
    "        v = v.todense()\n",
    "        vt = vt.todense()\n",
    "\n",
    "        # v = v.to_dense()\n",
    "        # vt = vt.to_dense()\n",
    "        v = v - 1\n",
    "        vt = vt - 1\n",
    "        v = torch.Tensor(v)\n",
    "        vt = torch.Tensor(vt)\n",
    "        if torch.cuda.is_available():\n",
    "            v = v.cuda()\n",
    "            vt = vt.cuda()\n",
    "        if len(vt[vt > -1]) > 0:\n",
    "            _, h = rbm.sample_h(v)\n",
    "            _, v = rbm.sample_v(h)\n",
    "\n",
    "            # Update test RMSE reconstruction error\n",
    "            test_recon_error += torch.sqrt(torch.mean((vt[vt > -1] - v[vt > -1])**2)) * len(vt > -1)\n",
    "            s += len(vt > -1) \n",
    "\n",
    "    return test_recon_error / s\n",
    "\n",
    "print('-------')\n",
    "n_vis = user_reviews_df_exploded['item_id_int'].max() + 1\n",
    "n_hidden = 1024\n",
    "batch_size = 1024\n",
    "epochs = 100\n",
    "train_errors = []\n",
    "test_errors = []\n",
    "rbm = RBM(n_vis, n_hidden)\n",
    "\n",
    "# https://stackoverflow.com/questions/40896157/scipy-sparse-csr-matrix-to-tensorflow-sparsetensor-mini-batch-gradient-descent\n",
    "def convert_sparse_matrix_to_sparse_tensor(X):\n",
    "    coo = X.tocoo()\n",
    "\n",
    "    values = coo.data\n",
    "    indices = np.vstack((coo.row, coo.col))\n",
    "\n",
    "    i = torch.LongTensor(indices)\n",
    "    v = torch.FloatTensor(values)\n",
    "    # print(values)\n",
    "    # print(\"values\", v)\n",
    "    shape = coo.shape\n",
    "    tensor = torch.sparse.FloatTensor(i, v, torch.Size(shape)) \n",
    "    if torch.cuda.is_available():\n",
    "        tensor = tensor.cuda()\n",
    "\n",
    "    return tensor \n",
    "\n",
    "print(\"start training\")\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    rbm.train()\n",
    "    train_recon_error = 0  # RMSE reconstruction error initialized to 0 at the beginning of training\n",
    "    s = 0\n",
    "    \n",
    "    for user_id in range(0, user_reviews_df_exploded['user_id_int'].max() + 1 - batch_size, batch_size):\n",
    "        training_sample = train_matrix[user_id : user_id + batch_size]\n",
    "        training_sample2 = train_matrix[user_id : user_id + batch_size]\n",
    "        # print(training_sample)\n",
    "        v0 = convert_sparse_matrix_to_sparse_tensor(training_sample)\n",
    "        # print(v0.coalesce().indices())\n",
    "        vk = convert_sparse_matrix_to_sparse_tensor(training_sample2)\n",
    "\n",
    "        v0 = v0.to_dense()\n",
    "        vk = vk.to_dense()\n",
    "        v0 = v0.sub(1)\n",
    "        vk = vk.sub(1)\n",
    "        \n",
    "        ph0, _ = rbm.sample_h(v0)   \n",
    "\n",
    "        # Third for loop - perform contrastive divergence\n",
    "        # TODO misschien is iets lager proberen?\n",
    "        for k in range(10):\n",
    "            _, hk = rbm.sample_h(vk)\n",
    "            _, vk = rbm.sample_v(hk)\n",
    "\n",
    "            # We don't want to learn when there is no rating by the user, and there is no update when rating = -1\n",
    "            # Remove indices from vk vector that are not in the v0 vector => get sparse tensor again\n",
    "            vk[v0 < 0] = v0[v0 < 0]\n",
    "            vksparse = vk.to_sparse()\n",
    "            # print(\"v0\", v0)\n",
    "            # print(\"v0\", v0.add(1).to_sparse())\n",
    "            # print(\"vk\", vk.add(1).to_sparse())\n",
    "            \n",
    "            # print(k)\n",
    "\n",
    "        phk, _ = rbm.sample_h(vk)\n",
    "\n",
    "\n",
    "        rbm.train_model(v0, vk, ph0, phk)\n",
    "        \n",
    "        train_recon_error += torch.sqrt(torch.mean((v0[v0 > -1] - vk[v0 > -1])**2)) * len(v0 > -1)\n",
    "        s += len(v0 > -1)\n",
    "        \n",
    "        # print((torch.mm(v0.t(), ph0) - torch.mm(vk.t(), phk)).t().shape)\n",
    "        # print(torch.sum((-vk + v0), 0).shape)\n",
    "        # print(torch.sum((ph0 - phk), 0).shape)\n",
    "        \n",
    "    train_errors.append(train_recon_error / s)\n",
    "\n",
    "    # print('calculating test scores')\n",
    "    rbm.eval()\n",
    "    test_errors.append(score_model(rbm, batch_size))\n",
    "\n",
    "    # print('finished epoch', epoch)    \n",
    "    \n",
    "import matplotlib.pyplot as plt\n",
    "# Plot the RMSE reconstruction error with respect to increasing number of epochs\n",
    "plt.plot(torch.Tensor(train_errors, device='cpu'), label=\"train\")\n",
    "plt.plot(torch.Tensor(test_errors, device='cpu'), label=\"test\")\n",
    "plt.ylabel('Error')\n",
    "plt.xlabel('Epoch')\n",
    "plt.savefig(f'test0-{batch_size}-{epochs}.jpg')\n",
    "\n",
    "# Evaluate the RBM on test set\n",
    "# test_recon_error = score_model(rbm)\n",
    "# print(\"Final error\", test_recon_error)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(torch.Tensor(train_errors, device='cpu'), label=\"train\")\n",
    "plt.plot(torch.Tensor(test_errors, device='cpu'), label=\"test\")\n",
    "plt.ylabel('Error')\n",
    "plt.xlabel('Epoch')\n",
    "plt.savefig('errors.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# torch.save(rbm.state_dict(), \"./network\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true,
     "name": "#%% load model\n"
    }
   },
   "outputs": [],
   "source": [
    "rbm = RBM(n_vis, n_hidden)\n",
    "rbm.load_state_dict(torch.load(\"./network\"))\n",
    "rbm.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Full Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7793069it [03:55, 33126.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 3176223 rows.\n"
     ]
    }
   ],
   "source": [
    "steam_reviews_df = parse_json(steam_path + steam_reviews)\n",
    "steam_reviews_df_small = steam_reviews_df[['user_id', 'product_id', 'recommended', 'date']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "steam_reviews_df_cleaned = steam_reviews_df_small.dropna(axis=0, subset=['user_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76561198011965365    1254\n",
       "76561198094803808     900\n",
       "76561197969749884     750\n",
       "76561198094321628     669\n",
       "76561198073092169     549\n",
       "                     ... \n",
       "76561198345086561       1\n",
       "76561198054491833       1\n",
       "76561198095690287       1\n",
       "76561198301658414       1\n",
       "76561198089897928       1\n",
       "Name: user_id, Length: 1485611, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steam_reviews_df_cleaned.head(5)\n",
    "steam_reviews_df[\"user_id\"].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3176223/3176223 [00:02<00:00, 1579855.53it/s]\n"
     ]
    }
   ],
   "source": [
    "dct = {}\n",
    "def map_to_consecutive_id(uuid):\n",
    "  if uuid in dct:\n",
    "    return dct[uuid]\n",
    "  else:\n",
    "    id = len(dct)\n",
    "    dct[uuid] = id\n",
    "    return id\n",
    "steam_reviews_df_cleaned['product_id_int'] = steam_reviews_df_cleaned['product_id'].progress_apply(map_to_consecutive_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# train_df, test_df = train_test_split(steam_reviews_df_cleaned, test_size=0.2)\n",
    "\n",
    "\n",
    "# test_df_grouped = test_df.groupby('user_id_int').agg(list)\n",
    "# test_df_grouped = test_df_grouped.reset_index()\n",
    "\n",
    "# train_df_grouped = train_df.groupby('user_id_int').agg(list)\n",
    "# train_df_grouped = train_df_grouped.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Date Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id                   object\n",
       "product_id                object\n",
       "recommended                 bool\n",
       "date              datetime64[ns]\n",
       "product_id_int             int64\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>recommended</th>\n",
       "      <th>date</th>\n",
       "      <th>product_id_int</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>76561198007483075</td>\n",
       "      <td>35140</td>\n",
       "      <td>True</td>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>76561197970402776</td>\n",
       "      <td>707610</td>\n",
       "      <td>True</td>\n",
       "      <td>2017-10-16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>76561198060686749</td>\n",
       "      <td>328100</td>\n",
       "      <td>True</td>\n",
       "      <td>2017-06-23</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>76561198023491401</td>\n",
       "      <td>35140</td>\n",
       "      <td>True</td>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>76561198115331805</td>\n",
       "      <td>35140</td>\n",
       "      <td>True</td>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             user_id product_id  recommended       date  product_id_int\n",
       "0  76561198007483075      35140         True 2018-01-04               0\n",
       "1  76561197970402776     707610         True 2017-10-16               1\n",
       "2  76561198060686749     328100         True 2017-06-23               2\n",
       "3  76561198023491401      35140         True 2018-01-03               0\n",
       "4  76561198115331805      35140         True 2018-01-03               0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "steam_reviews_df_cleaned[\"date\"] = pd.to_datetime(steam_reviews_df_cleaned[\"date\"])\n",
    "display(steam_reviews_df_cleaned.dtypes)\n",
    "display(steam_reviews_df_cleaned.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id_int</th>\n",
       "      <th>recommended</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>76561197960265806</th>\n",
       "      <td>[14313]</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[2017-12-20 00:00:00]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76561197960266010</th>\n",
       "      <td>[9722]</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[2017-11-27 00:00:00]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76561197960266146</th>\n",
       "      <td>[597]</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[2017-11-04 00:00:00]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76561197960266225</th>\n",
       "      <td>[1622]</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[2017-06-07 00:00:00]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76561197960266375</th>\n",
       "      <td>[3716]</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[2017-09-13 00:00:00]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  product_id_int recommended                   date\n",
       "user_id                                                            \n",
       "76561197960265806        [14313]      [True]  [2017-12-20 00:00:00]\n",
       "76561197960266010         [9722]      [True]  [2017-11-27 00:00:00]\n",
       "76561197960266146          [597]      [True]  [2017-11-04 00:00:00]\n",
       "76561197960266225         [1622]      [True]  [2017-06-07 00:00:00]\n",
       "76561197960266375         [3716]      [True]  [2017-09-13 00:00:00]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id_int</th>\n",
       "      <th>recommended</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>76561197960266546</th>\n",
       "      <td>[2678, 2678]</td>\n",
       "      <td>[True, True]</td>\n",
       "      <td>[2016-11-25 00:00:00, 2016-11-25 00:00:00]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76561197960266564</th>\n",
       "      <td>[7259, 7259]</td>\n",
       "      <td>[True, True]</td>\n",
       "      <td>[2016-08-14 00:00:00, 2016-08-14 00:00:00]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76561197960267022</th>\n",
       "      <td>[7779, 13382]</td>\n",
       "      <td>[True, True]</td>\n",
       "      <td>[2015-09-29 00:00:00, 2015-04-16 00:00:00]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76561197960267615</th>\n",
       "      <td>[1428, 2098, 2545, 2643, 2633, 3052, 3150, 3979, 3979, 5255, 5797, 5747, 5884, 6832, 6500, 6956, 7122, 7102, 7352, 7469, 7931, 9757, 9911, 10291, 11006, 11309, 11432, 11736, 12754, 12703, 12755, 13323, 13215, 13544, 14085, 14055]</td>\n",
       "      <td>[True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True]</td>\n",
       "      <td>[2012-11-06 00:00:00, 2011-11-30 00:00:00, 2011-07-16 00:00:00, 2011-11-30 00:00:00, 2012-04-04 00:00:00, 2011-07-06 00:00:00, 2011-11-30 00:00:00, 2010-12-10 00:00:00, 2010-12-10 00:00:00, 2011-11-30 00:00:00, 2010-12-10 00:00:00, 2011-11-30 00:00:00, 2013-01-09 00:00:00, 2011-11-30 00:00:00, 2013-10-30 00:00:00, 2011-11-30 00:00:00, 2011-11-30 00:00:00, 2011-11-30 00:00:00, 2011-11-30 00:00:00, 2011-11-30 00:00:00, 2011-11-30 00:00:00, 2010-12-10 00:00:00, 2011-09-13 00:00:00, 2010-12-10 00:00:00, 2011-11-30 00:00:00, 2012-11-05 00:00:00, 2011-11-30 00:00:00, 2011-07-20 00:00:00, 2012-12-14 00:00:00, 2011-11-30 00:00:00, 2011-11-30 00:00:00, 2010-12-10 00:00:00, 2011-11-30 00:00:00, 2012-07-14 00:00:00, 2011-07-30 00:00:00, 2011-11-30 00:00:00]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76561197960268226</th>\n",
       "      <td>[9485, 13462]</td>\n",
       "      <td>[True, True]</td>\n",
       "      <td>[2015-06-01 00:00:00, 2016-11-28 00:00:00]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                          product_id_int  \\\n",
       "user_id                                                                                                                                                                                                                                                    \n",
       "76561197960266546                                                                                                                                                                                                                           [2678, 2678]   \n",
       "76561197960266564                                                                                                                                                                                                                           [7259, 7259]   \n",
       "76561197960267022                                                                                                                                                                                                                          [7779, 13382]   \n",
       "76561197960267615  [1428, 2098, 2545, 2643, 2633, 3052, 3150, 3979, 3979, 5255, 5797, 5747, 5884, 6832, 6500, 6956, 7122, 7102, 7352, 7469, 7931, 9757, 9911, 10291, 11006, 11309, 11432, 11736, 12754, 12703, 12755, 13323, 13215, 13544, 14085, 14055]   \n",
       "76561197960268226                                                                                                                                                                                                                          [9485, 13462]   \n",
       "\n",
       "                                                                                                                                                                                                                                recommended  \\\n",
       "user_id                                                                                                                                                                                                                                       \n",
       "76561197960266546                                                                                                                                                                                                              [True, True]   \n",
       "76561197960266564                                                                                                                                                                                                              [True, True]   \n",
       "76561197960267022                                                                                                                                                                                                              [True, True]   \n",
       "76561197960267615  [True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True]   \n",
       "76561197960268226                                                                                                                                                                                                              [True, True]   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   date  \n",
       "user_id                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "76561197960266546                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            [2016-11-25 00:00:00, 2016-11-25 00:00:00]  \n",
       "76561197960266564                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            [2016-08-14 00:00:00, 2016-08-14 00:00:00]  \n",
       "76561197960267022                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            [2015-09-29 00:00:00, 2015-04-16 00:00:00]  \n",
       "76561197960267615  [2012-11-06 00:00:00, 2011-11-30 00:00:00, 2011-07-16 00:00:00, 2011-11-30 00:00:00, 2012-04-04 00:00:00, 2011-07-06 00:00:00, 2011-11-30 00:00:00, 2010-12-10 00:00:00, 2010-12-10 00:00:00, 2011-11-30 00:00:00, 2010-12-10 00:00:00, 2011-11-30 00:00:00, 2013-01-09 00:00:00, 2011-11-30 00:00:00, 2013-10-30 00:00:00, 2011-11-30 00:00:00, 2011-11-30 00:00:00, 2011-11-30 00:00:00, 2011-11-30 00:00:00, 2011-11-30 00:00:00, 2011-11-30 00:00:00, 2010-12-10 00:00:00, 2011-09-13 00:00:00, 2010-12-10 00:00:00, 2011-11-30 00:00:00, 2012-11-05 00:00:00, 2011-11-30 00:00:00, 2011-07-20 00:00:00, 2012-12-14 00:00:00, 2011-11-30 00:00:00, 2011-11-30 00:00:00, 2010-12-10 00:00:00, 2011-11-30 00:00:00, 2012-07-14 00:00:00, 2011-07-30 00:00:00, 2011-11-30 00:00:00]  \n",
       "76561197960268226                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            [2015-06-01 00:00:00, 2016-11-28 00:00:00]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "steam_reviews_df_grouped = steam_reviews_df_cleaned.groupby(\"user_id\")[[\"product_id_int\", \"recommended\", \"date\"]].agg(list)\n",
    "display(steam_reviews_df_grouped.head(5))\n",
    "\n",
    "steam_reviews_df_grouped_smaller = steam_reviews_df_grouped[steam_reviews_df_grouped[\"recommended\"].map(len) > 1]\n",
    "display(steam_reviews_df_grouped_smaller.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 581343/581343 [00:00<00:00, 1062545.44it/s]\n"
     ]
    }
   ],
   "source": [
    "dct.clear()\n",
    "steam_reviews_df_grouped_smaller = steam_reviews_df_grouped_smaller.reset_index()\n",
    "steam_reviews_df_grouped_smaller[\"user_id_int\"] = steam_reviews_df_grouped_smaller[\"user_id\"].progress_apply(map_to_consecutive_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(581343, 5)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(1485611, 3)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "904268\n"
     ]
    }
   ],
   "source": [
    "display(steam_reviews_df_grouped_smaller.shape)\n",
    "display(steam_reviews_df_grouped.shape)\n",
    "print(steam_reviews_df_grouped.shape[0] - steam_reviews_df_grouped_smaller.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 581343/581343 [00:01<00:00, 424552.48it/s]\n",
      "100%|██████████| 581343/581343 [00:00<00:00, 1058674.83it/s]\n",
      "100%|██████████| 581343/581343 [00:00<00:00, 1060604.75it/s]\n",
      "100%|██████████| 581343/581343 [00:00<00:00, 1080321.69it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>product_id_int</th>\n",
       "      <th>recommended</th>\n",
       "      <th>date</th>\n",
       "      <th>user_id_int</th>\n",
       "      <th>product_history</th>\n",
       "      <th>product_future</th>\n",
       "      <th>recommended_history</th>\n",
       "      <th>recommended_future</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>76561197960266546</td>\n",
       "      <td>[2678, 2678]</td>\n",
       "      <td>[True, True]</td>\n",
       "      <td>[2016-11-25 00:00:00, 2016-11-25 00:00:00]</td>\n",
       "      <td>0</td>\n",
       "      <td>[2678]</td>\n",
       "      <td>[2678]</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>76561197960266564</td>\n",
       "      <td>[7259, 7259]</td>\n",
       "      <td>[True, True]</td>\n",
       "      <td>[2016-08-14 00:00:00, 2016-08-14 00:00:00]</td>\n",
       "      <td>1</td>\n",
       "      <td>[7259]</td>\n",
       "      <td>[7259]</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>76561197960267022</td>\n",
       "      <td>[7779, 13382]</td>\n",
       "      <td>[True, True]</td>\n",
       "      <td>[2015-09-29 00:00:00, 2015-04-16 00:00:00]</td>\n",
       "      <td>2</td>\n",
       "      <td>[7779]</td>\n",
       "      <td>[13382]</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>76561197960267615</td>\n",
       "      <td>[1428, 2098, 2545, 2643, 2633, 3052, 3150, 3979, 3979, 5255, 5797, 5747, 5884, 6832, 6500, 6956, 7122, 7102, 7352, 7469, 7931, 9757, 9911, 10291, 11006, 11309, 11432, 11736, 12754, 12703, 12755, 13323, 13215, 13544, 14085, 14055]</td>\n",
       "      <td>[True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True]</td>\n",
       "      <td>[2012-11-06 00:00:00, 2011-11-30 00:00:00, 2011-07-16 00:00:00, 2011-11-30 00:00:00, 2012-04-04 00:00:00, 2011-07-06 00:00:00, 2011-11-30 00:00:00, 2010-12-10 00:00:00, 2010-12-10 00:00:00, 2011-11-30 00:00:00, 2010-12-10 00:00:00, 2011-11-30 00:00:00, 2013-01-09 00:00:00, 2011-11-30 00:00:00, 2013-10-30 00:00:00, 2011-11-30 00:00:00, 2011-11-30 00:00:00, 2011-11-30 00:00:00, 2011-11-30 00:00:00, 2011-11-30 00:00:00, 2011-11-30 00:00:00, 2010-12-10 00:00:00, 2011-09-13 00:00:00, 2010-12-10 00:00:00, 2011-11-30 00:00:00, 2012-11-05 00:00:00, 2011-11-30 00:00:00, 2011-07-20 00:00:00, 2012-12-14 00:00:00, 2011-11-30 00:00:00, 2011-11-30 00:00:00, 2010-12-10 00:00:00, 2011-11-30 00:00:00, 2012-07-14 00:00:00, 2011-07-30 00:00:00, 2011-11-30 00:00:00]</td>\n",
       "      <td>3</td>\n",
       "      <td>[1428, 2098, 2545, 2643, 2633, 3052, 3150, 3979, 3979, 5255, 5797, 5747, 5884, 6832, 6500, 6956, 7122, 7102, 7352, 7469, 7931, 9757, 9911, 10291, 11006, 11309, 11432, 11736]</td>\n",
       "      <td>[12754, 12703, 12755, 13323, 13215, 13544, 14085, 14055]</td>\n",
       "      <td>[True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True]</td>\n",
       "      <td>[True, True, True, True, True, True, True, True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>76561197960268226</td>\n",
       "      <td>[9485, 13462]</td>\n",
       "      <td>[True, True]</td>\n",
       "      <td>[2015-06-01 00:00:00, 2016-11-28 00:00:00]</td>\n",
       "      <td>4</td>\n",
       "      <td>[9485]</td>\n",
       "      <td>[13462]</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[True]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             user_id  \\\n",
       "0  76561197960266546   \n",
       "1  76561197960266564   \n",
       "2  76561197960267022   \n",
       "3  76561197960267615   \n",
       "4  76561197960268226   \n",
       "\n",
       "                                                                                                                                                                                                                          product_id_int  \\\n",
       "0                                                                                                                                                                                                                           [2678, 2678]   \n",
       "1                                                                                                                                                                                                                           [7259, 7259]   \n",
       "2                                                                                                                                                                                                                          [7779, 13382]   \n",
       "3  [1428, 2098, 2545, 2643, 2633, 3052, 3150, 3979, 3979, 5255, 5797, 5747, 5884, 6832, 6500, 6956, 7122, 7102, 7352, 7469, 7931, 9757, 9911, 10291, 11006, 11309, 11432, 11736, 12754, 12703, 12755, 13323, 13215, 13544, 14085, 14055]   \n",
       "4                                                                                                                                                                                                                          [9485, 13462]   \n",
       "\n",
       "                                                                                                                                                                                                                recommended  \\\n",
       "0                                                                                                                                                                                                              [True, True]   \n",
       "1                                                                                                                                                                                                              [True, True]   \n",
       "2                                                                                                                                                                                                              [True, True]   \n",
       "3  [True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True]   \n",
       "4                                                                                                                                                                                                              [True, True]   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   date  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            [2016-11-25 00:00:00, 2016-11-25 00:00:00]   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            [2016-08-14 00:00:00, 2016-08-14 00:00:00]   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            [2015-09-29 00:00:00, 2015-04-16 00:00:00]   \n",
       "3  [2012-11-06 00:00:00, 2011-11-30 00:00:00, 2011-07-16 00:00:00, 2011-11-30 00:00:00, 2012-04-04 00:00:00, 2011-07-06 00:00:00, 2011-11-30 00:00:00, 2010-12-10 00:00:00, 2010-12-10 00:00:00, 2011-11-30 00:00:00, 2010-12-10 00:00:00, 2011-11-30 00:00:00, 2013-01-09 00:00:00, 2011-11-30 00:00:00, 2013-10-30 00:00:00, 2011-11-30 00:00:00, 2011-11-30 00:00:00, 2011-11-30 00:00:00, 2011-11-30 00:00:00, 2011-11-30 00:00:00, 2011-11-30 00:00:00, 2010-12-10 00:00:00, 2011-09-13 00:00:00, 2010-12-10 00:00:00, 2011-11-30 00:00:00, 2012-11-05 00:00:00, 2011-11-30 00:00:00, 2011-07-20 00:00:00, 2012-12-14 00:00:00, 2011-11-30 00:00:00, 2011-11-30 00:00:00, 2010-12-10 00:00:00, 2011-11-30 00:00:00, 2012-07-14 00:00:00, 2011-07-30 00:00:00, 2011-11-30 00:00:00]   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            [2015-06-01 00:00:00, 2016-11-28 00:00:00]   \n",
       "\n",
       "   user_id_int  \\\n",
       "0            0   \n",
       "1            1   \n",
       "2            2   \n",
       "3            3   \n",
       "4            4   \n",
       "\n",
       "                                                                                                                                                                 product_history  \\\n",
       "0                                                                                                                                                                         [2678]   \n",
       "1                                                                                                                                                                         [7259]   \n",
       "2                                                                                                                                                                         [7779]   \n",
       "3  [1428, 2098, 2545, 2643, 2633, 3052, 3150, 3979, 3979, 5255, 5797, 5747, 5884, 6832, 6500, 6956, 7122, 7102, 7352, 7469, 7931, 9757, 9911, 10291, 11006, 11309, 11432, 11736]   \n",
       "4                                                                                                                                                                         [9485]   \n",
       "\n",
       "                                             product_future  \\\n",
       "0                                                    [2678]   \n",
       "1                                                    [7259]   \n",
       "2                                                   [13382]   \n",
       "3  [12754, 12703, 12755, 13323, 13215, 13544, 14085, 14055]   \n",
       "4                                                   [13462]   \n",
       "\n",
       "                                                                                                                                                        recommended_history  \\\n",
       "0                                                                                                                                                                    [True]   \n",
       "1                                                                                                                                                                    [True]   \n",
       "2                                                                                                                                                                    [True]   \n",
       "3  [True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True]   \n",
       "4                                                                                                                                                                    [True]   \n",
       "\n",
       "                                 recommended_future  \n",
       "0                                            [True]  \n",
       "1                                            [True]  \n",
       "2                                            [True]  \n",
       "3  [True, True, True, True, True, True, True, True]  \n",
       "4                                            [True]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "def split(items, train_percentage):\n",
    "    train_count = math.floor(len(items) * train_percentage)\n",
    "    return items[0:train_count], items[train_count:]\n",
    "\n",
    "train_percentage = 0.8\n",
    "steam_reviews_df_grouped_smaller[\"product_history\"] = steam_reviews_df_grouped_smaller[\"product_id_int\"].progress_apply(lambda items: split(items, train_percentage)[0])\n",
    "steam_reviews_df_grouped_smaller[\"product_future\"] = steam_reviews_df_grouped_smaller[\"product_id_int\"].progress_apply(lambda items: split(items, train_percentage)[1])\n",
    "steam_reviews_df_grouped_smaller[\"recommended_history\"] = steam_reviews_df_grouped_smaller[\"recommended\"].progress_apply(lambda items: split(items, train_percentage)[0])\n",
    "steam_reviews_df_grouped_smaller[\"recommended_future\"] = steam_reviews_df_grouped_smaller[\"recommended\"].progress_apply(lambda items: split(items, train_percentage)[1])\n",
    "display(steam_reviews_df_grouped_smaller.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2271955"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steam_reviews_df_grouped_smaller[\"recommended\"].map(len).describe()\n",
    "steam_reviews_df_grouped_smaller[\"recommended\"].map(len).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#Create scipy csr matrix\n",
    "def get_sparse_matrix(df, shape, recommended_col=\"recommended_history\", product_col=\"product_history\"):\n",
    "    user_ids = []\n",
    "    product_ids = []\n",
    "    values = []\n",
    "    for _, row in df.iterrows():\n",
    "        products = row[product_col]\n",
    "        user = row['user_id_int']\n",
    "    \n",
    "        recommended = row[recommended_col]\n",
    "        user_ids.extend([user] * len(products))\n",
    "        product_ids.extend(products)\n",
    "        values.extend([2 if recommended[i] else 1 for i in range(len(products))])\n",
    "    #create csr matrix\n",
    "    # values = np.ones(len(user_ids))\n",
    "    matrix = scipy.sparse.csr_matrix((values, (user_ids, product_ids)), shape=shape, dtype=np.int32)\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "steam_reviews_set = steam_reviews_df_grouped_smaller#.head(100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<581343x14513 sparse matrix of type '<class 'numpy.intc'>'\n",
       "\twith 1404885 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape = (steam_reviews_set.shape[0], steam_reviews_df_cleaned['product_id_int'].max() + 1)\n",
    "\n",
    "steam_reviews_set = steam_reviews_set.reset_index()\n",
    "train_matrix = get_sparse_matrix(steam_reviews_set, shape)\n",
    "test_matrix = get_sparse_matrix(steam_reviews_set, shape, recommended_col=\"recommended_future\", product_col=\"product_future\")\n",
    "train_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<581343x14513 sparse matrix of type '<class 'numpy.intc'>'\n",
       "\twith 708285 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------\n",
      "start training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 10/50 [25:58<1:43:44, 155.62s/it]"
     ]
    }
   ],
   "source": [
    "def score_model(rbm):\n",
    "    test_recon_error = 0  # RMSE reconstruction error initialized to 0 at the beginning of training\n",
    "    s = 0  # a counter (float type) \n",
    "    # for loop - go through every single user\n",
    "    for id_user in range(shape[0]):\n",
    "        v = train_matrix[id_user:id_user + 1]  # training set inputs are used to activate neurons of my RBM\n",
    "        vt = test_matrix[id_user:id_user + 1]  # target\n",
    "        # v = convert_sparse_matrix_to_sparse_tensor(training_sample)\n",
    "        # vt = convert_sparse_matrix_to_sparse_tensor(training_sample2)\n",
    "        v = v.todense()\n",
    "        vt = vt.todense()\n",
    "\n",
    "        # v = v.to_dense()\n",
    "        # vt = vt.to_dense()\n",
    "        v = v - 1\n",
    "        vt = vt - 1\n",
    "        v = torch.Tensor(v)\n",
    "        vt = torch.Tensor(vt)\n",
    "        if torch.cuda.is_available():\n",
    "            v = v.cuda()\n",
    "            vt = vt.cuda()\n",
    "        if len(vt[vt > -1]) > 0:\n",
    "            _, h = rbm.sample_h(v)\n",
    "            _, v = rbm.sample_v(h)\n",
    "\n",
    "            # Update test RMSE reconstruction error\n",
    "            test_recon_error += torch.sqrt(torch.mean((vt[vt > -1] - v[vt > -1])**2)) * len(vt > -1)\n",
    "            s += len(vt > -1)\n",
    "\n",
    "    return test_recon_error / s\n",
    "\n",
    "print('-------')\n",
    "n_vis = shape[1]\n",
    "n_hidden = 200\n",
    "batch_size = 2048 \n",
    "epochs = 50\n",
    "train_errors = []\n",
    "test_errors = []\n",
    "rbm = RBM(n_vis, n_hidden)\n",
    "\n",
    "# https://stackoverflow.com/questions/40896157/scipy-sparse-csr-matrix-to-tensorflow-sparsetensor-mini-batch-gradient-descent\n",
    "def convert_sparse_matrix_to_sparse_tensor(X):\n",
    "    coo = X.tocoo()\n",
    "\n",
    "    values = coo.data\n",
    "    indices = np.vstack((coo.row, coo.col))\n",
    "\n",
    "    i = torch.LongTensor(indices)\n",
    "    v = torch.FloatTensor(values)\n",
    "    if torch.cuda.is_available():\n",
    "        i = i.cuda()\n",
    "        v = v.cuda()\n",
    "    # print(values)\n",
    "    # print(\"values\", v)\n",
    "    shape = coo.shape\n",
    "    tensor = torch.sparse.FloatTensor(i, v, torch.Size(shape)) \n",
    "    if torch.cuda.is_available():\n",
    "        tensor = tensor.cuda()\n",
    "\n",
    "    return tensor \n",
    "\n",
    "print(\"start training\")\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    rbm.train()\n",
    "    train_recon_error = 0  # RMSE reconstruction error initialized to 0 at the beginning of training\n",
    "    s = 0\n",
    "    \n",
    "    for user_id in range(0, shape[0] - batch_size, batch_size):\n",
    "        training_sample = train_matrix[user_id : user_id + batch_size]\n",
    "        training_sample2 = train_matrix[user_id : user_id + batch_size]\n",
    "        # print(training_sample)\n",
    "        v0 = convert_sparse_matrix_to_sparse_tensor(training_sample)\n",
    "        # print(v0.coalesce().indices())\n",
    "        vk = convert_sparse_matrix_to_sparse_tensor(training_sample2)\n",
    "\n",
    "        v0 = v0.to_dense()\n",
    "        vk = vk.to_dense()\n",
    "        v0 = v0.sub(1)\n",
    "        vk = vk.sub(1)\n",
    "        \n",
    "        ph0, _ = rbm.sample_h(v0)   \n",
    "\n",
    "        # Third for loop - perform contrastive divergence\n",
    "        for k in range(10):\n",
    "            _, hk = rbm.sample_h(vk)\n",
    "            _, vk = rbm.sample_v(hk)\n",
    "\n",
    "            # We don't want to learn when there is no rating by the user, and there is no update when rating = -1\n",
    "            # Remove indices from vk vector that are not in the v0 vector => get sparse tensor again\n",
    "            vk[v0 < 0] = v0[v0 < 0]\n",
    "            vksparse = vk.to_sparse()\n",
    "            # print(\"v0\", v0)\n",
    "            # print(\"v0\", v0.add(1).to_sparse())\n",
    "            # print(\"vk\", vk.add(1).to_sparse())\n",
    "            \n",
    "            # print(k)\n",
    "\n",
    "        phk, _ = rbm.sample_h(vk)\n",
    "\n",
    "\n",
    "        rbm.train_model(v0, vk, ph0, phk)\n",
    "        \n",
    "        train_recon_error += torch.sqrt(torch.mean((v0[v0 > -1] - vk[v0 > -1])**2)) * len(v0 > -1)\n",
    "        s += len(v0 > -1) \n",
    "        \n",
    "        # print((torch.mm(v0.t(), ph0) - torch.mm(vk.t(), phk)).t().shape)\n",
    "        # print(torch.sum((-vk + v0), 0).shape)\n",
    "        # print(torch.sum((ph0 - phk), 0).shape)\n",
    "        \n",
    "    train_errors.append(train_recon_error / s)\n",
    "\n",
    "    # print('calculating test scores')\n",
    "    # rbm.eval()\n",
    "    # test_errors.append(score_model(rbm))\n",
    "\n",
    "    # print('finished epoch', epoch)    \n",
    "    \n",
    "import matplotlib.pyplot as plt\n",
    "# Plot the RMSE reconstruction error with respect to increasing number of epochs\n",
    "plt.plot(torch.Tensor(train_errors, device='cpu'), label=\"train\")\n",
    "plt.plot(torch.Tensor(test_errors, device='cpu'), label=\"test\")\n",
    "plt.ylabel('Error')\n",
    "plt.xlabel('Epoch')\n",
    "plt.savefig(f'datasubset-{n_hidden}-{batch_size}-{epochs}.jpg')\n",
    "\n",
    "# Evaluate the RBM on test set\n",
    "# test_recon_error = score_model(rbm)\n",
    "# print(\"Final error\", test_recon_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(0.8445, device='cuda:0'),\n",
       " tensor(0.7586, device='cuda:0'),\n",
       " tensor(0.7307, device='cuda:0'),\n",
       " tensor(0.7131, device='cuda:0'),\n",
       " tensor(0.7022, device='cuda:0'),\n",
       " tensor(0.6943, device='cuda:0'),\n",
       " tensor(0.6878, device='cuda:0'),\n",
       " tensor(0.6818, device='cuda:0'),\n",
       " tensor(0.6780, device='cuda:0'),\n",
       " tensor(0.6749, device='cuda:0'),\n",
       " tensor(0.6719, device='cuda:0'),\n",
       " tensor(0.6683, device='cuda:0'),\n",
       " tensor(0.6660, device='cuda:0'),\n",
       " tensor(0.6633, device='cuda:0'),\n",
       " tensor(0.6620, device='cuda:0'),\n",
       " tensor(0.6601, device='cuda:0'),\n",
       " tensor(0.6583, device='cuda:0'),\n",
       " tensor(0.6573, device='cuda:0'),\n",
       " tensor(0.6558, device='cuda:0'),\n",
       " tensor(0.6544, device='cuda:0')]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(train_errors)\n",
    "display(test_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76561198037833890    1\n",
       "76561197992194309    1\n",
       "76561198043292775    1\n",
       "76561198030442121    1\n",
       "76561197963870074    1\n",
       "                    ..\n",
       "76561198345086561    1\n",
       "76561198054491833    1\n",
       "76561198095690287    1\n",
       "76561198301658414    1\n",
       "76561198089897928    1\n",
       "Name: user_id, Length: 904268, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "76561198011965365    1254\n",
       "76561198094803808     900\n",
       "76561197969749884     750\n",
       "76561198094321628     669\n",
       "76561198073092169     549\n",
       "                     ... \n",
       "76561198098554655       2\n",
       "76561198044342349       2\n",
       "76561198122784122       2\n",
       "76561198076341138       2\n",
       "76561198102545130       2\n",
       "Name: user_id, Length: 581343, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "76561198011965365    1254\n",
       "76561198094803808     900\n",
       "76561197969749884     750\n",
       "76561198094321628     669\n",
       "76561198073092169     549\n",
       "                     ... \n",
       "76561198345086561       1\n",
       "76561198054491833       1\n",
       "76561198095690287       1\n",
       "76561198301658414       1\n",
       "76561198089897928       1\n",
       "Name: user_id, Length: 1485611, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "s = steam_reviews_df_small[\"user_id\"].value_counts(dropna=False)\n",
    "display(s.loc[s < 2])\n",
    "display(s.loc[s >= 2])\n",
    "display(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_errors"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ac59ebe37160ed0dfa835113d9b8498d9f09ceb179beaac4002f036b9467c963"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Restricted Boltzmann Machine Defintion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# https://github.com/khanhnamle1994/MetaRec/blob/b5e36cb579a88b32cdfb728f35f645d76b24ad95/Boltzmann-Machines-Experiments/RBM-CF-PyTorch/rbm.py#L23\n",
    "# Import PyTorch library\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Create the Restricted Boltzmann Machine architecture\n",
    "class RBM(nn.Module):\n",
    "    def __init__(self, n_vis, n_hid):\n",
    "        \"\"\"\n",
    "        Initialize the parameters (weights and biases) we optimize during the training process\n",
    "        :param n_vis: number of visible units\n",
    "        :param n_hid: number of hidden units\n",
    "        \"\"\"\n",
    "\n",
    "        # Weights used for the probability of the visible units given the hidden units\n",
    "        super().__init__()\n",
    "        self.W = torch.randn(n_hid, n_vis)  # torch.rand: random normal distribution mean = 0, variance = 1\n",
    "\n",
    "        # Bias probability of the visible units is activated, given the value of the hidden units (p_v_given_h)\n",
    "        self.v_bias = torch.randn(1, n_vis)  # fake dimension for the batch = 1\n",
    "\n",
    "        # Bias probability of the hidden units is activated, given the value of the visible units (p_h_given_v)\n",
    "        self.h_bias = torch.randn(1, n_hid)  # fake dimension for the batch = 1\n",
    "\n",
    "    def sample_h(self, x):\n",
    "        \"\"\"\n",
    "        Sample the hidden units\n",
    "        :param x: the dataset\n",
    "        \"\"\"\n",
    "\n",
    "        # Probability h is activated given that the value v is sigmoid(Wx + a)\n",
    "        # torch.mm make the product of 2 tensors\n",
    "        # W.t() take the transpose because W is used for the p_v_given_h\n",
    "        wx = torch.mm(x, self.W.t())\n",
    "        # print(wx.shape)\n",
    "\n",
    "        # Expand the mini-batch\n",
    "        activation = wx + self.h_bias.expand_as(wx)\n",
    "        # print(activation.shape)\n",
    "\n",
    "        # Calculate the probability p_h_given_v\n",
    "        p_h_given_v = torch.sigmoid(activation)\n",
    "\n",
    "        # print(\"h sparse\", p_h_given_v.is_sparse, torch.bernoulli(p_h_given_v).is_sparse)\n",
    "\n",
    "        # Construct a Bernoulli RBM to predict whether an user loves the movie or not (0 or 1)\n",
    "        # This corresponds to whether the n_hid is activated or not activated\n",
    "        return p_h_given_v, torch.bernoulli(p_h_given_v)\n",
    "\n",
    "    def sample_v(self, y):\n",
    "        \"\"\"\n",
    "        Sample the visible units\n",
    "        :param y: the dataset\n",
    "        \"\"\"\n",
    "\n",
    "        # Probability v is activated given that the value h is sigmoid(Wx + a)\n",
    "        wy = torch.mm(y, self.W)\n",
    "\n",
    "        # Expand the mini-batch\n",
    "        activation = wy + self.v_bias.expand_as(wy)\n",
    "\n",
    "        # Calculate the probability p_v_given_h\n",
    "        p_v_given_h = torch.sigmoid(activation)\n",
    "\n",
    "        # print(\"v sparse\", p_v_given_h.is_sparse, torch.bernoulli(p_v_given_h).is_sparse)\n",
    "\n",
    "        # Construct a Bernoulli RBM to predict whether an user loves the movie or not (0 or 1)\n",
    "        # This corresponds to whether the n_vis is activated or not activated\n",
    "        return p_v_given_h, torch.bernoulli(p_v_given_h)\n",
    "\n",
    "    def train_model(self, v0, vk, ph0, phk):\n",
    "        \"\"\"\n",
    "        Perform contrastive divergence algorithm to optimize the weights that minimize the energy\n",
    "        This maximizes the log-likelihood of the model\n",
    "        \"\"\"\n",
    "\n",
    "        # Approximate the gradients with the CD algorithm\n",
    "        self.W += (torch.mm(v0.t(), ph0) - torch.mm(vk.t(), phk)).t()\n",
    "\n",
    "        # Add (difference, 0) for the tensor of 2 dimensions\n",
    "        self.v_bias += torch.sum((v0 - vk), 0)\n",
    "        self.h_bias += torch.sum((ph0 - phk), 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "import gzip\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "import math\n",
    "tqdm.pandas() #for progres_apply etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "#read file line-by-line and parse json, returns dataframe\n",
    "def parse_json(filename_gzipped_python_json, read_max=-1):\n",
    "  #read gzipped content\n",
    "  f=gzip.open(filename_gzipped_python_json,'r')\n",
    "  \n",
    "  #parse json\n",
    "  parse_data = []\n",
    "  for line in tqdm(f): #tqdm is for showing progress bar, always good when processing large amounts of data\n",
    "    line = line.decode('utf-8')\n",
    "    line = line.replace('true','True') #difference json/python\n",
    "    line = line.replace('false','False')\n",
    "    parsed_result = eval(line) #load python nested datastructure\n",
    "    # print(filename_gzipped_python_json == steam_path + steam_reviews and 'user_id' not in parsed_result)\n",
    "    # break\n",
    "    if filename_gzipped_python_json == steam_path + steam_reviews and 'user_id' not in parsed_result:\n",
    "      continue\n",
    "      \n",
    "    parse_data.append(parsed_result)\n",
    "    if read_max !=-1 and len(parse_data) > read_max:\n",
    "      print(f'Break reading after {read_max} records')\n",
    "      break\n",
    "  print(f\"Reading {len(parse_data)} rows.\")\n",
    "\n",
    "  #create dataframe\n",
    "  df= pd.DataFrame.from_dict(parse_data)\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "steam_path = './data/'\n",
    "metadata_games = 'steam_games.json.gz' \n",
    "user_items = 'australian_users_items.json.gz'\n",
    "user_reviews = 'australian_user_reviews.json.gz'\n",
    "game_bundles = 'bundle_data.json.gz'\n",
    "steam_reviews= 'steam_reviews.json.gz'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Australien Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# for dataset in [metadata_games, user_items, user_reviews, game_bundles, steam_reviews]:\n",
    "for dataset in [user_reviews]:\n",
    "  print(f\"----- {dataset}-----\")\n",
    "  size = os.path.getsize(steam_path + dataset) \n",
    "  print(f'Size of file is {size / 1000000}MB')\n",
    "  df_metadata = parse_json(steam_path + dataset)\n",
    "  pd.set_option('display.max_colwidth', None)\n",
    "  # display(df_metadata.head(5))\n",
    "#   display(df_metadata.describe(include='all'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r0it [00:00, ?it/s]\n",
      "\r837it [00:00, 8309.33it/s]\n",
      "\r1797it [00:00, 8641.53it/s]\n",
      "\r2723it [00:00, 8799.78it/s]\n",
      "\r3501it [00:00, 8446.66it/s]\n",
      "\r4485it [00:00, 8813.54it/s]\n",
      "\r5456it [00:00, 9046.14it/s]\n",
      "\r6646it [00:00, 9729.97it/s]\n",
      "\r7636it [00:00, 9773.40it/s]\n",
      "\r8615it [00:00, 9771.05it/s]\n",
      "\r9569it [00:01, 7997.07it/s]\n",
      "\r10412it [00:01, 8120.52it/s]\n",
      "\r11496it [00:01, 8779.77it/s]\n",
      "\r12408it [00:01, 7785.38it/s]\n",
      "\r13435it [00:01, 8380.66it/s]\n",
      "\r14563it [00:01, 9059.48it/s]\n",
      "\r15726it [00:01, 9687.93it/s]\n",
      "\r16794it [00:01, 9944.93it/s]\n",
      "\r17822it [00:01, 10021.72it/s]\n",
      "\r19014it [00:02, 10504.21it/s]\n",
      "\r20087it [00:02, 8804.56it/s] \n",
      "\r21171it [00:02, 9306.87it/s]\n",
      "\r22527it [00:02, 10255.54it/s]\n",
      "\r23938it [00:02, 11151.67it/s]\n",
      "\r25344it [00:02, 11880.91it/s]\n",
      "\r25799it [00:02, 9767.59it/s] \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 25799 rows.\n"
     ]
    }
   ],
   "source": [
    "user_reviews_df = parse_json(steam_path + user_reviews)\n",
    "user_reviews_df = user_reviews_df.drop_duplicates(subset='user_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "user_reviews_df_exploded = user_reviews_df.explode('reviews')\n",
    "user_reviews_df_exploded = user_reviews_df_exploded.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def func(x):\n",
    "    return x['recommend'], x[\"item_id\"]\n",
    "\n",
    "user_reviews_df_exploded['recommended'], user_reviews_df_exploded[\"item_id\"] = zip(\n",
    "    *user_reviews_df_exploded['reviews'].map(func)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "user_reviews_df_exploded.reset_index()\n",
    "\n",
    "\n",
    "user_reviews_df_exploded = user_reviews_df_exploded[['user_id', 'item_id', 'recommended']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24                         [False, True]\n",
       "26       [True, True, True, False, True]\n",
       "36                         [True, False]\n",
       "60             [False, True, True, True]\n",
       "71                         [False, True]\n",
       "                      ...               \n",
       "25758    [True, True, True, False, True]\n",
       "25761                      [False, True]\n",
       "25764                [True, True, False]\n",
       "25768    [True, True, False, True, True]\n",
       "25785                [True, True, False]\n",
       "Length: 3684, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enkeltrue = user_reviews_df[['reviews']].apply(lambda x: [elem['recommend'] for elem in x['reviews']], axis=1)\n",
    "enkeltrue.loc[enkeltrue.map(set).map(len) > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  0%|          | 0/58430 [00:00<?, ?it/s]\n",
      "\r100%|██████████| 58430/58430 [00:00<00:00, 603988.54it/s]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "user_id        object\n",
       "item_id        object\n",
       "recommended      bool\n",
       "item_id_int     int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dct = {}\n",
    "def map_to_consecutive_id(uuid):\n",
    "  if uuid in dct:\n",
    "    return dct[uuid]\n",
    "  else:\n",
    "    id = len(dct)\n",
    "    dct[uuid] = id\n",
    "    return id\n",
    "user_reviews_df_exploded['item_id_int'] = user_reviews_df_exploded['item_id'].progress_apply(map_to_consecutive_id)\n",
    "user_reviews_df_exploded.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  0%|          | 0/58430 [00:00<?, ?it/s]\n",
      "\r 81%|████████  | 47361/58430 [00:00<00:00, 470771.88it/s]\n",
      "\r100%|██████████| 58430/58430 [00:00<00:00, 442092.66it/s]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dct = {}\n",
    "user_reviews_df_exploded['user_id_int'] = user_reviews_df_exploded['user_id'].progress_apply(map_to_consecutive_id)\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_df, test_df = train_test_split(user_reviews_df_exploded, test_size=0.2)\n",
    "\n",
    "\n",
    "test_df_grouped = test_df.groupby('user_id_int').agg(list)\n",
    "test_df_grouped = test_df_grouped.reset_index()\n",
    "\n",
    "train_df_grouped = train_df.groupby('user_id_int').agg(list)\n",
    "train_df_grouped = train_df_grouped.reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "#Create scipy csr matrix\n",
    "def get_sparse_matrix(df):\n",
    "    shape = (user_reviews_df_exploded['user_id_int'].max() + 1, user_reviews_df_exploded['item_id_int'].max() + 1)\n",
    "    \n",
    "    user_ids = []\n",
    "    item_ids = []\n",
    "    values = []\n",
    "    for idx, row in df.iterrows():\n",
    "        items = row['item_id_int']\n",
    "        user = row['user_id_int']\n",
    "    \n",
    "        recommended = row['recommended']\n",
    "        user_ids.extend([user] * len(items))\n",
    "        item_ids.extend(items)\n",
    "        values.extend([2 if recommended[i] else 1 for i in range(len(items))])\n",
    "    #create csr matrix\n",
    "    # values = np.ones(len(user_ids))\n",
    "    matrix = scipy.sparse.csr_matrix((values, (user_ids, item_ids)), shape=shape, dtype=np.int32)\n",
    "    return matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<25457x3682 sparse matrix of type '<class 'numpy.intc'>'\n",
       "\twith 46744 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_matrix = get_sparse_matrix(test_df_grouped)\n",
    "\n",
    "train_matrix = get_sparse_matrix(train_df_grouped)\n",
    "train_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------\n",
      "start training\n",
      "calculating test scores\n",
      "finished epoch 0\n",
      "calculating test scores\n",
      "finished epoch 1\n",
      "calculating test scores\n",
      "finished epoch 2\n",
      "calculating test scores\n",
      "finished epoch 3\n",
      "calculating test scores\n",
      "finished epoch 4\n",
      "calculating test scores\n",
      "finished epoch 5\n",
      "calculating test scores\n",
      "finished epoch 6\n",
      "calculating test scores\n",
      "finished epoch 7\n",
      "calculating test scores\n",
      "finished epoch 8\n",
      "calculating test scores\n",
      "finished epoch 9\n",
      "calculating test scores\n",
      "finished epoch 10\n",
      "calculating test scores\n",
      "finished epoch 11\n",
      "calculating test scores\n",
      "finished epoch 12\n",
      "calculating test scores\n",
      "finished epoch 13\n",
      "calculating test scores\n",
      "finished epoch 14\n",
      "calculating test scores\n",
      "finished epoch 15\n",
      "calculating test scores\n",
      "finished epoch 16\n",
      "calculating test scores\n",
      "finished epoch 17\n",
      "calculating test scores\n",
      "finished epoch 18\n",
      "calculating test scores\n",
      "finished epoch 19\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def score_model(rbm):\n",
    "    test_recon_error = 0  # RMSE reconstruction error initialized to 0 at the beginning of training\n",
    "    s = 0  # a counter (float type) \n",
    "    # for loop - go through every single user\n",
    "    for id_user in range(user_reviews_df_exploded['user_id_int'].max() + 1):\n",
    "        v = train_matrix[id_user:id_user + 1]  # training set inputs are used to activate neurons of my RBM\n",
    "        vt = test_matrix[id_user:id_user + 1]  # target\n",
    "        # v = convert_sparse_matrix_to_sparse_tensor(training_sample)\n",
    "        # vt = convert_sparse_matrix_to_sparse_tensor(training_sample2)\n",
    "        v = v.todense()\n",
    "        vt = vt.todense()\n",
    "\n",
    "        # v = v.to_dense()\n",
    "        # vt = vt.to_dense()\n",
    "        v = v - 1\n",
    "        vt = vt - 1\n",
    "        v = torch.Tensor(v)\n",
    "        vt = torch.Tensor(vt)\n",
    "        if len(vt[vt > -1]) > 0:\n",
    "            _, h = rbm.sample_h(v)\n",
    "            _, v = rbm.sample_v(h)\n",
    "\n",
    "            # Update test RMSE reconstruction error\n",
    "            test_recon_error += torch.sqrt(torch.mean((vt[vt > -1] - v[vt > -1])**2))\n",
    "            s += 1\n",
    "\n",
    "    return test_recon_error / s\n",
    "\n",
    "print('-------')\n",
    "n_vis = user_reviews_df_exploded['item_id_int'].max() + 1\n",
    "n_hidden = 12\n",
    "batch_size = 128\n",
    "train_errors = []\n",
    "test_errors = []\n",
    "rbm = RBM(n_vis, n_hidden)\n",
    "\n",
    "# https://stackoverflow.com/questions/40896157/scipy-sparse-csr-matrix-to-tensorflow-sparsetensor-mini-batch-gradient-descent\n",
    "def convert_sparse_matrix_to_sparse_tensor(X):\n",
    "    coo = X.tocoo()\n",
    "\n",
    "    values = coo.data\n",
    "    indices = np.vstack((coo.row, coo.col))\n",
    "\n",
    "    i = torch.LongTensor(indices)\n",
    "    v = torch.FloatTensor(values)\n",
    "    # print(values)\n",
    "    # print(\"values\", v)\n",
    "    shape = coo.shape\n",
    "\n",
    "    return torch.sparse.FloatTensor(i, v, torch.Size(shape))\n",
    "\n",
    "print(\"start training\")\n",
    "for epoch in range(20):\n",
    "    rbm.train()\n",
    "    train_recon_error = 0  # RMSE reconstruction error initialized to 0 at the beginning of training\n",
    "    s = 0\n",
    "    \n",
    "    for user_id in range(0, user_reviews_df_exploded['user_id_int'].max() + 1 - batch_size, batch_size):\n",
    "        training_sample = train_matrix[user_id : user_id + batch_size]\n",
    "        training_sample2 = train_matrix[user_id : user_id + batch_size]\n",
    "        # print(training_sample)\n",
    "        v0 = convert_sparse_matrix_to_sparse_tensor(training_sample)\n",
    "        # print(v0.coalesce().indices())\n",
    "        vk = convert_sparse_matrix_to_sparse_tensor(training_sample2)\n",
    "\n",
    "        v0 = v0.to_dense()\n",
    "        vk = vk.to_dense()\n",
    "        v0 = v0.sub(1)\n",
    "        vk = vk.sub(1)\n",
    "        \n",
    "        ph0, _ = rbm.sample_h(v0)   \n",
    "\n",
    "        # Third for loop - perform contrastive divergence\n",
    "        for k in range(10):\n",
    "            _, hk = rbm.sample_h(vk)\n",
    "            _, vk = rbm.sample_v(hk)\n",
    "\n",
    "            # We don't want to learn when there is no rating by the user, and there is no update when rating = -1\n",
    "            # Remove indices from vk vector that are not in the v0 vector => get sparse tensor again\n",
    "            vk[v0 < 0] = v0[v0 < 0]\n",
    "            vksparse = vk.to_sparse()\n",
    "            # print(\"v0\", v0)\n",
    "            # print(\"v0\", v0.add(1).to_sparse())\n",
    "            # print(\"vk\", vk.add(1).to_sparse())\n",
    "            \n",
    "            # print(k)\n",
    "\n",
    "        phk, _ = rbm.sample_h(vk)\n",
    "\n",
    "\n",
    "        rbm.train_model(v0, vk, ph0, phk)\n",
    "        \n",
    "        train_recon_error += torch.sqrt(torch.mean((v0[v0 > 0] - vk[v0 > 0])**2))\n",
    "        s += 1\n",
    "        \n",
    "        # print((torch.mm(v0.t(), ph0) - torch.mm(vk.t(), phk)).t().shape)\n",
    "        # print(torch.sum((-vk + v0), 0).shape)\n",
    "        # print(torch.sum((ph0 - phk), 0).shape)\n",
    "        \n",
    "    train_errors.append(train_recon_error / s)\n",
    "\n",
    "    print('calculating test scores')\n",
    "    rbm.eval()\n",
    "    test_errors.append(score_model(rbm))\n",
    "\n",
    "    print('finished epoch', epoch)    \n",
    "    \n",
    "import matplotlib.pyplot as plt\n",
    "# Plot the RMSE reconstruction error with respect to increasing number of epochs\n",
    "plt.plot(train_errors, label=\"train\")\n",
    "plt.plot(test_errors, label=\"test\")\n",
    "plt.ylabel('Error')\n",
    "plt.xlabel('Epoch')\n",
    "plt.savefig('errors.jpg')\n",
    "\n",
    "# Evaluate the RBM on test set\n",
    "# test_recon_error = score_model(rbm)\n",
    "# print(\"Final error\", test_recon_error)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# torch.save(rbm.state_dict(), \"./network\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": false,
     "name": "#%% load model\n"
    }
   },
   "outputs": [],
   "source": [
    "rbm = RBM(n_vis, n_hidden)\n",
    "rbm.load_state_dict(torch.load(\"./network\"))\n",
    "rbm.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Full Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7793069it [06:00, 21624.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 3176223 rows.\n"
     ]
    }
   ],
   "source": [
    "steam_reviews_df = parse_json(steam_path + steam_reviews)\n",
    "steam_reviews_df_small = steam_reviews_df[['user_id', 'product_id', 'recommended', 'date']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "steam_reviews_df_cleaned = steam_reviews_df_small.dropna(axis=0, subset=['user_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76561198011965365    1254\n",
       "76561198094803808     900\n",
       "76561197969749884     750\n",
       "76561198094321628     669\n",
       "76561198073092169     549\n",
       "                     ... \n",
       "76561198345086561       1\n",
       "76561198054491833       1\n",
       "76561198095690287       1\n",
       "76561198301658414       1\n",
       "76561198089897928       1\n",
       "Name: user_id, Length: 1485611, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steam_reviews_df_cleaned.head(5)\n",
    "steam_reviews_df[\"user_id\"].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3176223/3176223 [00:02<00:00, 1059200.44it/s]\n",
      "100%|██████████| 3176223/3176223 [00:04<00:00, 713953.82it/s]\n"
     ]
    }
   ],
   "source": [
    "dct = {}\n",
    "def map_to_consecutive_id(uuid):\n",
    "  if uuid in dct:\n",
    "    return dct[uuid]\n",
    "  else:\n",
    "    id = len(dct)\n",
    "    dct[uuid] = id\n",
    "    return id\n",
    "steam_reviews_df_cleaned['product_id_int'] = steam_reviews_df_cleaned['product_id'].progress_apply(map_to_consecutive_id)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# train_df, test_df = train_test_split(steam_reviews_df_cleaned, test_size=0.2)\n",
    "\n",
    "\n",
    "# test_df_grouped = test_df.groupby('user_id_int').agg(list)\n",
    "# test_df_grouped = test_df_grouped.reset_index()\n",
    "\n",
    "# train_df_grouped = train_df.groupby('user_id_int').agg(list)\n",
    "# train_df_grouped = train_df_grouped.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Date Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id                   object\n",
       "product_id                object\n",
       "recommended                 bool\n",
       "date              datetime64[ns]\n",
       "product_id_int             int64\n",
       "user_id_int                int64\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>recommended</th>\n",
       "      <th>date</th>\n",
       "      <th>product_id_int</th>\n",
       "      <th>user_id_int</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>76561198007483075</td>\n",
       "      <td>35140</td>\n",
       "      <td>True</td>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>76561197970402776</td>\n",
       "      <td>707610</td>\n",
       "      <td>True</td>\n",
       "      <td>2017-10-16</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>76561198060686749</td>\n",
       "      <td>328100</td>\n",
       "      <td>True</td>\n",
       "      <td>2017-06-23</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>76561198023491401</td>\n",
       "      <td>35140</td>\n",
       "      <td>True</td>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>76561198115331805</td>\n",
       "      <td>35140</td>\n",
       "      <td>True</td>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             user_id product_id  recommended       date  product_id_int  \\\n",
       "0  76561198007483075      35140         True 2018-01-04               0   \n",
       "1  76561197970402776     707610         True 2017-10-16               1   \n",
       "2  76561198060686749     328100         True 2017-06-23               2   \n",
       "3  76561198023491401      35140         True 2018-01-03               0   \n",
       "4  76561198115331805      35140         True 2018-01-03               0   \n",
       "\n",
       "   user_id_int  \n",
       "0            0  \n",
       "1            1  \n",
       "2            2  \n",
       "3            3  \n",
       "4            4  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "steam_reviews_df_cleaned[\"date\"] = pd.to_datetime(steam_reviews_df_cleaned[\"date\"])\n",
    "display(steam_reviews_df_cleaned.dtypes)\n",
    "display(steam_reviews_df_cleaned.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id_int</th>\n",
       "      <th>recommended</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>76561197960265806</th>\n",
       "      <td>[14313]</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[2017-12-20 00:00:00]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76561197960266010</th>\n",
       "      <td>[9722]</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[2017-11-27 00:00:00]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76561197960266146</th>\n",
       "      <td>[597]</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[2017-11-04 00:00:00]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76561197960266225</th>\n",
       "      <td>[1622]</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[2017-06-07 00:00:00]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76561197960266375</th>\n",
       "      <td>[3716]</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[2017-09-13 00:00:00]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  product_id_int recommended                   date\n",
       "user_id                                                            \n",
       "76561197960265806        [14313]      [True]  [2017-12-20 00:00:00]\n",
       "76561197960266010         [9722]      [True]  [2017-11-27 00:00:00]\n",
       "76561197960266146          [597]      [True]  [2017-11-04 00:00:00]\n",
       "76561197960266225         [1622]      [True]  [2017-06-07 00:00:00]\n",
       "76561197960266375         [3716]      [True]  [2017-09-13 00:00:00]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id_int</th>\n",
       "      <th>recommended</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>76561197960266546</th>\n",
       "      <td>[2678, 2678]</td>\n",
       "      <td>[True, True]</td>\n",
       "      <td>[2016-11-25 00:00:00, 2016-11-25 00:00:00]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76561197960266564</th>\n",
       "      <td>[7259, 7259]</td>\n",
       "      <td>[True, True]</td>\n",
       "      <td>[2016-08-14 00:00:00, 2016-08-14 00:00:00]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76561197960267022</th>\n",
       "      <td>[7779, 13382]</td>\n",
       "      <td>[True, True]</td>\n",
       "      <td>[2015-09-29 00:00:00, 2015-04-16 00:00:00]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76561197960267615</th>\n",
       "      <td>[1428, 2098, 2545, 2643, 2633, 3052, 3150, 397...</td>\n",
       "      <td>[True, True, True, True, True, True, True, Tru...</td>\n",
       "      <td>[2012-11-06 00:00:00, 2011-11-30 00:00:00, 201...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76561197960268226</th>\n",
       "      <td>[9485, 13462]</td>\n",
       "      <td>[True, True]</td>\n",
       "      <td>[2015-06-01 00:00:00, 2016-11-28 00:00:00]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      product_id_int  \\\n",
       "user_id                                                                \n",
       "76561197960266546                                       [2678, 2678]   \n",
       "76561197960266564                                       [7259, 7259]   \n",
       "76561197960267022                                      [7779, 13382]   \n",
       "76561197960267615  [1428, 2098, 2545, 2643, 2633, 3052, 3150, 397...   \n",
       "76561197960268226                                      [9485, 13462]   \n",
       "\n",
       "                                                         recommended  \\\n",
       "user_id                                                                \n",
       "76561197960266546                                       [True, True]   \n",
       "76561197960266564                                       [True, True]   \n",
       "76561197960267022                                       [True, True]   \n",
       "76561197960267615  [True, True, True, True, True, True, True, Tru...   \n",
       "76561197960268226                                       [True, True]   \n",
       "\n",
       "                                                                date  \n",
       "user_id                                                               \n",
       "76561197960266546         [2016-11-25 00:00:00, 2016-11-25 00:00:00]  \n",
       "76561197960266564         [2016-08-14 00:00:00, 2016-08-14 00:00:00]  \n",
       "76561197960267022         [2015-09-29 00:00:00, 2015-04-16 00:00:00]  \n",
       "76561197960267615  [2012-11-06 00:00:00, 2011-11-30 00:00:00, 201...  \n",
       "76561197960268226         [2015-06-01 00:00:00, 2016-11-28 00:00:00]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyError",
     "evalue": "'user_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/dev/ai-project/.venv/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3360\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/ai-project/.venv/lib/python3.8/site-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/dev/ai-project/.venv/lib/python3.8/site-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'user_id'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_186504/577707902.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mdct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0msteam_reviews_df_grouped_smaller\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"user_id_int\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msteam_reviews_df_grouped_smaller\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"user_id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogress_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap_to_consecutive_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/dev/ai-project/.venv/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3456\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3457\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3458\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3459\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3460\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/ai-project/.venv/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3361\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3363\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhasnans\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'user_id'"
     ]
    }
   ],
   "source": [
    "steam_reviews_df_grouped = steam_reviews_df_cleaned.groupby(\"user_id\")[[\"product_id_int\", \"recommended\", \"date\"]].agg(list)\n",
    "display(steam_reviews_df_grouped.head(5))\n",
    "\n",
    "steam_reviews_df_grouped_smaller = steam_reviews_df_grouped[steam_reviews_df_grouped[\"recommended\"].map(len) > 1]\n",
    "display(steam_reviews_df_grouped_smaller.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 581343/581343 [00:00<00:00, 677140.64it/s]\n"
     ]
    }
   ],
   "source": [
    "dct.clear()\n",
    "steam_reviews_df_grouped_smaller = steam_reviews_df_grouped_smaller.reset_index()\n",
    "steam_reviews_df_grouped_smaller[\"user_id_int\"] = steam_reviews_df_grouped_smaller[\"user_id\"].progress_apply(map_to_consecutive_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(581343, 5)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(1485611, 3)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "904268\n"
     ]
    }
   ],
   "source": [
    "display(steam_reviews_df_grouped_smaller.shape)\n",
    "display(steam_reviews_df_grouped.shape)\n",
    "print(steam_reviews_df_grouped.shape[0] - steam_reviews_df_grouped_smaller.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 581343/581343 [00:00<00:00, 702547.43it/s]\n",
      "100%|██████████| 581343/581343 [00:00<00:00, 651432.98it/s]\n",
      "100%|██████████| 581343/581343 [00:00<00:00, 708283.17it/s]\n",
      "100%|██████████| 581343/581343 [00:00<00:00, 736112.96it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>product_id_int</th>\n",
       "      <th>recommended</th>\n",
       "      <th>date</th>\n",
       "      <th>user_id_int</th>\n",
       "      <th>product_history</th>\n",
       "      <th>product_future</th>\n",
       "      <th>recommended_history</th>\n",
       "      <th>recommended_future</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>76561197960266546</td>\n",
       "      <td>[2678, 2678]</td>\n",
       "      <td>[True, True]</td>\n",
       "      <td>[2016-11-25 00:00:00, 2016-11-25 00:00:00]</td>\n",
       "      <td>0</td>\n",
       "      <td>[2678]</td>\n",
       "      <td>[2678]</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>76561197960266564</td>\n",
       "      <td>[7259, 7259]</td>\n",
       "      <td>[True, True]</td>\n",
       "      <td>[2016-08-14 00:00:00, 2016-08-14 00:00:00]</td>\n",
       "      <td>1</td>\n",
       "      <td>[7259]</td>\n",
       "      <td>[7259]</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>76561197960267022</td>\n",
       "      <td>[7779, 13382]</td>\n",
       "      <td>[True, True]</td>\n",
       "      <td>[2015-09-29 00:00:00, 2015-04-16 00:00:00]</td>\n",
       "      <td>2</td>\n",
       "      <td>[7779]</td>\n",
       "      <td>[13382]</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>76561197960267615</td>\n",
       "      <td>[1428, 2098, 2545, 2643, 2633, 3052, 3150, 397...</td>\n",
       "      <td>[True, True, True, True, True, True, True, Tru...</td>\n",
       "      <td>[2012-11-06 00:00:00, 2011-11-30 00:00:00, 201...</td>\n",
       "      <td>3</td>\n",
       "      <td>[1428, 2098, 2545, 2643, 2633, 3052, 3150, 397...</td>\n",
       "      <td>[12754, 12703, 12755, 13323, 13215, 13544, 140...</td>\n",
       "      <td>[True, True, True, True, True, True, True, Tru...</td>\n",
       "      <td>[True, True, True, True, True, True, True, True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>76561197960268226</td>\n",
       "      <td>[9485, 13462]</td>\n",
       "      <td>[True, True]</td>\n",
       "      <td>[2015-06-01 00:00:00, 2016-11-28 00:00:00]</td>\n",
       "      <td>4</td>\n",
       "      <td>[9485]</td>\n",
       "      <td>[13462]</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[True]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             user_id                                     product_id_int  \\\n",
       "0  76561197960266546                                       [2678, 2678]   \n",
       "1  76561197960266564                                       [7259, 7259]   \n",
       "2  76561197960267022                                      [7779, 13382]   \n",
       "3  76561197960267615  [1428, 2098, 2545, 2643, 2633, 3052, 3150, 397...   \n",
       "4  76561197960268226                                      [9485, 13462]   \n",
       "\n",
       "                                         recommended  \\\n",
       "0                                       [True, True]   \n",
       "1                                       [True, True]   \n",
       "2                                       [True, True]   \n",
       "3  [True, True, True, True, True, True, True, Tru...   \n",
       "4                                       [True, True]   \n",
       "\n",
       "                                                date  user_id_int  \\\n",
       "0         [2016-11-25 00:00:00, 2016-11-25 00:00:00]            0   \n",
       "1         [2016-08-14 00:00:00, 2016-08-14 00:00:00]            1   \n",
       "2         [2015-09-29 00:00:00, 2015-04-16 00:00:00]            2   \n",
       "3  [2012-11-06 00:00:00, 2011-11-30 00:00:00, 201...            3   \n",
       "4         [2015-06-01 00:00:00, 2016-11-28 00:00:00]            4   \n",
       "\n",
       "                                     product_history  \\\n",
       "0                                             [2678]   \n",
       "1                                             [7259]   \n",
       "2                                             [7779]   \n",
       "3  [1428, 2098, 2545, 2643, 2633, 3052, 3150, 397...   \n",
       "4                                             [9485]   \n",
       "\n",
       "                                      product_future  \\\n",
       "0                                             [2678]   \n",
       "1                                             [7259]   \n",
       "2                                            [13382]   \n",
       "3  [12754, 12703, 12755, 13323, 13215, 13544, 140...   \n",
       "4                                            [13462]   \n",
       "\n",
       "                                 recommended_history  \\\n",
       "0                                             [True]   \n",
       "1                                             [True]   \n",
       "2                                             [True]   \n",
       "3  [True, True, True, True, True, True, True, Tru...   \n",
       "4                                             [True]   \n",
       "\n",
       "                                 recommended_future  \n",
       "0                                            [True]  \n",
       "1                                            [True]  \n",
       "2                                            [True]  \n",
       "3  [True, True, True, True, True, True, True, True]  \n",
       "4                                            [True]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "def split(items, train_percentage):\n",
    "    train_count = math.floor(len(items) * train_percentage)\n",
    "    return items[0:train_count], items[train_count:]\n",
    "\n",
    "train_percentage = 0.8\n",
    "steam_reviews_df_grouped_smaller[\"product_history\"] = steam_reviews_df_grouped_smaller[\"product_id_int\"].progress_apply(lambda items: split(items, train_percentage)[0])\n",
    "steam_reviews_df_grouped_smaller[\"product_future\"] = steam_reviews_df_grouped_smaller[\"product_id_int\"].progress_apply(lambda items: split(items, train_percentage)[1])\n",
    "steam_reviews_df_grouped_smaller[\"recommended_history\"] = steam_reviews_df_grouped_smaller[\"recommended\"].progress_apply(lambda items: split(items, train_percentage)[0])\n",
    "steam_reviews_df_grouped_smaller[\"recommended_future\"] = steam_reviews_df_grouped_smaller[\"recommended\"].progress_apply(lambda items: split(items, train_percentage)[1])\n",
    "display(steam_reviews_df_grouped_smaller.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    581343.000000\n",
       "mean          3.908114\n",
       "std           5.950826\n",
       "min           2.000000\n",
       "25%           2.000000\n",
       "50%           2.000000\n",
       "75%           4.000000\n",
       "max        1254.000000\n",
       "Name: recommended, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steam_reviews_df_grouped_smaller[\"recommended\"].map(len).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create scipy csr matrix\n",
    "def get_sparse_matrix(df, shape, recommended_col=\"recommended_history\", product_col=\"product_history\"):\n",
    "    user_ids = []\n",
    "    product_ids = []\n",
    "    values = []\n",
    "    for _, row in df.iterrows():\n",
    "        products = row[product_col]\n",
    "        user = row['user_id_int']\n",
    "    \n",
    "        recommended = row[recommended_col]\n",
    "        user_ids.extend([user] * len(products))\n",
    "        product_ids.extend(products)\n",
    "        values.extend([2 if recommended[i] else 1 for i in range(len(products))])\n",
    "    #create csr matrix\n",
    "    # values = np.ones(len(user_ids))\n",
    "    matrix = scipy.sparse.csr_matrix((values, (user_ids, product_ids)), shape=shape, dtype=np.int32)\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "steam_reviews_set = steam_reviews_df_grouped_smaller.head(100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<100000x14513 sparse matrix of type '<class 'numpy.int32'>'\n",
       "\twith 293925 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape = (steam_reviews_set.shape[0], steam_reviews_df_cleaned['product_id_int'].max() + 1)\n",
    "\n",
    "steam_reviews_set = steam_reviews_set.reset_index()\n",
    "train_matrix = get_sparse_matrix(steam_reviews_set, shape)\n",
    "test_matrix = get_sparse_matrix(steam_reviews_set, shape, recommended_col=\"recommended_future\", product_col=\"product_future\")\n",
    "train_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<100000x14513 sparse matrix of type '<class 'numpy.int32'>'\n",
       "\twith 132628 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------\n",
      "start training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 97/97 [16:10<00:00, 10.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating test scores\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [01:36<00:00, 1037.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 97/97 [16:11<00:00, 10.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating test scores\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [01:34<00:00, 1055.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished epoch 1\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def score_model(rbm):\n",
    "    test_recon_error = 0  # RMSE reconstruction error initialized to 0 at the beginning of training\n",
    "    s = 0  # a counter (float type) \n",
    "    # for loop - go through every single user\n",
    "    for id_user in tqdm(range(shape[0])):\n",
    "        v = train_matrix[id_user:id_user + 1]  # training set inputs are used to activate neurons of my RBM\n",
    "        vt = test_matrix[id_user:id_user + 1]  # target\n",
    "        # v = convert_sparse_matrix_to_sparse_tensor(training_sample)\n",
    "        # vt = convert_sparse_matrix_to_sparse_tensor(training_sample2)\n",
    "        v = v.todense()\n",
    "        vt = vt.todense()\n",
    "\n",
    "        # v = v.to_dense()\n",
    "        # vt = vt.to_dense()\n",
    "        v = v - 1\n",
    "        vt = vt - 1\n",
    "        v = torch.Tensor(v)\n",
    "        vt = torch.Tensor(vt)\n",
    "        if len(vt[vt > -1]) > 0:\n",
    "            _, h = rbm.sample_h(v)\n",
    "            _, v = rbm.sample_v(h)\n",
    "\n",
    "            # Update test RMSE reconstruction error\n",
    "            test_recon_error += torch.sqrt(torch.mean((vt[vt > -1] - v[vt > -1])**2))\n",
    "            s += 1\n",
    "\n",
    "    return test_recon_error / s\n",
    "\n",
    "print('-------')\n",
    "n_vis = shape[1]\n",
    "n_hidden = 12\n",
    "batch_size = 1024 \n",
    "train_errors = []\n",
    "test_errors = []\n",
    "rbm = RBM(n_vis, n_hidden)\n",
    "\n",
    "# https://stackoverflow.com/questions/40896157/scipy-sparse-csr-matrix-to-tensorflow-sparsetensor-mini-batch-gradient-descent\n",
    "def convert_sparse_matrix_to_sparse_tensor(X):\n",
    "    coo = X.tocoo()\n",
    "\n",
    "    values = coo.data\n",
    "    indices = np.vstack((coo.row, coo.col))\n",
    "\n",
    "    i = torch.LongTensor(indices)\n",
    "    v = torch.FloatTensor(values)\n",
    "    # print(values)\n",
    "    # print(\"values\", v)\n",
    "    shape = coo.shape\n",
    "\n",
    "    return torch.sparse.FloatTensor(i, v, torch.Size(shape))\n",
    "\n",
    "print(\"start training\")\n",
    "for epoch in range(2):\n",
    "    rbm.train()\n",
    "    train_recon_error = 0  # RMSE reconstruction error initialized to 0 at the beginning of training\n",
    "    s = 0\n",
    "    \n",
    "    for user_id in tqdm(range(0, shape[0] - batch_size, batch_size)):\n",
    "        training_sample = train_matrix[user_id : user_id + batch_size]\n",
    "        training_sample2 = train_matrix[user_id : user_id + batch_size]\n",
    "        # print(training_sample)\n",
    "        v0 = convert_sparse_matrix_to_sparse_tensor(training_sample)\n",
    "        # print(v0.coalesce().indices())\n",
    "        vk = convert_sparse_matrix_to_sparse_tensor(training_sample2)\n",
    "\n",
    "        v0 = v0.to_dense()\n",
    "        vk = vk.to_dense()\n",
    "        v0 = v0.sub(1)\n",
    "        vk = vk.sub(1)\n",
    "        \n",
    "        ph0, _ = rbm.sample_h(v0)   \n",
    "\n",
    "        # Third for loop - perform contrastive divergence\n",
    "        for k in range(10):\n",
    "            _, hk = rbm.sample_h(vk)\n",
    "            _, vk = rbm.sample_v(hk)\n",
    "\n",
    "            # We don't want to learn when there is no rating by the user, and there is no update when rating = -1\n",
    "            # Remove indices from vk vector that are not in the v0 vector => get sparse tensor again\n",
    "            vk[v0 < 0] = v0[v0 < 0]\n",
    "            vksparse = vk.to_sparse()\n",
    "            # print(\"v0\", v0)\n",
    "            # print(\"v0\", v0.add(1).to_sparse())\n",
    "            # print(\"vk\", vk.add(1).to_sparse())\n",
    "            \n",
    "            # print(k)\n",
    "\n",
    "        phk, _ = rbm.sample_h(vk)\n",
    "\n",
    "\n",
    "        rbm.train_model(v0, vk, ph0, phk)\n",
    "        \n",
    "        train_recon_error += torch.sqrt(torch.mean((v0[v0 > 0] - vk[v0 > 0])**2))\n",
    "        s += 1\n",
    "        \n",
    "        # print((torch.mm(v0.t(), ph0) - torch.mm(vk.t(), phk)).t().shape)\n",
    "        # print(torch.sum((-vk + v0), 0).shape)\n",
    "        # print(torch.sum((ph0 - phk), 0).shape)\n",
    "        \n",
    "    train_errors.append(train_recon_error / s)\n",
    "\n",
    "    print('calculating test scores')\n",
    "    rbm.eval()\n",
    "    test_errors.append(score_model(rbm))\n",
    "\n",
    "    print('finished epoch', epoch)    \n",
    "    \n",
    "import matplotlib.pyplot as plt\n",
    "# Plot the RMSE reconstruction error with respect to increasing number of epochs\n",
    "plt.plot(train_errors, label=\"train\")\n",
    "plt.plot(test_errors, label=\"test\")\n",
    "plt.ylabel('Error')\n",
    "plt.xlabel('Epoch')\n",
    "plt.savefig('errors.jpg')\n",
    "\n",
    "# Evaluate the RBM on test set\n",
    "# test_recon_error = score_model(rbm)\n",
    "# print(\"Final error\", test_recon_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(0.6697), tensor(0.6338)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[tensor(0.1125), tensor(0.1012)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(train_errors)\n",
    "display(test_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76561198037833890    1\n",
       "76561197992194309    1\n",
       "76561198043292775    1\n",
       "76561198030442121    1\n",
       "76561197963870074    1\n",
       "                    ..\n",
       "76561198345086561    1\n",
       "76561198054491833    1\n",
       "76561198095690287    1\n",
       "76561198301658414    1\n",
       "76561198089897928    1\n",
       "Name: user_id, Length: 904268, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "76561198011965365    1254\n",
       "76561198094803808     900\n",
       "76561197969749884     750\n",
       "76561198094321628     669\n",
       "76561198073092169     549\n",
       "                     ... \n",
       "76561198098554655       2\n",
       "76561198044342349       2\n",
       "76561198122784122       2\n",
       "76561198076341138       2\n",
       "76561198102545130       2\n",
       "Name: user_id, Length: 581343, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "76561198011965365    1254\n",
       "76561198094803808     900\n",
       "76561197969749884     750\n",
       "76561198094321628     669\n",
       "76561198073092169     549\n",
       "                     ... \n",
       "76561198345086561       1\n",
       "76561198054491833       1\n",
       "76561198095690287       1\n",
       "76561198301658414       1\n",
       "76561198089897928       1\n",
       "Name: user_id, Length: 1485611, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "s = steam_reviews_df_small[\"user_id\"].value_counts(dropna=False)\n",
    "display(s.loc[s < 2])\n",
    "display(s.loc[s >= 2])\n",
    "display(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(0.0369), tensor(0.0350)]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_errors"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "217547bed935db835ab8ee75368a6e3b4fa2f4141d63447ea52f48769f3995fc"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('.venv': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

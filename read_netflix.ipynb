{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle as pickle\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "import gzip\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "import math\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "tqdm.pandas() #for progres_apply etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1425333it [00:00, 1618829.73it/s]\n"
     ]
    }
   ],
   "source": [
    "def parse_probe():\n",
    "    parsed_data = []\n",
    "    with open(f\"netflix/probe.txt\") as f:\n",
    "        movie = None\n",
    "        for line in tqdm(f):\n",
    "            if line[-2] == \":\":\n",
    "                movie = int(line[:-2])\n",
    "            else:\n",
    "                user = line[:-1]\n",
    "                parsed_data.append({\"movie_user\": str(movie) + \"_\" + user, \"movie\": movie, \"user\": int(user)})\n",
    "\n",
    "    return pd.DataFrame.from_dict(parsed_data)\n",
    "\n",
    "df_val = parse_probe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24058263it [00:20, 1167464.17it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie</th>\n",
       "      <th>user</th>\n",
       "      <th>rating</th>\n",
       "      <th>time</th>\n",
       "      <th>movie_user</th>\n",
       "      <th>validation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1488844</td>\n",
       "      <td>3</td>\n",
       "      <td>2005-09-06</td>\n",
       "      <td>1_1488844</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>822109</td>\n",
       "      <td>5</td>\n",
       "      <td>2005-05-13</td>\n",
       "      <td>1_822109</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>885013</td>\n",
       "      <td>4</td>\n",
       "      <td>2005-10-19</td>\n",
       "      <td>1_885013</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>30878</td>\n",
       "      <td>4</td>\n",
       "      <td>2005-12-26</td>\n",
       "      <td>1_30878</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>823519</td>\n",
       "      <td>3</td>\n",
       "      <td>2004-05-03</td>\n",
       "      <td>1_823519</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movie     user  rating        time movie_user  validation\n",
       "0      1  1488844       3  2005-09-06  1_1488844       False\n",
       "1      1   822109       5  2005-05-13   1_822109       False\n",
       "2      1   885013       4  2005-10-19   1_885013       False\n",
       "3      1    30878       4  2005-12-26    1_30878        True\n",
       "4      1   823519       3  2004-05-03   1_823519       False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def parse_netflix():\n",
    "    parsed_data = []\n",
    "    for i in range(1, 2):\n",
    "        with open(f\"netflix/combined_data_{i}.txt\") as f:\n",
    "            movie = None\n",
    "            for line in tqdm(f):\n",
    "                if line[-2] == \":\":\n",
    "                    movie = int(line[:-2])\n",
    "                else:\n",
    "                    user, rating, rating_time = line[:-1].split(',')\n",
    "                    movie_user = str(movie) + \"_\" + user\n",
    "                    parsed_data.append({\"movie\": movie, \"user\": int(user), \"rating\": int(rating), \"time\": rating_time, \"movie_user\": movie_user})\n",
    "\n",
    "    return pd.DataFrame.from_dict(parsed_data)\n",
    "\n",
    "df = parse_netflix()\n",
    "df[\"validation\"] = df.movie_user.isin(df_val.movie_user)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "34 seconden lezen, 36 seconden df maken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_min = df.drop(columns=[\"time\", \"movie_user\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie</th>\n",
       "      <th>user</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.405376e+07</td>\n",
       "      <td>2.405376e+07</td>\n",
       "      <td>2.405376e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.308324e+03</td>\n",
       "      <td>1.322285e+06</td>\n",
       "      <td>3.599634e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.303909e+03</td>\n",
       "      <td>7.645779e+05</td>\n",
       "      <td>1.086118e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.180000e+03</td>\n",
       "      <td>6.609270e+05</td>\n",
       "      <td>3.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.342000e+03</td>\n",
       "      <td>1.318602e+06</td>\n",
       "      <td>4.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.433000e+03</td>\n",
       "      <td>1.984358e+06</td>\n",
       "      <td>4.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.499000e+03</td>\n",
       "      <td>2.649429e+06</td>\n",
       "      <td>5.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              movie          user        rating\n",
       "count  2.405376e+07  2.405376e+07  2.405376e+07\n",
       "mean   2.308324e+03  1.322285e+06  3.599634e+00\n",
       "std    1.303909e+03  7.645779e+05  1.086118e+00\n",
       "min    1.000000e+00  6.000000e+00  1.000000e+00\n",
       "25%    1.180000e+03  6.609270e+05  3.000000e+00\n",
       "50%    2.342000e+03  1.318602e+06  4.000000e+00\n",
       "75%    3.433000e+03  1.984358e+06  4.000000e+00\n",
       "max    4.499000e+03  2.649429e+06  5.000000e+00"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_min.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_min[df[\"validation\"] == False]\n",
    "df_val = df_min[df[\"validation\"] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24053764, 4)\n",
      "(23476551, 4)\n",
      "(577213, 4)\n"
     ]
    }
   ],
   "source": [
    "print(df_min.shape)\n",
    "print(df_train.shape)\n",
    "print(df_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# long operation\n",
    "df_train_grouped = df_train.groupby([\"user\"]).agg(list)\n",
    "df_val_grouped = df_val.groupby([\"user\"]).agg(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sparse_matrix(df):\n",
    "    shape = (df_min['user'].max() + 1, df_min['movie'].max() + 1)\n",
    "    \n",
    "    user_ids = []\n",
    "    item_ids = []\n",
    "    values = []\n",
    "    for idx, row in tqdm(df.iterrows()):\n",
    "        items = row['movie']\n",
    "        user = row['user']\n",
    "    \n",
    "        rating = row['rating']\n",
    "        user_ids.extend([user] * len(items))\n",
    "        item_ids.extend(items)\n",
    "        values.extend(rating)\n",
    "    #create csr matrix\n",
    "    # values = np.ones(len(user_ids))\n",
    "    matrix = scipy.sparse.csr_matrix((values, (user_ids, item_ids)), shape=shape, dtype=np.int32)\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_grouped = df_train_grouped.reset_index()\n",
    "df_val_grouped = df_val_grouped.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "321679it [00:07, 42984.06it/s]\n",
      "448719it [00:11, 38375.12it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<2649430x4500 sparse matrix of type '<class 'numpy.intc'>'\n",
       "\twith 23476551 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_matrix = get_sparse_matrix(df_val_grouped)\n",
    "\n",
    "train_matrix = get_sparse_matrix(df_train_grouped)\n",
    "train_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/khanhnamle1994/MetaRec/blob/b5e36cb579a88b32cdfb728f35f645d76b24ad95/Boltzmann-Machines-Experiments/RBM-CF-PyTorch/rbm.py#L23\n",
    "# Create the Restricted Boltzmann Machine architecture\n",
    "class RBM(nn.Module):\n",
    "    def __init__(self, n_vis, n_hid, k, batch_size):\n",
    "        \"\"\"\n",
    "        Initialize the parameters (weights and biases) we optimize during the training process\n",
    "        :param n_vis: number of visible units\n",
    "        :param n_hid: number of hidden units\n",
    "        \"\"\"\n",
    "        self.i = 0\n",
    "        self.K = k\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        # Weights used for the probability of the visible units given the hidden units\n",
    "        super().__init__()\n",
    "        self.W = torch.zeros(k, n_hid, n_vis)  # torch.rand: random normal distribution mean = 0, variance = 1\n",
    "\n",
    "        # Bias probability of the visible units is activated, given the value of the hidden units (p_v_given_h)\n",
    "        self.v_bias = torch.zeros(k, 1, n_vis)  # fake dimension for the batch = 1\n",
    "\n",
    "        # Bias probability of the hidden units is activated, given the value of the visible units (p_h_given_v)\n",
    "        self.h_bias = torch.zeros(1, n_hid)  # fake dimension for the batch = 1\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            self.W = self.W.cuda()\n",
    "            self.v_bias = self.v_bias.cuda()\n",
    "            self.h_bias = self.h_bias.cuda()\n",
    "    \n",
    "    def lr(self):\n",
    "        return 0.01 / self.batch_size\n",
    "\n",
    "    def sample_h(self, x):\n",
    "        \"\"\"\n",
    "        Sample the hidden units\n",
    "        :param x: the dataset\n",
    "        \"\"\"\n",
    "\n",
    "        # Probability h is activated given that the value v is sigmoid(Wx + a)\n",
    "        # torch.mm make the product of 2 tensors\n",
    "        # W.t() take the transpose because W is used for the p_v_given_h\n",
    "\n",
    "        temp = torch.transpose(self.W, 1, 2)\n",
    "        wx = torch.bmm(x.cpu(), temp.cpu())\n",
    "        if torch.cuda.is_available():\n",
    "            wx = wx.cuda()\n",
    "        wx_sum = torch.sum(wx, 0)\n",
    "        # print(wx.shape)\n",
    "\n",
    "        # Expand the mini-batch\n",
    "        activation = wx_sum + self.h_bias.expand_as(wx_sum)\n",
    "        # print(activation.shape)\n",
    "\n",
    "        # Calculate the probability p_h_given_v\n",
    "        p_h_given_v = torch.sigmoid(activation)\n",
    "\n",
    "        # print(\"h sparse\", p_h_given_v.is_sparse, torch.bernoulli(p_h_given_v).is_sparse)\n",
    "\n",
    "        # Construct a Bernoulli RBM to predict whether an user loves the movie or not (0 or 1)\n",
    "        # This corresponds to whether the n_hid is activated or not activated\n",
    "        return p_h_given_v, torch.bernoulli(p_h_given_v)\n",
    "\n",
    "    def sample_v(self, y):\n",
    "        \"\"\"\n",
    "        Sample the visible units\n",
    "        :param y: the dataset\n",
    "        \"\"\"\n",
    "        # print(y.mean(), y.min(), y.max())\n",
    "\n",
    "        exponents = []\n",
    "        for k in range(self.K):\n",
    "            wy = torch.mm(y, self.W[k])\n",
    "            activation = wy + self.v_bias[k].expand_as(wy)\n",
    "            exponents.append(torch.exp(activation))\n",
    "\n",
    "        exponent_tensor = torch.stack(exponents)\n",
    "        exponent_sum = torch.sum(exponent_tensor, 0)\n",
    "        probs = []\n",
    "        for k in range(self.K):\n",
    "            p_v_k_given_h = exponent_tensor[k] / exponent_sum\n",
    "            # print(p_v_k_given_h.mean(), p_v_k_given_h.min(), p_v_k_given_h.max())\n",
    "            probs.append(p_v_k_given_h)\n",
    "\n",
    "        p_v_given_h = torch.stack(probs)\n",
    "        # try:\n",
    "        # print(p_v_given_h.mean(), p_v_given_h.max(), p_v_given_h.min())\n",
    "        bern = torch.bernoulli(p_v_given_h)\n",
    "        # if self.i == 0:\n",
    "        #     print(p_v_given_h[0][0][0])\n",
    "        #     print(p_v_given_h[0][0].min(), p_v_given_h[0][0].max())\n",
    "        return p_v_given_h, bern\n",
    "        # except Exception as e:\n",
    "            # raise Exception(\"bernoulli kapot\")\n",
    "\n",
    "\n",
    "\n",
    "    def train_model(self, v0, vk, ph0, phk):\n",
    "        \"\"\"\n",
    "        Perform contrastive divergence algorithm to optimize the weights that minimize the energy\n",
    "        This maximizes the log-likelihood of the model\n",
    "        \"\"\"\n",
    "\n",
    "        ph0_K = torch.stack([ph0 for _ in range(self.K)])\n",
    "        phk_K = torch.stack([phk for _ in range(self.K)])\n",
    "\n",
    "        pos = torch.bmm(torch.transpose(v0, 1, 2).cpu(), ph0_K.cpu())\n",
    "        neg = torch.bmm(torch.transpose(vk, 1, 2).cpu(), phk_K.cpu())\n",
    "        if torch.cuda.is_available():\n",
    "            pos = pos.cuda()\n",
    "            neg = neg.cuda()\n",
    "\n",
    "        w_extra = torch.transpose(pos - neg, 1, 2)\n",
    "        v_extra = torch.sum((v0 - vk), 1)\n",
    "        h_extra = torch.sum((ph0 - phk), 0)\n",
    "\n",
    "        # if self.i % 45 == 0:\n",
    "            # print(torch.max(w_extra), torch.max(v_extra), torch.max(h_extra), flush=True)\n",
    "\n",
    "        # Approximate the gradients with the CD algorithm\n",
    "        # TODO learning rate toevoegen\n",
    "        self.W += self.lr() * w_extra\n",
    "\n",
    "        # Add (difference, 0) for the tensor of 2 dimensions\n",
    "        self.v_bias += self.lr() * v_extra.unsqueeze(1)\n",
    "        self.h_bias += self.lr() * h_extra\n",
    "        self.i += 1\n",
    "\n",
    "def score_model(rbm: RBM, batch_size, train_matrix, test_matrix):\n",
    "    test_recon_error = 0  # RMSE reconstruction error initialized to 0 at the beginning of training\n",
    "    s = 0  # a counter (float type) \n",
    "    # for loop - go through every single user\n",
    "    for id_user in range(0, train_matrix.shape[0] - batch_size, batch_size):\n",
    "        v = train_matrix[id_user:id_user + batch_size]  # training set inputs are used to activate neurons of my RBM\n",
    "        vt = test_matrix[id_user:id_user + batch_size]  # target\n",
    "        v = convert_sparse_matrix_to_sparse_tensor(v)\n",
    "        vt = convert_sparse_matrix_to_sparse_tensor(vt)\n",
    "\n",
    "        v = v.to_dense()\n",
    "        vt = vt.to_dense()\n",
    "        v = v.sub(1)\n",
    "        vt = vt.sub(1)\n",
    "        if torch.cuda.is_available():\n",
    "            v = v.cuda()\n",
    "            vt = vt.cuda()\n",
    "\n",
    "        if len(vt[vt > -1]) > 0:\n",
    "            _, h = rbm.sample_h(v)\n",
    "            _, v = rbm.sample_v(h)\n",
    "\n",
    "            # Update test RMSE reconstruction error\n",
    "            test_recon_error += torch.mean((vt[vt > -1] - v[vt > -1])**2) * len(vt > -1) \n",
    "            s += len(vt > -1)\n",
    "\n",
    "    return torch.sqrt(test_recon_error / s)\n",
    "\n",
    "\n",
    "# https://stackoverflow.com/questions/40896157/scipy-sparse-csr-matrix-to-tensorflow-sparsetensor-mini-batch-gradient-descent\n",
    "def convert_sparse_matrix_to_sparse_tensor(X, k=5):\n",
    "    coo = X.tocoo()\n",
    "\n",
    "    values = coo.data\n",
    "    indices = np.vstack((coo.row, coo.col))\n",
    "    i = torch.LongTensor(indices)\n",
    "    v = torch.DoubleTensor(values)\n",
    "    tensor_list = []\n",
    "\n",
    "    for index in range(k):\n",
    "        value = index + 1\n",
    "        yeet = torch.where(v == value, 2., 1.)\n",
    "        shape = coo.shape\n",
    "        tensor = torch.sparse.DoubleTensor(i, yeet, torch.Size(shape)) \n",
    "        if torch.cuda.is_available():\n",
    "            tensor = tensor.cuda()\n",
    "\n",
    "        tensor_list.append(tensor)\n",
    "\n",
    "    tensor = torch.stack(tensor_list) \n",
    "    return tensor\n",
    "\n",
    "def create_rbm(train_matrix, test_matrix, n_hidden, batch_size, epochs, rbm=None, k=5) -> RBM:\n",
    "    n_vis = train_matrix.shape[1]\n",
    "    train_errors = []\n",
    "    test_errors = []\n",
    "    if rbm is None:\n",
    "        rbm = RBM(n_vis, n_hidden, k, batch_size)\n",
    "\n",
    "    print(\"start training\")\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        rbm.train()\n",
    "        train_recon_error = 0  # RMSE reconstruction error initialized to 0 at the beginning of training\n",
    "        s = 0\n",
    "        \n",
    "        for user_id in range(0, train_matrix.shape[0] - batch_size, batch_size):\n",
    "            training_sample = train_matrix[user_id : user_id + batch_size]\n",
    "            # training_sample2 = train_matrix[user_id : user_id + batch_size]\n",
    "            # print(training_sample)\n",
    "            v0 = convert_sparse_matrix_to_sparse_tensor(training_sample)\n",
    "            # print(v0.coalesce().indices())\n",
    "            # vk = convert_sparse_matrix_to_sparse_tensor(training_sample2)\n",
    "\n",
    "            v0 = v0.to_dense()\n",
    "            # vk = vk.to_dense()\n",
    "            v0 = v0.sub(1)\n",
    "            # vk = vk.sub(1)\n",
    "            # v0[v0 == -2] = 0\n",
    "            # vk[vk == -2] = 0\n",
    "\n",
    "            vk = v0.detach().clone()\n",
    "\n",
    "            # v0.unsqueeze_(-1)\n",
    "            # v0 = v0.expand(v0.shape[0], v0.shape[1], rbm.K)\n",
    "            # vk.unsqueeze_(-1)\n",
    "            # vk = vk.expand(vk.shape[0], vk.shape[1], rbm.K)\n",
    "\n",
    "            # v0 = torch.transpose(v0, 0, 2)\n",
    "            # vk = torch.transpose(vk, 0, 2)\n",
    "\n",
    "            # for i in range(rbm.K):\n",
    "            #     v0[i][v0[i] != i+1] = 0\n",
    "            #     # v0[i][(v0[i] != i+1) & (v0[i] != -1)] = 0\n",
    "            #     v0[i][v0[i] == i+1] = 1\n",
    "            \n",
    "            ph0, _ = rbm.sample_h(v0)\n",
    "            _, hk = rbm.sample_h(vk)\n",
    "            _, vk = rbm.sample_v(hk)\n",
    "            vk[v0 < 0] = v0[v0 < 0]\n",
    "\n",
    "            # Third for loop - perform contrastive divergence\n",
    "            # TODO misschien is iets lager proberen?\n",
    "            # for k in range(1):\n",
    "                # _, hk = rbm.sample_h(vk)\n",
    "                # _, vk = rbm.sample_v(hk)\n",
    "\n",
    "                # We don't want to learn when there is no rating by the user, and there is no update when rating = -1\n",
    "                # Remove indices from vk vector that are not in the v0 vector => get sparse tensor again\n",
    "                # vk[v0 < 0] = v0[v0 < 0]\n",
    "                \n",
    "            phk, _ = rbm.sample_h(vk)\n",
    "\n",
    "            rbm.train_model(v0, vk, ph0, phk)\n",
    "            # vk, _ = rbm.sample_v(hk)\n",
    "\n",
    "            # TODO alle ^2 errors optellen\n",
    "            # TODO check is met tensorflow implementatie\n",
    "            \n",
    "            train_recon_error += torch.mean((v0[v0 > -1] - vk[v0 > -1])**2) * len(v0 > -1)\n",
    "            s += len(v0 > -1)\n",
    "            \n",
    "        train_errors.append(torch.sqrt(train_recon_error / s))\n",
    "\n",
    "        # print('calculating test scores')\n",
    "        rbm.eval()\n",
    "        test_errors.append(score_model(rbm, batch_size, train_matrix, test_matrix))\n",
    "\n",
    "        # print('finished epoch', epoch)    \n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "    # Plot the RMSE reconstruction error with respect to increasing number of epochs\n",
    "    plt.plot(torch.Tensor(train_errors, device='cpu'), label=\"train\")\n",
    "    plt.plot(torch.Tensor(test_errors, device='cpu'), label=\"test\")\n",
    "    plt.ylabel('Error')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend()\n",
    "    plt.savefig(f'netflix-{n_hidden}-{batch_size}-{epochs}.jpg')\n",
    "\n",
    "    return rbm, train_errors, test_errors\n",
    "\n",
    "# Evaluate the RBM on test set\n",
    "# test_recon_error = score_model(rbm)\n",
    "# print(\"Final error\", test_recon_error)\n",
    "# rbm, train, test = create_rbm(train_matrix, test_matrix, 100, 4000, 1, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"rbm_netflix1.p\", \"wb\") as f:\n",
    "    # pickle.dump(rbm, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(rbm.state_dict(), \"./network-netflix1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"rbm_netflix1.p\", \"rb\") as f:\n",
    "    # rbm = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RBM()"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rbm = RBM(train_matrix.shape[1], 101, 5, 4000)\n",
    "rbm.load_state_dict(torch.load('./network-netflix1'))\n",
    "rbm.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 662/662 [04:19<00:00,  2.55it/s]\n"
     ]
    }
   ],
   "source": [
    "def compute_hr(train_matrix, test_matrix, rbm, k=10, batch_size=100):\n",
    "    hitrates = []\n",
    "    recall = []\n",
    "    nDCG = []\n",
    "    # for loop - go through every single user\n",
    "    for id_user in tqdm(range(0, train_matrix.shape[0] - rbm.batch_size, rbm.batch_size)): # - batch_size, batch_size):\n",
    "        v = train_matrix[id_user:id_user + rbm.batch_size]  # training set inputs are used to activate neurons of my RBM\n",
    "        vt = test_matrix[id_user:id_user + rbm.batch_size]  # target\n",
    "        if vt.getnnz() == 0:\n",
    "            continue\n",
    "\n",
    "        v = convert_sparse_matrix_to_sparse_tensor(v)\n",
    "        vt = convert_sparse_matrix_to_sparse_tensor(vt)\n",
    "        v = v.to_dense()\n",
    "        vt = vt.to_dense()\n",
    "        v = v.sub(1)\n",
    "        vt = vt.sub(1)\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            vt = vt.cuda()\n",
    "            v = v.cuda()\n",
    "\n",
    "        # ground truth\n",
    "        ratings, users, movies = (vt > 0).nonzero(as_tuple=True)\n",
    "\n",
    "        indices = torch.stack([users, movies])\n",
    "        shape = (rbm.batch_size, train_matrix.shape[1])\n",
    "        target = torch.sparse.LongTensor(indices, torch.add(ratings, 1), torch.Size(shape))\n",
    "        target_dense = target.to_dense()\n",
    "\n",
    "        target_rating, target_movie = torch.topk(target_dense, k, 1)\n",
    "        target_movie[target_rating < 3] = -1 # remove all bad movies from top k\n",
    "\n",
    "        values, _ = torch.max(target_movie, dim=1)\n",
    "        users_with_target = (values > -1).nonzero(as_tuple=True)[0].cpu().tolist()\n",
    "\n",
    "        # _, order = torch.sort(ratings[ratings >= 2], descending=True)\n",
    "        # target_users = torch.index_select(users[ratings >= 2], 0, order) \n",
    "        # target_recommendations = torch.index_select(movies[ratings >= 2], 0, order) \n",
    "\n",
    "        # predicted\n",
    "        _, h = rbm.sample_h(v)\n",
    "        recommended, _ = rbm.sample_v(h)\n",
    "\n",
    "        scaled_tensors = [recommended[0]]\n",
    "        for i in range(1, rbm.K):\n",
    "            scaled_tensors.append(recommended[i] * (i+1))\n",
    "        recommended_scaled = torch.stack(scaled_tensors)\n",
    "        recommended_summed = torch.sum(recommended_scaled, 0)\n",
    "        predicted_rating, predicted_movie = torch.topk(recommended_summed, k)\n",
    "\n",
    "        # TODO optimize range s.t. users without target are skipped\n",
    "\n",
    "        for user in users_with_target:\n",
    "\n",
    "            # all recommendations\n",
    "            user_target = target_movie[user].cpu().tolist()\n",
    "            user_pred = predicted_movie[user].cpu().tolist()\n",
    "\n",
    "            counter = 0\n",
    "            total = len(user_target)\n",
    "            for target in user_target:\n",
    "                if target in user_pred:\n",
    "                    counter += 1\n",
    "            # counter = len(recommendations)\n",
    "\n",
    "            recall.append(counter / total)\n",
    "            hitrates.append(min(1, counter))\n",
    "\n",
    "            # nDCG\n",
    "            idcg = np.sum([1 / np.log2(i+2) for i in range(min(k, len(user_target)))])\n",
    "            dcg = 0\n",
    "            for i, r in enumerate(user_pred):\n",
    "                if r in user_target:\n",
    "                    dcg += 1 / np.log2(i+2)\n",
    "\n",
    "            nDCG.append(dcg / idcg) \n",
    "\n",
    "    return hitrates, recall, nDCG\n",
    "\n",
    "h, r, n = compute_hr(train_matrix, test_matrix, rbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0028320608348452406\n",
      "0.0002832060834845241\n",
      "0.00020293384669478723\n"
     ]
    }
   ],
   "source": [
    "print(np.average(h))\n",
    "print(np.average(r))\n",
    "print(np.average(n))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ac59ebe37160ed0dfa835113d9b8498d9f09ceb179beaac4002f036b9467c963"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

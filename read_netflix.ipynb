{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle as pickle\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "import gzip\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "import math\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "tqdm.pandas() #for progres_apply etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1425333it [00:00, 1628583.24it/s]\n"
     ]
    }
   ],
   "source": [
    "def parse_probe():\n",
    "    parsed_data = []\n",
    "    with open(f\"netflix/probe.txt\") as f:\n",
    "        movie = None\n",
    "        for line in tqdm(f):\n",
    "            if line[-2] == \":\":\n",
    "                movie = int(line[:-2])\n",
    "            else:\n",
    "                user = line[:-1]\n",
    "                parsed_data.append({\"movie_user\": str(movie) + \"_\" + user, \"movie\": movie, \"user\": int(user)})\n",
    "\n",
    "    return pd.DataFrame.from_dict(parsed_data)\n",
    "\n",
    "df_val = parse_probe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24058263it [00:21, 1120694.96it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie</th>\n",
       "      <th>user</th>\n",
       "      <th>rating</th>\n",
       "      <th>time</th>\n",
       "      <th>movie_user</th>\n",
       "      <th>validation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1488844</td>\n",
       "      <td>3</td>\n",
       "      <td>2005-09-06</td>\n",
       "      <td>1_1488844</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>822109</td>\n",
       "      <td>5</td>\n",
       "      <td>2005-05-13</td>\n",
       "      <td>1_822109</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>885013</td>\n",
       "      <td>4</td>\n",
       "      <td>2005-10-19</td>\n",
       "      <td>1_885013</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>30878</td>\n",
       "      <td>4</td>\n",
       "      <td>2005-12-26</td>\n",
       "      <td>1_30878</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>823519</td>\n",
       "      <td>3</td>\n",
       "      <td>2004-05-03</td>\n",
       "      <td>1_823519</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movie     user  rating        time movie_user  validation\n",
       "0      1  1488844       3  2005-09-06  1_1488844       False\n",
       "1      1   822109       5  2005-05-13   1_822109       False\n",
       "2      1   885013       4  2005-10-19   1_885013       False\n",
       "3      1    30878       4  2005-12-26    1_30878        True\n",
       "4      1   823519       3  2004-05-03   1_823519       False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def parse_netflix():\n",
    "    parsed_data = []\n",
    "    for i in range(1, 2):\n",
    "        with open(f\"netflix/combined_data_{i}.txt\") as f:\n",
    "            movie = None\n",
    "            for line in tqdm(f):\n",
    "                if line[-2] == \":\":\n",
    "                    movie = int(line[:-2])\n",
    "                else:\n",
    "                    user, rating, rating_time = line[:-1].split(',')\n",
    "                    movie_user = str(movie) + \"_\" + user\n",
    "                    parsed_data.append({\"movie\": movie, \"user\": int(user), \"rating\": int(rating), \"time\": rating_time, \"movie_user\": movie_user})\n",
    "\n",
    "    return pd.DataFrame.from_dict(parsed_data)\n",
    "\n",
    "df = parse_netflix()\n",
    "df[\"validation\"] = df.movie_user.isin(df_val.movie_user)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "34 seconden lezen, 36 seconden df maken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_min = df.drop(columns=[\"time\", \"movie_user\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie</th>\n",
       "      <th>user</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.405376e+07</td>\n",
       "      <td>2.405376e+07</td>\n",
       "      <td>2.405376e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.308324e+03</td>\n",
       "      <td>1.322285e+06</td>\n",
       "      <td>3.599634e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.303909e+03</td>\n",
       "      <td>7.645779e+05</td>\n",
       "      <td>1.086118e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.180000e+03</td>\n",
       "      <td>6.609270e+05</td>\n",
       "      <td>3.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.342000e+03</td>\n",
       "      <td>1.318602e+06</td>\n",
       "      <td>4.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.433000e+03</td>\n",
       "      <td>1.984358e+06</td>\n",
       "      <td>4.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.499000e+03</td>\n",
       "      <td>2.649429e+06</td>\n",
       "      <td>5.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              movie          user        rating\n",
       "count  2.405376e+07  2.405376e+07  2.405376e+07\n",
       "mean   2.308324e+03  1.322285e+06  3.599634e+00\n",
       "std    1.303909e+03  7.645779e+05  1.086118e+00\n",
       "min    1.000000e+00  6.000000e+00  1.000000e+00\n",
       "25%    1.180000e+03  6.609270e+05  3.000000e+00\n",
       "50%    2.342000e+03  1.318602e+06  4.000000e+00\n",
       "75%    3.433000e+03  1.984358e+06  4.000000e+00\n",
       "max    4.499000e+03  2.649429e+06  5.000000e+00"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_min.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_min[df[\"validation\"] == False]\n",
    "df_val = df_min[df[\"validation\"] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24053764, 4)\n",
      "(23476551, 4)\n",
      "(577213, 4)\n"
     ]
    }
   ],
   "source": [
    "print(df_min.shape)\n",
    "print(df_train.shape)\n",
    "print(df_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# long operation\n",
    "df_train_grouped = df_train.groupby([\"user\"]).agg(list)\n",
    "df_val_grouped = df_val.groupby([\"user\"]).agg(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sparse_matrix(df):\n",
    "    shape = (df_min['user'].max() + 1, df_min['movie'].max() + 1)\n",
    "    \n",
    "    user_ids = []\n",
    "    item_ids = []\n",
    "    values = []\n",
    "    for idx, row in tqdm(df.iterrows()):\n",
    "        items = row['movie']\n",
    "        user = row['user']\n",
    "    \n",
    "        rating = row['rating']\n",
    "        user_ids.extend([user] * len(items))\n",
    "        item_ids.extend(items)\n",
    "        values.extend(rating)\n",
    "    #create csr matrix\n",
    "    # values = np.ones(len(user_ids))\n",
    "    matrix = scipy.sparse.csr_matrix((values, (user_ids, item_ids)), shape=shape, dtype=np.int32)\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_grouped = df_train_grouped.reset_index()\n",
    "df_val_grouped = df_val_grouped.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "321679it [00:08, 39992.85it/s]\n",
      "448719it [00:12, 36529.24it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<2649430x4500 sparse matrix of type '<class 'numpy.intc'>'\n",
       "\twith 23476551 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_matrix = get_sparse_matrix(df_val_grouped)\n",
    "\n",
    "train_matrix = get_sparse_matrix(df_train_grouped)\n",
    "train_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [19:39<00:00, 1179.17s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RBM()"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZUAAAEICAYAAACXo2mmAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAff0lEQVR4nO3de5BV5Z3u8e9Dc1OiiNA6CnIghiSSYFrdgVwtrycoM2LGHC5BR3MpooGjdXLigBWSE83UjHJmjPGExMKEFCdBQM2tnXjiLTrR0iQ0hhFQsFs01Y1GW8QrXkB+54/9ti6a3dCXtXrT8HyqdvV6L2ut96WreHrtd++1FBGYmZnloV+1B2BmZvsPh4qZmeXGoWJmZrlxqJiZWW4cKmZmlhuHipmZ5abQUJE0WdJGSU2S5ldov1jSWklrJD0gaXyqn5Xq2l47JdWltumSHpG0XtI1mWMNkrQyneuPksYUOTczM9udivqeiqQa4HHgTKAFWAXMjIhHM30OjYiX0/Y5wFcjYnK740wAfhURx0oaDvwZOCkiWiUtBf5vRNwj6avA8RFxsaQZwGcjYvqexjhixIgYM2ZMbnM2MzsQrF69+vmIqK3U1r/A804EmiJiE4CkFcBU4J1QaQuUZAhQKeFmAivS9nuBxohoTeW7gfOAe9Kxv53qbwW+L0mxh9QcM2YMDQ0NXZyWmdmBTdJfOmorMlRGAs2ZcgswqX0nSXOArwEDgdMqHGc65cAAaAI+kN7aagHOTfvtcr6I2CHpJWA48Hy7880GZgOMHj2667MyM7MOVX2hPiIWRcSxwDxgQbZN0iRgW0SsS323ApcAK4H7gaeAt7t4vsURUYqIUm1txas3MzPrpiJDZTNwTKY8KtV1ZAXlK4+sGcDybEVE3BYRkyLi48BGyus2u5xPUn9gKLClu4M3M7OuK/Ltr1XAOEljKf+HPwP4fLaDpHER0ZiKU4DGTFs/YBrw6Xb7HBERz0kaBnw19QGoBy4EHgI+B/xuT+spZmbdtX37dlpaWnjjjTeqPZRCDR48mFGjRjFgwIBO71NYqKR1jbnAHUANsCQi1ku6CmiIiHpgrqQzgO3AVsqh0OZkoLltoT/je5I+kravioi2K5UfAz+V1AS8QDnEzMxy19LSwiGHHMKYMWOQVO3hFCIi2LJlCy0tLYwdO7bT+xX2keK+oFQqhT/9ZWZd9dhjj/HBD35wvw2UNhHBhg0bOO6443apl7Q6IkqV9qn6Qr2ZWV+0vwcKdG+ODhUzM8uNQ8XMrI958cUX+cEPftDl/c4++2xefPHF/AeU4VAxM+tjOgqVHTt27HG/22+/ncMOO6ygUZUV+ZFiMzMrwPz583niiSeoq6tjwIABDB48mGHDhrFhwwYef/xxzj33XJqbm3njjTe47LLLmD17NvDuraleffVVzjrrLD71qU/x4IMPMnLkSH79619z0EEH9XhsDhUzsx648rb1PPr0y3vv2AXjjz6U//V3H+qw/eqrr2bdunWsWbOG++67jylTprBu3bp3Pvq7ZMkSDj/8cF5//XU++tGPct555zF8+PBdjtHY2Mjy5cu58cYbmTZtGj//+c85//zzezx2h4qZWR83ceLEXb5Lcv311/PLX/4SgObmZhobG3cLlbFjx1JXVwfASSedxFNPPZXLWBwqZmY9sKcrit4yZMiQd7bvu+8+7r77bh566CEOPvhgTjnllIrf/B80aNA72zU1Nbz++uu5jMUL9WZmfcwhhxzCK6+8UrHtpZdeYtiwYRx88MFs2LCBP/zhD706Nl+pmJn1McOHD+eTn/wkH/7whznooIM48sgj32mbPHkyN9xwA8cddxwf+MAH+NjHPtarY/NtWnybFjProscee2y3W5fsryrN1bdpMTOzXuFQMTOz3DhUzMwsNw4VMzPLjUPFzMxy41AxM7PcFBoqkiZL2iipSdL8Cu0XS1oraY2kBySNT/WzUl3ba6ekutQ2M+3ziKTfShqR6r8taXNmn7OLnJuZWbV099b3ANdddx3btm3LeUTvKixUJNUAi4CzgPHAzLbQyLgpIiZERB2wELgWICKWRURdqr8AeDIi1kjqD3wPODUijgceAeZmjvfdtv0i4vai5mZmVk37cqgU+Y36iUBTRGwCkLQCmAo82tYhIrK39hwCVPom5kxgRdpWeg2RtAU4FGjKf+hmZvuu7K3vzzzzTI444ghuvvlm3nzzTT772c9y5ZVX8tprrzFt2jRaWlp4++23+eY3v8mzzz7L008/zamnnsqIESO49957cx9bkaEyEmjOlFuASe07SZoDfA0YCJxW4TjTKYcREbFd0iXAWuA1oBGYk+k7V9I/AA3A/4yIrRXONxuYDTB69Oiuz8rMLOv/zYe/rs33mH8zAc66usPm7K3v77zzTm699Vb+9Kc/ERGcc845/P73v6e1tZWjjz6a3/zmN0D5nmBDhw7l2muv5d5772XEiBH5jjmp+kJ9RCyKiGOBecCCbJukScC2iFiXygOAS4ATgKMpv/11Rer+Q+BYoA54Bvi3Ds63OCJKEVGqra3Nf0JmZr3ozjvv5M477+SEE07gxBNPZMOGDTQ2NjJhwgTuuusu5s2bx/3338/QoUN7ZTxFXqlsBo7JlEeluo6soBwMWTOA5ZlyHUBEPAEg6WZgfqp7tq2TpBuBf+/muM3MOm8PVxS9ISK44oor+MpXvrJb28MPP8ztt9/OggULOP300/nWt75V+HiKvFJZBYyTNFbSQMoBUZ/tIGlcpjiF8ttZbW39gGm8u54C5VAaL6ntEuNM4LHU/6hMv88C63Kah5nZPiV76/vPfOYzLFmyhFdffRWAzZs389xzz/H0009z8MEHc/7553P55Zfz8MMP77ZvEQq7UomIHZLmAncANcCSiFgv6SqgISLqKa+BnAFsB7YCF2YOcTLQ3LbQn475tKQrgd9L2g78BbgoNS9MHzsO4Clg99g2M9sPZG99f9ZZZ/H5z3+ej3/84wC85z3v4Wc/+xlNTU1cfvnl9OvXjwEDBvDDH5bfCJo9ezaTJ0/m6KOPLmSh3re+963vzayLfOt73/rezMx6gUPFzMxy41AxM+uGA2HpoDtzdKiYmXXR4MGD2bJly34dLBHBli1bGDx4cJf2K/J7KmZm+6VRo0bR0tJCa2trtYdSqMGDBzNq1Kgu7eNQMTProgEDBjB27NhqD2Of5Le/zMwsNw4VMzPLjUPFzMxy41AxM7PcOFTMzCw3DhUzM8uNQ8XMzHLjUDEzs9w4VMzMLDcOFTMzy41DxczMclNoqEiaLGmjpCZJ8yu0XyxpraQ1kh6QND7Vz0p1ba+d6VHBSJqZ9nlE0m8ljUj1h0u6S1Jj+jmsyLmZmdnuCgsVSTXAIuAsYDwwsy00Mm6KiAkRUQcsBK4FiIhlEVGX6i8AnoyINZL6A98DTo2I44FHgLnpWPOBeyJiHHBPKpuZWS8q8kplItAUEZsi4i1gBTA12yEiXs4UhwCVHk4wM+0LoPQaIknAocDTqW0qsDRtLwXOzWEOZmbWBUXe+n4k0JwptwCT2neSNAf4GjAQOK3CcaaTwigitku6BFgLvAY0AnNSvyMj4pm0/VfgyEqDkjQbmA0wevTors3IzMz2qOoL9RGxKCKOBeYBC7JtkiYB2yJiXSoPAC4BTgCOpvz21xUVjhlUvuohIhZHRCkiSrW1tbnOxczsQFdkqGwGjsmUR6W6jqxg97esZgDLM+U6gIh4IgXHzcAnUtuzko4CSD+f6+7Azcyse4oMlVXAOEljJQ2kHBD12Q6SxmWKUyi/ndXW1g+YxrvrKVAOpfGS2i4xzgQeS9v1wIVp+0Lg1znNw8zMOqmwNZWI2CFpLnAHUAMsiYj1kq4CGiKiHpgr6QxgO7CVd0MB4GSgOSI2ZY75tKQrgd9L2g78BbgoNV8N3CzpS6l+WlFzMzOzylR+F+nAVCqVoqGhodrDMDPrUyStjohSpbaqL9Sbmdn+w6FiZma5caiYmVluHCpmZpYbh4qZmeXGoWJmZrlxqJiZWW4cKmZmlhuHipmZ5cahYmZmuXGomJlZbhwqZmaWG4eKmZnlxqFiZma5caiYmVluHCpmZpYbh4qZmeWm0FCRNFnSRklNkuZXaL9Y0lpJayQ9IGl8qp+V6tpeOyXVSTqkXf3zkq5L+1wkqTXT9uUi52ZmZrsr7Bn1kmqARcCZQAuwSlJ9RDya6XZTRNyQ+p8DXAtMjohlwLJUPwH4VUSsSfvUZc6xGvhF5ngrI2JuMTMyM7O9KfJKZSLQFBGbIuItYAUwNdshIl7OFIcAUeE4M9O+u5D0fuAI4P7cRmxmZj1SZKiMBJoz5ZZUtwtJcyQ9ASwELq1wnOnA8gr1MyhfmWSD6DxJj0i6VdIxlQYlabakBkkNra2tnZ2LmZl1QtUX6iNiUUQcC8wDFmTbJE0CtkXEugq7zmDXsLkNGBMRxwN3AUs7ON/iiChFRKm2tjaXOZiZWVmRobIZyF4tjEp1HVkBnNuurn1wACDpI0D/iFjdVhcRWyLizVT8EXBSN8ZsZmY9UGSorALGSRoraSDlgKjPdpA0LlOcAjRm2voB06iwnkJ5nWWXsJF0VKZ4DvBYj0ZvZmZdVtinvyJih6S5wB1ADbAkItZLugpoiIh6YK6kM4DtwFbgwswhTgaaI2JThcNPA85uV3dp+gTZDuAF4KJcJ2RmZnulXde5DyylUikaGhqqPQwzsz5F0uqIKFVqq/pCvZmZ7T8cKmZmlhuHipmZ5cahYmZmuXGomJlZbhwqZmaWG4eKmZnlxqFiZma5caiYmVluHCpmZpYbh4qZmeXGoWJmZrlxqJiZWW72GiqS+kn6RG8MxszM+ra9hkpE7AQW9cJYzMysj+vs21/3SDpPkgodjZmZ9WmdDZWvALcAb0l6WdIrkl4ucFxmZtYHdSpUIuKQiOgXEQMi4tBUPnRv+0maLGmjpCZJ8yu0XyxpraQ1kh6QND7Vz0p1ba+dkuokHdKu/nlJ16V9Bklamc71R0ljuvZPYWZmPdXpZ9Sn57+fnIr3RcS/76V/DeW1mDOBFmCVpPqIeDTT7aaIuCFz/GuByRGxDFiW6icAv4qINWmfusw5VgO/SMUvAVsj4n2SZgDXANM7Oz8zM+u5Tl2pSLoauAx4NL0uk/Qve9ltItAUEZsi4i1gBTA12yEism+hDQGiwnFmpn3bj+n9wBHA/alqKrA0bd8KnO41IDOz3tXZK5Wzgbr0STAkLQX+DFyxh31GAs2ZcgswqX0nSXOArwEDgdMqHGc67cIomQGsjIi2IHrnfBGxQ9JLwHDg+Xbnmw3MBhg9evQehm9mZl3VlS8/HpbZHprXACJiUUQcC8wDFmTbJE0CtkXEugq7zgCWd+N8iyOiFBGl2trabo3ZzMwq6+yVyj8Df5Z0LyDKayu7Lby3sxk4JlMeleo6sgL4Ybu6isEh6SNA/4hYXeF8LZL6Uw6+LXsZo5mZ5WivoSKpH7AT+Bjw0VQ9LyL+upddVwHjJI2l/B/+DODz7Y49LiIaU3EK0Jhp6wdMAz5d4dgz2T1s6oELgYeAzwG/y7w1ZmZmvWCvoRIROyX9Y0TcTPk/7k5J6xpzgTuAGmBJRKyXdBXQEBH1wFxJZwDbga2UQ6HNyUBzRGyqcPhplNd5sn4M/FRSE/AC5RAzM7NepM78MZ8+/fU8sBJ4ra0+Il4obmjFK5VK0dDQUO1hmJn1KZJWR0SpUltn11Tavu8xJ1MXwHt7MjAzM9u/dHZNZX5ErOyF8ZiZWR/W2bsUX94LYzEzsz6us99TuVvS1yUdI+nwtlehIzMzsz7HaypmZpabToVKRIwteiBmZtb37fHtL0n/mNn+b+3a/rmoQZmZWd+0tzWV7BcI2988cnLOYzEzsz5ub6GiDrYrlc3M7AC3t1CJDrYrlc3M7AC3t4X6j6Rn0Qs4KPNcegGDCx2ZmZn1OXsMlYio6a2BmJlZ39eVh3SZmZntkUPFzMxy41AxM7PcOFTMzCw3DhUzM8tNoaEiabKkjZKaJM2v0H6xpLWS1kh6QNL4VD8r1bW9dkqqS20DJS2W9LikDZLOS/UXSWrN7PPlIudmZma76+xdirtMUg2wCDgTaAFWSaqPiEcz3W6KiBtS/3OAa4HJEbEMWJbqJwC/iog1aZ9vAM9FxPvTA8Syt+BfGRFzi5qTmZntWWGhAkwEmiJiE4CkFcBU4J1QiYiXM/2HUPlb+jOBFZnyF4EPpv13As/nO2wzM+uuIt/+Ggk0Z8otqW4XkuZIegJYCFxa4TjTgeWp72Gp7juSHpZ0i6QjM33Pk/SIpFslHVNpUJJmS2qQ1NDa2tr1WZmZWYeqvlAfEYsi4lhgHrAg2yZpErAtItalqv7AKODBiDgReAj419R2GzAmIo4H7gKWdnC+xRFRiohSbW1t/hMyMzuAFRkqm4Hs1cKoVNeRFcC57epmkK5Ski3ANuAXqXwLcCJARGyJiDdT/Y+Ak7o1ajMz67YiQ2UVME7SWEkDKQdEfbaDpHGZ4hSgMdPWD5hGZj0lIoLyFckpqep00hqNpKMyxzoHeCyviZiZWecUtlAfETskzQXuAGqAJRGxXtJVQENE1ANzJZ0BbAe2AhdmDnEy0Ny20J8xD/ippOuAVuALqf7S9AmyHcALwEXFzMzMzDqi8h//B6ZSqRQNDQ3VHoaZWZ8iaXVElCq1VX2h3szM9h8OFTMzy41DxczMcuNQMTOz3DhUzMwsNw4VMzPLjUPFzMxy41AxM7PcOFTMzCw3DhUzM8uNQ8XMzHLjUDEzs9w4VMzMLDcOFTMzy41DxczMcuNQMTOz3DhUzMwsN4WGiqTJkjZKapI0v0L7xZLWSloj6QFJ41P9rFTX9topqS61DZS0WNLjkjZIOi/VD5K0Mp3rj5LGFDk3MzPbXWGhIqkGWAScBYwHZraFRsZNETEhIuqAhcC1ABGxLCLqUv0FwJMRsSbt8w3guYh4fzruf6T6LwFbI+J9wHeBa4qam5mZVVbklcpEoCkiNkXEW8AKYGq2Q0S8nCkOAaLCcWamfdt8EfiXtP/OiHg+1U8FlqbtW4HTJanHszAzs04rMlRGAs2Zckuq24WkOZKeoHylcmmF40wHlqe+h6W670h6WNItko5sf76I2AG8BAyvcL7ZkhokNbS2tnZrYmZmVlnVF+ojYlFEHAvMAxZk2yRNArZFxLpU1R8YBTwYEScCDwH/2sXzLY6IUkSUamtrez4BMzN7R5Ghshk4JlMeleo6sgI4t13dDNJVSrIF2Ab8IpVvAU5sfz5J/YGhqb+ZmfWSIkNlFTBO0lhJAykHRH22g6RxmeIUoDHT1g+YRmY9JSICuA04JVWdDjyatuuBC9P254Dfpf5mZtZL+hd14IjYIWkucAdQAyyJiPWSrgIaIqIemCvpDGA7sJV3QwHgZKA5Ija1O/Q84KeSrgNagS+k+h+n+ibgBcohZmZmvUgH8h/zpVIpGhoaqj0MM7M+RdLqiChVaqv6Qr2Zme0/HCpmZpYbh4qZmeXGoWJmZrlxqJiZWW4cKmZmlhuHipmZ5cahYmZmuXGomJlZbhwqZmaWG4eKmZnlxqFiZma5caiYmVluHCpmZpYbh4qZmeXGoWJmZrlxqJiZWW4KDRVJkyVtlNQkaX6F9oslrZW0RtIDksan+lmpru21U1JdarsvHbOt7YhUf5Gk1kz9l4ucm5mZ7a6wZ9RLqgEWAWcCLcAqSfUR8Wim200RcUPqfw5wLTA5IpYBy1L9BOBXEbEms9+siKj0HOCVETE3/9mYmVlnFHmlMhFoiohNEfEWsAKYmu0QES9nikOAqHCcmWlfMzPbxxUZKiOB5ky5JdXtQtIcSU8AC4FLKxxnOrC8Xd1P0ltc35SkTP15kh6RdKukYyoNStJsSQ2SGlpbW7s0ITMz27OqL9RHxKKIOBaYByzItkmaBGyLiHWZ6lkRMQH4dHpdkOpvA8ZExPHAXcDSDs63OCJKEVGqra3NeTZmZge2IkNlM5C9WhiV6jqyAji3Xd0M2l2lRMTm9PMV4CbKb7MREVsi4s3U7UfASd0duJmZdU+RobIKGCdprKSBlAOiPttB0rhMcQrQmGnrB0wjs54iqb+kEWl7APC3wLpUPipzrHOAx3KdjZmZ7VVhn/6KiB2S5gJ3ADXAkohYL+kqoCEi6oG5ks4AtgNbgQszhzgZaI6ITZm6QcAdKVBqgLuBG1PbpekTZDuAF4CLipqbmZlVpohKH7g6MJRKpWhoqPTJZDMz64ik1RFRqtRW9YV6MzPbfzhUzMwsNw4VMzPLjUPFzMxy41AxM7PcOFTMzCw3DhUzM8uNQ8XMzHLjUDEzs9w4VMzMLDcOFTMzy41DxczMcuNQMTOz3DhUzMwsNw4VMzPLjUPFzMxyU2ioSJosaaOkJknzK7RfLGmtpDWSHpA0PtXPSnVtr52S6lLbfemYbW1HpPpBklamc/1R0pgi52ZmZrsrLFQk1QCLgLOA8cDMttDIuCkiJkREHbAQuBYgIpZFRF2qvwB4MiLWZPab1dYeEc+lui8BWyPifcB3gWsKmpqZmXWgyCuViUBTRGyKiLeAFcDUbIeIeDlTHAJUerbxzLTv3kwFlqbtW4HTJanLozYzs27rX+CxRwLNmXILMKl9J0lzgK8BA4HTKhxnOu3CCPiJpLeBnwP/FBGRPV9E7JD0EjAceL6H8zAzs06q+kJ9RCyKiGOBecCCbJukScC2iFiXqZ4VEROAT6fXBV05n6TZkhokNbS2tvZw9GZmllVkqGwGjsmUR6W6jqwAzm1XNwNYnq2IiM3p5yvATZTfZtvlfJL6A0OBLe1PEhGLI6IUEaXa2trOzsXMzDqhyFBZBYyTNFbSQMoBUZ/tIGlcpjgFaMy09QOmkVlPkdRf0oi0PQD4W6DtKqYeuDBtfw74XXpbzMzMeklhayppXWMucAdQAyyJiPWSrgIaIqIemCvpDGA7sJV3QwHgZKA5IjZl6gYBd6RAqQHuBm5MbT8GfiqpCXiBcoiZmVkv0oH8x3ypVIqGhoZqD8PMrE+RtDoiSpXaqr5Qb2Zm+w+HipmZ5cahYmZmuTmg11QktQJ/qfY4umEEB96XOg+0OR9o8wXPuS/5LxFR8TsZB3So9FWSGjpaJNtfHWhzPtDmC57z/sJvf5mZWW4cKmZmlhuHSt+0uNoDqIIDbc4H2nzBc94veE3FzMxy4ysVMzPLjUPFzMxy41DZR0k6XNJdkhrTz2Ed9Lsw9WmUdGGF9npJ6yrtuy/pyXwlHSzpN5I2SFov6ereHX3XSJosaaOkJknzK7QPkrQytf9R0phM2xWpfqOkz/TqwHugu3OWdKak1ZLWpp+VHuS3T+rJ7zm1j5b0qqSv99qg8xARfu2DL2AhMD9tzweuqdDncGBT+jksbQ/LtP895WfOrKv2fIqcL3AwcGrqMxC4Hzir2nPqYJ41wBPAe9NY/xMY367PV4Eb0vYMYGXaHp/6DwLGpuPUVHtOBc/5BODotP1hYHO151P0nDPttwK3AF+v9ny68vKVyr5rKrA0bS9l9weYAXwGuCsiXoiIrcBdwGQASe+h/Jjmfyp+qLno9nwjYltE3AsQEW8BD1N+KNy+aCLQFBGb0lhXsPvjsrP/FrcCp0tSql8REW9GxJNAE+8+pG5f1u05R8SfI+LpVL8eOEjSoF4Zdc/05PeMpHOBJynPuU9xqOy7joyIZ9L2X4EjK/QZCTRnyi2pDuA7wL8B2wobYb56Ol8AJB0G/B1wTwFjzMNe55DtExE7gJeA4Z3cd1/UkzlnnQc8HBFvFjTOPHV7zukPwnnAlb0wztwV9pAu2ztJdwN/U6HpG9lCRISkTn/2W1IdcGxE/I/279NWU1HzzRy/P+XHT18fuz7czfo4SR8CrgH+a7XH0gu+DXw3Il5NFy59ikOliiLijI7aJD0r6aiIeEbSUcBzFbptBk7JlEcB9wEfB0qSnqL8Oz5C0n0RcQpVVOB82ywGGiPiup6PtjCbgWMy5VGprlKflhSUQ4Etndx3X9STOSNpFPBL4B8i4onih5uLnsx5EvA5SQuBw4Cdkt6IiO8XPuo8VHtRx6/KL+B/s+vC9cIKfQ6n/L7rsPR6Eji8XZ8x9I2F+h7Nl/La0c+BftWey17m2Z/yBwzG8u4C7ofa9ZnDrgu4N6ftD7HrQv0m+sZCfU/mfFjq//fVnkdvzbldn2/Txxbqqz4Avzr4xZTfT74HaATuzvznWQJ+lOn3RcoLtk3AFyocp6+ESrfnS/mvwAAeA9ak15erPac9zPVs4HHKnw76Rqq7CjgnbQ+m/KmfJuBPwHsz+34j7beRffQTbnnOGVgAvJb5va4Bjqj2fIr+PWeO0edCxbdpMTOz3PjTX2ZmlhuHipmZ5cahYmZmuXGomJlZbhwqZmaWG4eKWYEkvS1pTea1291qe3DsMX3hDtR2YPE36s2K9XpE1FV7EGa9xVcqZlUg6SlJC9NzQv4k6X2pfoyk30l6RNI9kkan+iMl/VLSf6bXJ9KhaiTdmJ4jc6ekg6o2KTMcKmZFO6jd21/TM20vRcQE4PvAdanu/wBLI+J4YBlwfaq/HviPiPgIcCLv3hJ9HLAoIj4EvEj5Tr5mVeNv1JsVSNKrEfGeCvVPAadFxCZJA4C/RsRwSc8DR0XE9lT/TESMkNQKjIrMbd/THajviohxqTwPGBARfeUZOrYf8pWKWfVEB9tdkX22yNt4ndSqzKFiVj3TMz8fStsPUr5jLcAsyo9GhvLNNi8BkFQjaWhvDdKsK/xXjVmxDpK0JlP+bUS0fax4mKRHKF9tzEx1/x34iaTLgVbgC6n+MmCxpC9RviK5BHgGs32M11TMqiCtqZQi4vlqj8UsT377y8zMcuMrFTMzy42vVMzMLDcOFTMzy41DxczMcuNQMTOz3DhUzMwsN/8fJF4OkplUPxMAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# https://github.com/khanhnamle1994/MetaRec/blob/b5e36cb579a88b32cdfb728f35f645d76b24ad95/Boltzmann-Machines-Experiments/RBM-CF-PyTorch/rbm.py#L23\n",
    "# Create the Restricted Boltzmann Machine architecture\n",
    "class RBM(nn.Module):\n",
    "    def __init__(self, n_vis, n_hid, k):\n",
    "        \"\"\"\n",
    "        Initialize the parameters (weights and biases) we optimize during the training process\n",
    "        :param n_vis: number of visible units\n",
    "        :param n_hid: number of hidden units\n",
    "        \"\"\"\n",
    "        self.i = 0\n",
    "        self.K = k\n",
    "\n",
    "        # Weights used for the probability of the visible units given the hidden units\n",
    "        super().__init__()\n",
    "        self.W = torch.zeros(k, n_hid, n_vis)  # torch.rand: random normal distribution mean = 0, variance = 1\n",
    "\n",
    "        # Bias probability of the visible units is activated, given the value of the hidden units (p_v_given_h)\n",
    "        self.v_bias = torch.zeros(k, 1, n_vis)  # fake dimension for the batch = 1\n",
    "\n",
    "        # Bias probability of the hidden units is activated, given the value of the visible units (p_h_given_v)\n",
    "        self.h_bias = torch.zeros(1, n_hid)  # fake dimension for the batch = 1\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            self.W = self.W.cuda()\n",
    "            self.v_bias = self.v_bias.cuda()\n",
    "            self.h_bias = self.h_bias.cuda()\n",
    "    \n",
    "    def lr(self):\n",
    "        return 0.02\n",
    "\n",
    "    def sample_h(self, x):\n",
    "        \"\"\"\n",
    "        Sample the hidden units\n",
    "        :param x: the dataset\n",
    "        \"\"\"\n",
    "\n",
    "        # Probability h is activated given that the value v is sigmoid(Wx + a)\n",
    "        # torch.mm make the product of 2 tensors\n",
    "        # W.t() take the transpose because W is used for the p_v_given_h\n",
    "\n",
    "        temp = torch.transpose(self.W, 1, 2)\n",
    "        wx = torch.bmm(x.cpu(), temp.cpu())\n",
    "        if torch.cuda.is_available():\n",
    "            wx = wx.cuda()\n",
    "        wx_sum = torch.sum(wx, 0)\n",
    "        # print(wx.shape)\n",
    "\n",
    "        # Expand the mini-batch\n",
    "        activation = wx_sum + self.h_bias.expand_as(wx_sum)\n",
    "        # print(activation.shape)\n",
    "\n",
    "        # Calculate the probability p_h_given_v\n",
    "        p_h_given_v = torch.sigmoid(activation)\n",
    "\n",
    "        # print(\"h sparse\", p_h_given_v.is_sparse, torch.bernoulli(p_h_given_v).is_sparse)\n",
    "\n",
    "        # Construct a Bernoulli RBM to predict whether an user loves the movie or not (0 or 1)\n",
    "        # This corresponds to whether the n_hid is activated or not activated\n",
    "        return p_h_given_v, torch.bernoulli(p_h_given_v)\n",
    "\n",
    "    def sample_v(self, y):\n",
    "        \"\"\"\n",
    "        Sample the visible units\n",
    "        :param y: the dataset\n",
    "        \"\"\"\n",
    "\n",
    "        exponents = []\n",
    "        for k in range(self.K):\n",
    "            wy = torch.mm(y, self.W[k])\n",
    "            activation = wy + self.v_bias[k].expand_as(wy)\n",
    "            exponents.append(torch.exp(activation))\n",
    "\n",
    "        exponent_tensor = torch.stack(exponents)\n",
    "        exponent_sum = torch.sum(exponent_tensor, 0)\n",
    "        probs = []\n",
    "        for k in range(self.K):\n",
    "            p_v_k_given_h = exponent_tensor[k] / exponent_sum\n",
    "            probs.append(p_v_k_given_h)\n",
    "\n",
    "        p_v_given_h = torch.stack(probs)\n",
    "        return p_v_given_h, torch.bernoulli(p_v_given_h)\n",
    "\n",
    "    def train_model(self, v0, vk, ph0, phk):\n",
    "        \"\"\"\n",
    "        Perform contrastive divergence algorithm to optimize the weights that minimize the energy\n",
    "        This maximizes the log-likelihood of the model\n",
    "        \"\"\"\n",
    "\n",
    "        ph0_K = torch.stack([ph0 for _ in range(self.K)])\n",
    "        phk_K = torch.stack([phk for _ in range(self.K)])\n",
    "\n",
    "        pos = torch.bmm(torch.transpose(v0, 1, 2).cpu(), ph0_K.cpu())\n",
    "        neg = torch.bmm(torch.transpose(vk, 1, 2).cpu(), phk_K.cpu())\n",
    "        if torch.cuda.is_available():\n",
    "            pos = pos.cuda()\n",
    "            neg = neg.cuda()\n",
    "\n",
    "        w_extra = torch.transpose(pos - neg, 1, 2)\n",
    "        v_extra = torch.sum((v0 - vk), 1)\n",
    "        h_extra = torch.sum((ph0 - phk), 0)\n",
    "\n",
    "        # if self.i % 45 == 0:\n",
    "            # print(torch.max(w_extra), torch.max(v_extra), torch.max(h_extra), flush=True)\n",
    "\n",
    "        # Approximate the gradients with the CD algorithm\n",
    "        # TODO learning rate toevoegen\n",
    "        self.W += self.lr() * w_extra\n",
    "\n",
    "        # Add (difference, 0) for the tensor of 2 dimensions\n",
    "        self.v_bias += self.lr() * v_extra.unsqueeze(1)\n",
    "        self.h_bias += self.lr() * h_extra\n",
    "        self.i += 1\n",
    "\n",
    "def score_model(rbm: RBM, batch_size, train_matrix, test_matrix):\n",
    "    test_recon_error = 0  # RMSE reconstruction error initialized to 0 at the beginning of training\n",
    "    s = 0  # a counter (float type) \n",
    "    # for loop - go through every single user\n",
    "    for id_user in range(0, train_matrix.shape[0] - batch_size, batch_size):\n",
    "        v = train_matrix[id_user:id_user + batch_size]  # training set inputs are used to activate neurons of my RBM\n",
    "        vt = test_matrix[id_user:id_user + batch_size]  # target\n",
    "        v = convert_sparse_matrix_to_sparse_tensor(v)\n",
    "        vt = convert_sparse_matrix_to_sparse_tensor(vt)\n",
    "\n",
    "        v = v.to_dense()\n",
    "        vt = vt.to_dense()\n",
    "        v = v.sub(1)\n",
    "        vt = vt.sub(1)\n",
    "        if torch.cuda.is_available():\n",
    "            v = v.cuda()\n",
    "            vt = vt.cuda()\n",
    "\n",
    "        if len(vt[vt > -1]) > 0:\n",
    "            _, h = rbm.sample_h(v)\n",
    "            v, _ = rbm.sample_v(h)\n",
    "\n",
    "            # Update test RMSE reconstruction error\n",
    "            test_recon_error += torch.sqrt(torch.mean((vt[vt > -1] - v[vt > -1])**2)) * len(vt > -1)\n",
    "            s += len(vt > -1) \n",
    "\n",
    "    return test_recon_error / s\n",
    "\n",
    "\n",
    "# https://stackoverflow.com/questions/40896157/scipy-sparse-csr-matrix-to-tensorflow-sparsetensor-mini-batch-gradient-descent\n",
    "def convert_sparse_matrix_to_sparse_tensor(X, k=5):\n",
    "    coo = X.tocoo()\n",
    "\n",
    "    values = coo.data\n",
    "    indices = np.vstack((coo.row, coo.col))\n",
    "    i = torch.LongTensor(indices)\n",
    "    v = torch.DoubleTensor(values)\n",
    "    tensor_list = []\n",
    "\n",
    "    for index in range(k):\n",
    "        value = index + 1\n",
    "        yeet = torch.where(v == value, 2., 1.)\n",
    "        shape = coo.shape\n",
    "        tensor = torch.sparse.DoubleTensor(i, yeet, torch.Size(shape)) \n",
    "        if torch.cuda.is_available():\n",
    "            tensor = tensor.cuda()\n",
    "\n",
    "        tensor_list.append(tensor)\n",
    "\n",
    "    tensor = torch.stack(tensor_list) \n",
    "    return tensor\n",
    "\n",
    "def create_rbm(train_matrix, test_matrix, n_hidden, batch_size, epochs, rbm=None, k=5) -> RBM:\n",
    "    n_vis = train_matrix.shape[1]\n",
    "    train_errors = []\n",
    "    test_errors = []\n",
    "    if rbm is None:\n",
    "        rbm = RBM(n_vis, n_hidden, k)\n",
    "\n",
    "    print(\"start training\")\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        rbm.train()\n",
    "        train_recon_error = 0  # RMSE reconstruction error initialized to 0 at the beginning of training\n",
    "        s = 0\n",
    "        \n",
    "        for user_id in range(0, train_matrix.shape[0] - batch_size, batch_size):\n",
    "            training_sample = train_matrix[user_id : user_id + batch_size]\n",
    "            training_sample2 = train_matrix[user_id : user_id + batch_size]\n",
    "            # print(training_sample)\n",
    "            v0 = convert_sparse_matrix_to_sparse_tensor(training_sample)\n",
    "            # print(v0.coalesce().indices())\n",
    "            vk = convert_sparse_matrix_to_sparse_tensor(training_sample2)\n",
    "\n",
    "            v0 = v0.to_dense()\n",
    "            vk = vk.to_dense()\n",
    "            v0 = v0.sub(1)\n",
    "            vk = vk.sub(1)\n",
    "            # v0[v0 == -2] = 0\n",
    "            # vk[vk == -2] = 0\n",
    "\n",
    "\n",
    "            # v0.unsqueeze_(-1)\n",
    "            # v0 = v0.expand(v0.shape[0], v0.shape[1], rbm.K)\n",
    "            # vk.unsqueeze_(-1)\n",
    "            # vk = vk.expand(vk.shape[0], vk.shape[1], rbm.K)\n",
    "\n",
    "            # v0 = torch.transpose(v0, 0, 2)\n",
    "            # vk = torch.transpose(vk, 0, 2)\n",
    "\n",
    "            # for i in range(rbm.K):\n",
    "            #     v0[i][v0[i] != i+1] = 0\n",
    "            #     # v0[i][(v0[i] != i+1) & (v0[i] != -1)] = 0\n",
    "            #     v0[i][v0[i] == i+1] = 1\n",
    "            \n",
    "            ph0, _ = rbm.sample_h(v0)\n",
    "\n",
    "            # Third for loop - perform contrastive divergence\n",
    "            # TODO misschien is iets lager proberen?\n",
    "            for k in range(1):\n",
    "                _, hk = rbm.sample_h(vk)\n",
    "                _, vk = rbm.sample_v(hk)\n",
    "\n",
    "                # We don't want to learn when there is no rating by the user, and there is no update when rating = -1\n",
    "                # Remove indices from vk vector that are not in the v0 vector => get sparse tensor again\n",
    "                vk[v0 < 0] = v0[v0 < 0]\n",
    "                \n",
    "\n",
    "            phk, _ = rbm.sample_h(vk)\n",
    "\n",
    "            rbm.train_model(v0, vk, ph0, phk)\n",
    "            vk, _ = rbm.sample_v(hk)\n",
    "            \n",
    "            train_recon_error += torch.sqrt(torch.mean((v0[v0 > -1] - vk[v0 > -1])**2)) * len(v0 > -1)\n",
    "            s += len(v0 > -1)\n",
    "            \n",
    "        train_errors.append(train_recon_error / s)\n",
    "\n",
    "        # print('calculating test scores')\n",
    "        rbm.eval()\n",
    "        test_errors.append(score_model(rbm, batch_size, train_matrix, test_matrix))\n",
    "\n",
    "        # print('finished epoch', epoch)    \n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "    # Plot the RMSE reconstruction error with respect to increasing number of epochs\n",
    "    plt.plot(torch.Tensor(train_errors, device='cpu'), label=\"train\")\n",
    "    plt.plot(torch.Tensor(test_errors, device='cpu'), label=\"test\")\n",
    "    plt.ylabel('Error')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend()\n",
    "    plt.savefig(f'netflix-{n_hidden}-{batch_size}-{epochs}.jpg')\n",
    "\n",
    "    return rbm\n",
    "\n",
    "# Evaluate the RBM on test set\n",
    "# test_recon_error = score_model(rbm)\n",
    "# print(\"Final error\", test_recon_error)\n",
    "create_rbm(train_matrix, test_matrix, 100, 1000, 10, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_errors' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16656/296781233.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_errors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'train_errors' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_3736/1830910530.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mgc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\cuda\\memory.py\u001b[0m in \u001b[0;36mempty_cache\u001b[1;34m()\u001b[0m\n\u001b[0;32m    112\u001b[0m     \"\"\"\n\u001b[0;32m    113\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mis_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 114\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cuda_emptyCache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "# import gc\n",
    "# \n",
    "# gc.collect()\n",
    "\n",
    "# torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ac59ebe37160ed0dfa835113d9b8498d9f09ceb179beaac4002f036b9467c963"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
